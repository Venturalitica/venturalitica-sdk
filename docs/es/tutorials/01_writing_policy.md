# üõ†Ô∏è Escribiendo Pol√≠tica Primero en C√≥digo (El Ingeniero)

Esta gu√≠a se centra en la **Persona del Ingeniero**: quien traduce los requisitos legales en reglas t√©cnicas (OSCAL).
En el **Nivel 1**, aprendiste a "Bloquear" despliegues incorrectos. Ahora escribiremos el archivo de pol√≠tica real que gobierna el proyecto.

---

## Parte 1: La Pol√≠tica de Datos (`data_policy.yaml`)

Para la **Fase 1 (Auditor√≠a de Datos)**, solo nos importa el **Art√≠culo 10 (Gobernanza de Datos)**.
Tu Cient√≠fico de Datos (El Constructor) no puede comenzar el entrenamiento hasta que este archivo est√© listo.

### 1. La Estructura

Crea un archivo llamado `data_policy.yaml` en la ra√≠z de tu proyecto.

```yaml
assessment-plan:
  uuid: credit-scoring-v1
  metadata:
    title: "Art√≠culo 10: Directiva de Cr√©dito al Consumo (CCD)"
    description: "Criterios de aceptaci√≥n para la calidad y sesgo de los datos de entrenamiento."
  reviewed-controls:
    control-selections:
      - include-controls:
        # LAS REGLAS VAN AQU√ç
```

---

## 2. Definiendo las Reglas (Controles)

Un "Control" es una unidad de l√≥gica. En la Ley de IA de la UE, debes probar que verificaste riesgos espec√≠ficos.

### Regla A: Representaci√≥n (Soporte Estad√≠stico)
*   **Requisito Legal**: "Los conjuntos de datos de entrenamiento, validaci√≥n y prueba deber√°n ser pertinentes, representativos, libres de errores y completos." (Art 10.3)
*   **Traducci√≥n**: Asegurar que ning√∫n grupo demogr√°fico sea borrado (M√≠nimo 20% de representaci√≥n).

```yaml
        - control-id: check-imbalance
          description: "Asegurar que los grupos minoritarios sean estad√≠sticamente significativos."
          props:
            - name: metric_key
              value: min_class_ratio
            - name: threshold
              value: "0.20"  # Fallar si la clase minoritaria < 20%
            - name: operator
              value: ">"
```

### Regla B: Sesgo (Impacto Dispar)
*   **Requisito Legal**: "Examen de posibles sesgos." (Art 10.2.f)
*   **Traducci√≥n**: Las tasas de aceptaci√≥n no deben desviarse m√°s del 20% entre grupos (Regla de los Cuatro Quintos).

```yaml
        - control-id: check-gender-bias
          description: "El Ratio de Impacto Dispar debe estar entre 0.8 - 1.25"
          props:
            - name: metric_key
              value: disparate_impact_ratio
            - name: threshold
              value: "0.80"
            - name: operator
              value: ">"
```

---

## 3. Verificar la Pol√≠tica

Antes de entregarla al Cient√≠fico de Datos, verifica que funcione.

```python
import venturalitica as vl
from venturalitica.quickstart import load_sample

# 1. Cargar el Conjunto de Datos 'Aprobado' (Simulado)
data = load_sample('loan')

# 2. Prueba Seca de la Pol√≠tica
try:
    vl.enforce(
        data=data,
        target="class",
        gender="Attribute9",  # "Estado personal y sexo" en Datos de Cr√©dito Alem√°n
        policy="data_policy.yaml"
    )
    print("‚úÖ La pol√≠tica tiene sintaxis v√°lida y pasa los datos base.")
except Exception as e:
    print(f"‚ùå Error de Pol√≠tica: {e}")
```

---

## Parte 2: La Pol√≠tica del Modelo (`model_policy.yaml`)

Una vez aprobados los datos, necesitas definir las reglas para el **producto final** (el modelo entrenado).
Esto corresponde al **Art√≠culo 15 (Precisi√≥n, Robustez y Ciberseguridad)**.

Crea un segundo archivo: `model_policy.yaml`.

### Regla C: Rendimiento (Precisi√≥n)
*   **Requisito Legal**: "Los sistemas de IA de alto riesgo se dise√±ar√°n... para lograr un nivel adecuado de precisi√≥n." (Art 15.1)
*   **Traducci√≥n**: El modelo debe ser mejor que adivinar al azar (ej. > 70% de precisi√≥n).

```yaml
        - control-id: accuracy-check
          description: "El modelo debe lograr al menos 70% de precisi√≥n."
          props:
            - name: metric_key
              value: accuracy_score
            - name: threshold
              value: "0.70"
            - name: operator
              value: ">"
```

### Regla D: Equidad Post-Entrenamiento (Resultado)
*   **Requisito Legal**: "Los resultados no deber√°n estar sesgados..."
*   **Traducci√≥n**: Incluso si los datos estaban equilibrados, el modelo podr√≠a aprender a discriminar. Verifica las predicciones nuevamente.

```yaml
        - control-id: gender-fairness-model
          description: "Asegurar que las predicciones del modelo no impacten disparmente a las mujeres."
          props:
            - name: metric_key
              value: disparate_impact_ratio
            - name: "input:dimension"
              value: "gender"         # Enlazar expl√≠citamente a la columna de g√©nero
            - name: threshold
              value: "0.80"
            - name: operator
              value: ">"
```

---

## ¬øQu√© Sigue?

Ahora has creado la **especificaci√≥n**.
üëâ Entrega estos archivos (`data_policy.yaml` y `model_policy.yaml`) a tu Cient√≠fico de Datos. Ellos los usar√°n en el **Nivel 2** para auditar su flujo de entrenamiento.
