{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Venturalitica","text":"<p>Frictionless Governance for AI.</p> <p>Detect bias in your datasets with one line of code.</p> <pre><code>import venturalitica as vl\n\n# Auto-download UCI data and run bias audit\nresults = vl.quickstart('loan')\n</code></pre>"},{"location":"#get-started","title":"Get Started","text":"<p>\u2192 60-Second Quickstart - Your first bias audit</p>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install venturalitica\n</code></pre> <p>\u00a9 2026 Venturalitica | GitHub</p>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#core-functions","title":"Core Functions","text":""},{"location":"api/#quickstart","title":"quickstart","text":"<p>Run a pre-configured bias audit demo.</p> <pre><code>import venturalitica as vl\n\nresults = vl.quickstart('loan')\n</code></pre> <p>Parameters: - <code>scenario</code> (str): One of <code>'loan'</code>, <code>'hiring'</code>, <code>'health'</code> - <code>verbose</code> (bool): Show detailed output (default: True)</p> <p>Returns: <code>List[ComplianceResult]</code></p>"},{"location":"api/#enforce","title":"enforce","text":"<p>Audit data or model predictions for bias.</p> <pre><code>import venturalitica as vl\n\n# Data audit (pre-training)\nvl.enforce(\n    data=df,\n    target=\"approved\",\n    gender=\"gender\",\n    policy=\"policy.yaml\"\n)\n\n# Model audit (post-training)\nvl.enforce(\n    data=df,\n    target=\"approved\",\n    prediction=predictions,\n    gender=\"gender\",\n    policy=\"policy.yaml\"\n)\n</code></pre> <p>Parameters: - <code>data</code> (DataFrame): Your dataset - <code>target</code> (str): Column with ground truth - <code>prediction</code> (str or array): Model predictions (optional for data-only audit) - <code>policy</code> (str): Path to OSCAL policy file - <code>**attributes</code>: Protected attributes (e.g., <code>gender=\"col_name\"</code>)</p> <p>Returns: <code>List[ComplianceResult]</code></p>"},{"location":"api/#wrap","title":"wrap","text":"<p>Automatically audit on <code>fit()</code> and <code>predict()</code>.</p> <pre><code>import venturalitica as vl\nfrom sklearn.ensemble import RandomForestClassifier\n\nmodel = vl.wrap(RandomForestClassifier(), policy=\"policy.yaml\")\n\n# Auto-audits on fit\nmodel.fit(X_train, y_train, audit_data=df_train)\n\n# Auto-audits on predict\nmodel.predict(X_test, audit_data=df_test)\n\n# Get results\nmodel.last_audit_results\n</code></pre> <p>Parameters: - <code>model</code>: Any sklearn-compatible model - <code>policy</code> (str): Path to OSCAL policy file</p> <p>Returns: <code>GovernanceWrapper</code> (behaves like original model)</p>"},{"location":"api/#monitor","title":"monitor","text":"<p>Context manager for tracking training.</p> <pre><code>import venturalitica as vl\n\nwith vl.monitor(name=\"My Training\"):\n    model.fit(X, y)\n</code></pre> <p>Tracks: - Duration - CO2 emissions (if CodeCarbon installed) - Hardware telemetry</p>"},{"location":"api/#utility-functions","title":"Utility Functions","text":""},{"location":"api/#list_scenarios","title":"list_scenarios","text":"<pre><code>&gt;&gt;&gt; vl.list_scenarios()\n{'loan': 'Credit scoring fairness',\n 'hiring': 'Recruitment equity',\n 'health': 'Clinical diagnosis fairness'}\n</code></pre>"},{"location":"api/#load_sample","title":"load_sample","text":"<pre><code>df = vl.load_sample('loan')\n</code></pre> <p>Loads UCI dataset for the given scenario.</p>"},{"location":"quickstart/","title":"60-Second Quickstart","text":"<p>Goal: Your first bias audit in under 60 seconds.</p>"},{"location":"quickstart/#step-1-install","title":"Step 1: Install","text":"<pre><code>pip install venturalitica\n</code></pre>"},{"location":"quickstart/#step-2-run-your-first-audit","title":"Step 2: Run Your First Audit","text":"<pre><code>import venturalitica as vl\n\nvl.quickstart('loan')\n</code></pre> <p>Output:</p> <pre><code>[Venturalitica] \ud83c\udf93 Scenario: Credit Scoring Fairness\n[Venturalitica] \ud83d\udcca Loaded: UCI Dataset #144 (1000 samples)\n\n  \u274c FAIL | Controls: 2/3 passed\n    \u2713 [credit-data-imbalance] Data Quality... 0.429 (Limit: &gt;0.2)\n    \u2713 [credit-data-bias] Disparate impact... 0.818 (Limit: &gt;0.8)\n    \u2717 [credit-age-disparate] Age disparity... 0.286 (Limit: &gt;0.5)\n</code></pre> <p>\ud83d\udca1 The audit detected age-based bias in the UCI German Credit dataset.</p>"},{"location":"quickstart/#step-3-whats-happening-under-the-hood","title":"Step 3: What's Happening Under the Hood","text":"<p>The <code>quickstart()</code> function is a wrapper that:</p> <ol> <li>Downloads data from UCI Machine Learning Repository</li> <li>Loads a policy that defines fairness rules</li> <li>Calls <code>enforce()</code> to run the audit</li> </ol> <p>Here's the equivalent code:</p> <pre><code>from ucimlrepo import fetch_ucirepo\nimport venturalitica as vl\n\n# 1. Load UCI German Credit dataset\ndataset = fetch_ucirepo(id=144)\ndf = dataset.data.features\ndf['class'] = dataset.data.targets\n\n# 2. Run audit with policy\nvl.enforce(\n    data=df,\n    target=\"class\",\n    gender=\"Attribute9\",\n    age=\"Attribute13\",\n    policy=\"risks.oscal.yaml\"\n)\n</code></pre>"},{"location":"quickstart/#the-policy-file","title":"The Policy File","text":"<p>The policy (<code>risks.oscal.yaml</code>) defines the rules:</p> <pre><code>assessment-plan:\n  uuid: credit-risk-policy\n  metadata:\n    title: \"Credit Scoring Fairness\"\n  reviewed-controls:\n    control-selections:\n      - include-controls:\n        - control-id: credit-data-bias\n          description: \"Disparate impact ratio must be &gt; 0.8 (80% rule)\"\n          props:\n            - name: metric_key\n              value: disparate_impact\n            - name: threshold\n              value: \"0.8\"\n            - name: operator\n              value: \"&gt;\"\n            - name: \"input:dimension\"\n              value: gender\n            - name: \"input:target\"\n              value: target\n</code></pre> <p>Each control defines: - metric_key: What to measure (<code>disparate_impact</code>) - threshold: The limit (<code>0.8</code>) - operator: How to compare (<code>&gt;</code>) - inputs: Which columns to use</p>"},{"location":"quickstart/#whats-next","title":"What's Next?","text":"<ul> <li>API Reference - Full documentation</li> <li>Create your own policy - Copy the YAML above and modify thresholds</li> </ul>"},{"location":"training/","title":"Training Tutorial","text":"<p>Integrate fairness and performance checks into your ML workflow.</p>"},{"location":"training/#overview","title":"Overview","text":"Phase Check Function Pre-training Data bias <code>enforce(data=train_df)</code> Post-training Model fairness + Performance <code>enforce(data=test_df, prediction=pred)</code>"},{"location":"training/#step-1-load-data","title":"Step 1: Load Data","text":"<pre><code>from ucimlrepo import fetch_ucirepo\nfrom sklearn.model_selection import train_test_split\n\n# Fetch UCI German Credit\ndataset = fetch_ucirepo(id=144)\ndf = dataset.data.features.copy()\ndf['class'] = dataset.data.targets\n\n# Split\ntrain_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\nX_train = train_df.drop(columns=['class'])\ny_train = train_df['class']\nX_test = test_df.drop(columns=['class'])\ny_test = test_df['class']\n</code></pre>"},{"location":"training/#step-2-pre-training-audit-data-bias","title":"Step 2: Pre-Training Audit (Data Bias)","text":"<p>Check training data for bias before you train:</p> <pre><code>import venturalitica as vl\n\nvl.enforce(\n    data=train_df,\n    target=\"class\",\n    gender=\"Attribute9\",\n    policy=\"data-policy.yaml\"\n)\n</code></pre>"},{"location":"training/#data-policyyaml","title":"data-policy.yaml","text":"<pre><code>assessment-plan:\n  uuid: data-bias-policy\n  metadata:\n    title: \"Training Data Quality\"\n  reviewed-controls:\n    control-selections:\n      - include-controls:\n        - control-id: class-balance\n          description: \"Minority class must be &gt;20%\"\n          props:\n            - name: metric_key\n              value: minority_ratio\n            - name: threshold\n              value: \"0.2\"\n            - name: operator\n              value: \"&gt;\"\n        - control-id: gender-disparate\n          description: \"Disparate impact &gt;0.8 (80% rule)\"\n          props:\n            - name: metric_key\n              value: disparate_impact\n            - name: threshold\n              value: \"0.8\"\n            - name: operator\n              value: \"&gt;\"\n            - name: \"input:dimension\"\n              value: gender\n            - name: \"input:target\"\n              value: target\n</code></pre>"},{"location":"training/#step-3-train-model","title":"Step 3: Train Model","text":"<pre><code>from sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\nmodel.fit(X_train, y_train)\n</code></pre>"},{"location":"training/#step-4-post-training-audit-fairness-performance","title":"Step 4: Post-Training Audit (Fairness + Performance)","text":"<p>Check model predictions on test data:</p> <pre><code># Get predictions\npredictions = model.predict(X_test)\n\n# Prepare test dataframe\ntest_df_with_pred = test_df.copy()\ntest_df_with_pred['prediction'] = predictions\n\n# Audit fairness AND performance\nvl.enforce(\n    data=test_df_with_pred,\n    target=\"class\",\n    prediction=\"prediction\",\n    gender=\"Attribute9\",\n    policy=\"model-policy.yaml\"\n)\n</code></pre>"},{"location":"training/#model-policyyaml","title":"model-policy.yaml","text":"<pre><code>assessment-plan:\n  uuid: model-fairness-policy\n  metadata:\n    title: \"Model Fairness &amp; Performance\"\n  reviewed-controls:\n    control-selections:\n      - include-controls:\n        # Performance checks\n        - control-id: accuracy-check\n          description: \"Model accuracy must be &gt;70%\"\n          props:\n            - name: metric_key\n              value: accuracy\n            - name: threshold\n              value: \"0.7\"\n            - name: operator\n              value: \"&gt;\"\n        - control-id: precision-check\n          description: \"Precision must be &gt;60%\"\n          props:\n            - name: metric_key\n              value: precision\n            - name: threshold\n              value: \"0.6\"\n            - name: operator\n              value: \"&gt;\"\n        # Fairness checks\n        - control-id: equal-opportunity\n          description: \"Equal opportunity difference &lt;10%\"\n          props:\n            - name: metric_key\n              value: equal_opportunity_diff\n            - name: threshold\n              value: \"0.1\"\n            - name: operator\n              value: \"&lt;\"\n            - name: \"input:dimension\"\n              value: gender\n            - name: \"input:target\"\n              value: target\n            - name: \"input:prediction\"\n              value: prediction\n</code></pre>"},{"location":"training/#example-output","title":"Example Output","text":"<pre><code>[Venturalitica] \ud83d\udee1  Enforcing policy: model-policy.yaml\n  \u2705 PASS | Controls: 3/3 passed\n    \u2713 [accuracy-check] Model accuracy... 0.76 (Limit: &gt;0.7)\n    \u2713 [precision-check] Precision... 0.68 (Limit: &gt;0.6)\n    \u2713 [equal-opportunity] Equal opportunity... 0.08 (Limit: &lt;0.1)\n</code></pre>"},{"location":"training/#summary","title":"Summary","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Phase       \u2502 What to Check       \u2502 Policy File          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Pre-train   \u2502 Data bias           \u2502 data-policy.yaml     \u2502\n\u2502 Post-train  \u2502 Fairness + Accuracy \u2502 model-policy.yaml    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"}]}