{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Venturalitica","text":"<p>Frictionless Governance for AI.</p> <p>Detect bias in your datasets with one line of code.</p> <pre><code>import venturalitica as vl\n\n# Auto-download UCI data and run bias audit\nresults = vl.quickstart('loan')\n</code></pre>"},{"location":"#get-started","title":"Get Started","text":"<p>\u2192 60-Second Quickstart - Your first bias audit</p>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install venturalitica\n</code></pre> <p>\u00a9 2026 Venturalitica | GitHub</p>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#core-functions","title":"Core Functions","text":""},{"location":"api/#quickstart","title":"quickstart","text":"<p>Run a pre-configured bias audit demo.</p> <pre><code>import venturalitica as vl\n\nresults = vl.quickstart('loan')\n</code></pre> <p>Parameters: - <code>scenario</code> (str): One of <code>'loan'</code>, <code>'hiring'</code>, <code>'health'</code> - <code>verbose</code> (bool): Show detailed output (default: True)</p> <p>Returns: <code>List[ComplianceResult]</code></p>"},{"location":"api/#enforce","title":"enforce","text":"<p>Audit data or model predictions for bias.</p> <pre><code>import venturalitica as vl\n\n# Data audit (pre-training)\nvl.enforce(\n    data=df,\n    target=\"approved\",\n    gender=\"gender\",\n    policy=\"policy.yaml\"\n)\n\n# Model audit (post-training)\nvl.enforce(\n    data=df,\n    target=\"approved\",\n    prediction=predictions,\n    gender=\"gender\",\n    policy=\"policy.yaml\"\n)\n</code></pre> <p>Parameters: - <code>data</code> (DataFrame): Your dataset - <code>target</code> (str): Column with ground truth - <code>prediction</code> (str or array): Model predictions (optional for data-only audit) - <code>policy</code> (str): Path to OSCAL policy file - <code>**attributes</code>: Protected attributes (e.g., <code>gender=\"col_name\"</code>)</p> <p>Returns: <code>List[ComplianceResult]</code></p>"},{"location":"api/#wrap","title":"wrap","text":"<p>Automatically audit on <code>fit()</code> and <code>predict()</code>.</p> <pre><code>import venturalitica as vl\nfrom sklearn.ensemble import RandomForestClassifier\n\nmodel = vl.wrap(RandomForestClassifier(), policy=\"policy.yaml\")\n\n# Auto-audits on fit\nmodel.fit(X_train, y_train, audit_data=df_train)\n\n# Auto-audits on predict\nmodel.predict(X_test, audit_data=df_test)\n\n# Get results\nmodel.last_audit_results\n</code></pre> <p>Parameters: - <code>model</code>: Any sklearn-compatible model - <code>policy</code> (str): Path to OSCAL policy file</p> <p>Returns: <code>GovernanceWrapper</code> (behaves like original model)</p>"},{"location":"api/#monitor","title":"monitor","text":"<p>Context manager for tracking training.</p> <pre><code>import venturalitica as vl\n\nwith vl.monitor(name=\"My Training\"):\n    model.fit(X, y)\n</code></pre> <p>Tracks: - Duration - CO2 emissions (if CodeCarbon installed) - Hardware telemetry</p>"},{"location":"api/#utility-functions","title":"Utility Functions","text":""},{"location":"api/#list_scenarios","title":"list_scenarios","text":"<pre><code>&gt;&gt;&gt; vl.list_scenarios()\n{'loan': 'Credit scoring fairness',\n 'hiring': 'Recruitment equity',\n 'health': 'Clinical diagnosis fairness'}\n</code></pre>"},{"location":"api/#load_sample","title":"load_sample","text":"<pre><code>df = vl.load_sample('loan')\n</code></pre> <p>Loads UCI dataset for the given scenario.</p>"},{"location":"quickstart/","title":"60-Second Quickstart","text":"<p>Goal: Your first bias audit in under 60 seconds.</p>"},{"location":"quickstart/#step-1-install","title":"Step 1: Install","text":"<pre><code>pip install venturalitica\n</code></pre>"},{"location":"quickstart/#step-2-run-your-first-audit","title":"Step 2: Run Your First Audit","text":"<pre><code>import venturalitica as vl\n\nvl.quickstart('loan')\n</code></pre> <p>Output:</p> <pre><code>[Venturalitica] \ud83c\udf93 Scenario: Credit Scoring Fairness\n[Venturalitica] \ud83d\udcca Loaded: UCI Dataset #144 (1000 samples)\n\n  \u274c FAIL | Controls: 2/3 passed\n    \u2713 [credit-data-imbalance] Data Quality... 0.429 (Limit: &gt;0.2)\n    \u2713 [credit-data-bias] Disparate impact... 0.818 (Limit: &gt;0.8)\n    \u2717 [credit-age-disparate] Age disparity... 0.286 (Limit: &gt;0.5)\n</code></pre> <p>\ud83d\udca1 The audit detected age-based bias in the UCI German Credit dataset.</p>"},{"location":"quickstart/#step-3-whats-happening-under-the-hood","title":"Step 3: What's Happening Under the Hood","text":"<p>The <code>quickstart()</code> function is a wrapper that:</p> <ol> <li>Downloads data from UCI Machine Learning Repository</li> <li>Loads a policy that defines fairness rules</li> <li>Calls <code>enforce()</code> to run the audit</li> </ol> <p>Here's the equivalent code:</p> <pre><code>from ucimlrepo import fetch_ucirepo\nimport venturalitica as vl\n\n# 1. Load UCI German Credit dataset\ndataset = fetch_ucirepo(id=144)\ndf = dataset.data.features\ndf['class'] = dataset.data.targets\n\n# 2. Run audit with policy\nvl.enforce(\n    data=df,\n    target=\"class\",\n    gender=\"Attribute9\",\n    age=\"Attribute13\",\n    policy=\"risks.oscal.yaml\"\n)\n</code></pre>"},{"location":"quickstart/#the-policy-file","title":"The Policy File","text":"<p>The policy (<code>risks.oscal.yaml</code>) defines the rules:</p> <pre><code>assessment-plan:\n  uuid: credit-risk-policy\n  metadata:\n    title: \"Credit Scoring Fairness\"\n  reviewed-controls:\n    control-selections:\n      - include-controls:\n        - control-id: credit-data-bias\n          description: \"Disparate impact ratio must be &gt; 0.8 (80% rule)\"\n          props:\n            - name: metric_key\n              value: disparate_impact\n            - name: threshold\n              value: \"0.8\"\n            - name: operator\n              value: \"&gt;\"\n            - name: \"input:dimension\"\n              value: gender\n            - name: \"input:target\"\n              value: target\n</code></pre> <p>Each control defines: - metric_key: What to measure (<code>disparate_impact</code>) - threshold: The limit (<code>0.8</code>) - operator: How to compare (<code>&gt;</code>) - inputs: Which columns to use</p>"},{"location":"quickstart/#whats-next","title":"What's Next?","text":"<ul> <li>API Reference - Full documentation</li> <li>Create your own policy - Copy the YAML above and modify thresholds</li> </ul>"},{"location":"training/","title":"Training Tutorial","text":"<p>Integrate fairness and performance checks into your ML workflow.</p>"},{"location":"training/#overview","title":"Overview","text":"<p>\ud83d\udcd3 Interactive Version: You can run this tutorial in a Jupyter Notebook: 01-training-tutorial.ipynb</p> Phase Check Function Pre-training Data bias <code>enforce(data=train_df)</code> Post-training Model fairness + Performance <code>enforce(data=test_df, prediction=pred)</code>"},{"location":"training/#step-1-load-and-prepare-data","title":"Step 1: Load and Prepare Data","text":"<p>Since the German Credit dataset contains categorical strings, we must encode them before training.</p> <pre><code>from ucimlrepo import fetch_ucirepo\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\n\n# Fetch UCI German Credit\ndataset = fetch_ucirepo(id=144)\ndf = dataset.data.features.copy()\ndf['class'] = dataset.data.targets\n\n# Split raw data for the audit\ntrain_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n\n# Encode data for Scikit-Learn training\ndf_encoded = pd.get_dummies(df.drop(columns=['class']))\nX_train, X_test, y_train, y_test = train_test_split(\n    df_encoded, \n    df['class'].values.ravel(), \n    test_size=0.2, \n    random_state=42\n)\n</code></pre>"},{"location":"training/#step-2-pre-training-audit-data-bias","title":"Step 2: Pre-Training Audit (Data Bias)","text":"<p>Check your training data for bias before starting the compute-heavy training phase.</p> <pre><code>import venturalitica as vl\n\nvl.enforce(\n    data=train_df,\n    target=\"class\",\n    gender=\"Attribute9\",  # Gender/Status column\n    age=\"Attribute13\",    # Age column\n    policy=\"loan-policy.yaml\"\n)\n</code></pre> <p>Real Output: <pre><code>[Venturalitica] \ud83d\udee1 Enforcing policy: loan-policy.yaml\n  \u274c FAIL | Controls: 2/3 passed\n    \u2713 [imbalance] Minority ratio... 0.429 (Limit: &gt;0.2)\n    \u2713 [gender-bias] Disparate impact... 0.818 (Limit: &gt;0.8)\n    \u2717 [age-bias] Age disparity... 0.286 (Limit: &gt;0.5)\n</code></pre></p>"},{"location":"training/#step-3-train-and-evaluate","title":"Step 3: Train and Evaluate","text":"<pre><code>from sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\nmodel.fit(X_train, y_train)\n\n# Get predictions on test set\npredictions = model.predict(X_test)\n</code></pre>"},{"location":"training/#step-4-post-training-audit-fairness-performance","title":"Step 4: Post-Training Audit (Fairness + Performance)","text":"<p>Audit the model's behavior on unseen data.</p> <pre><code># Create audit dataframe (raw features + predictions)\ntest_audit_df = df.iloc[test_df.index].copy()\ntest_audit_df['prediction'] = predictions\n\nvl.enforce(\n    data=test_audit_df,\n    target=\"class\",\n    prediction=\"prediction\",\n    gender=\"Attribute9\",\n    age=\"Attribute13\",\n    policy=\"loan-policy.yaml\"\n)\n</code></pre> <p>Real Output: <pre><code>[Venturalitica] \ud83d\udee1 Enforcing policy: loan-policy.yaml\n  \u274c FAIL | Controls: 1/3 passed\n    \u2713 [imbalance] Minority ratio... 0.418 (Limit: &gt;0.2)\n    \u2717 [gender-bias] Disparate impact... 0.703 (Limit: &gt;0.8)\n    \u2717 [age-bias] Age disparity... 0.000 (Limit: &gt;0.5)\n</code></pre></p> <p>[!WARNING] While the training data passed the Gender check (0.81), the model amplified the bias in its predictions (0.70). This is a clear signal to retrain with fairness constraints.</p> <p>[!IMPORTANT] Why 0.286 vs 1.000?  If you see a perfect <code>1.000</code> but expect bias, check your column binding. If a column is missing or mismatched, Venturalitica may default to 1.0. Always verify your column names (like <code>Attribute9</code> vs <code>gender</code>) in the <code>enforce()</code> call.</p>"},{"location":"training/#step-5-including-performance-metrics","title":"Step 5: Including Performance Metrics","text":"<p>It makes perfect sense to audit performance alongside fairness. If you \"fix\" bias but destroy the model's utility (e.g., 20% accuracy), the system is still failing.</p> <p>You can define performance thresholds in the same policy:</p> <pre><code>- control-id: accuracy-threshold\n  description: \"Model must achieve at least 75% accuracy\"\n  props:\n    - name: metric_key\n      value: accuracy\n    - name: threshold\n      value: \"0.75\"\n    - name: operator\n      value: gt\n</code></pre> <p>Venturalitica supports: <code>accuracy</code>, <code>precision</code>, <code>recall</code>, and <code>f1</code>.</p>"}]}