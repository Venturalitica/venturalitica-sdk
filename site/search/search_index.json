{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Venturalitica","text":"<p>Frictionless Governance for AI.</p> <p>Venturalitica is a lightweight Python SDK designed to enforce policies, audit fairness, and track environmental impact in your ML workflows with zero friction.</p>"},{"location":"#quickstart-in-60-seconds","title":"\u26a1\ufe0f Quickstart in 60 Seconds","text":"<p>Detect bias in your datasets or models with one line of code.</p> <pre><code>import venturalitica as vl\n\n# Auto-download UCI data, load policy, and run bias audit\nresults = vl.quickstart('loan')\n</code></pre>"},{"location":"#key-features","title":"\ud83d\udee1 Key Features","text":"Feature Description Bias Detection Quantitative fairness audits (Disparate Impact, Class Balance). Integrity Checks Immutable audit trails and model fingerprints. Green AI Native carbon emission and energy consumption tracking. Policy as Code Define governance rules in standard OSCAL/YAML formats. Framework Agnostic Works with Scikit-learn, PyTorch, TensorFlow, and more."},{"location":"#explore-tutorials","title":"\ud83d\udcda Explore Tutorials","text":"<p>Start with our interactive Jupyter notebooks:</p> <ul> <li>\u26a1\ufe0f Zero-Setup Audit - Run a full compliance scan on any project folder in 2 minutes.</li> <li>\ud83d\udee0\ufe0f Training Workflow - Learn how to audit data before training and verify models post-training.</li> <li>\ud83d\udcca Regulatory Mapping - Deep dive into how Venturalitica maps technical evidence to the EU AI Act.</li> </ul>"},{"location":"#installation","title":"\u2699\ufe0f Installation","text":"<pre><code>pip install venturalitica\n</code></pre> <p>Quickstart Guide | Local Audit Tutorial | Regulatory Map | API Reference</p> <p>\u00a9 2026 Venturalitica | Built for Responsible AI</p>"},{"location":"api/","title":"API Reference","text":"<p>Venturalitica provides a simple, unified interface for AI governance.</p>"},{"location":"api/#core-functions","title":"\ud83d\ude80 Core Functions","text":""},{"location":"api/#quickstartscenario-verbosetrue","title":"<code>quickstart(scenario, verbose=True)</code>","text":"<p>Run a pre-configured bias audit demo on a standard dataset.</p> Parameter Type Description <code>scenario</code> <code>str</code> Predefined scenario: <code>'loan'</code>, <code>'hiring'</code>, <code>'health'</code>. <code>verbose</code> <code>bool</code> Whether to print the structured table report to the console. <p>Returns: <code>List[ComplianceResult]</code></p>"},{"location":"api/#enforcedata-target-predictionnone-policynone-attributes","title":"<code>enforce(data, target, prediction=None, policy=None, **attributes)</code>","text":"<p>The main entry point for auditing datasets and models.</p> Parameter Type Description <code>data</code> <code>DataFrame</code> Pandas DataFrame containing features, targets, and optionally predictions. <code>target</code> <code>str</code> Name of the column with ground truth labels. <code>prediction</code> <code>str\\|array</code> (Optional) Column name or array of model predictions. <code>policy</code> <code>str</code> Path to the OSCAL/YAML policy file. <code>**attributes</code> <code>str</code> Mappings for protected variables (e.g., <code>gender=\"attr9\"</code>, <code>age=\"age_col\"</code>). <p>Returns: <code>List[ComplianceResult]</code></p> <p>[!NOTE] If <code>prediction</code> is omitted, fairness metrics automatically fall back to using <code>target</code> to audit data bias.</p>"},{"location":"api/#wrapmodel-policy-experimental","title":"<code>wrap(model, policy)</code> (Experimental)","text":"<p>[!CAUTION] PREVIEW: This function is experimental and its API might change.</p> <p>Transparently audit your model during Scikit-Learn standard workflows.</p> Parameter Type Description <code>model</code> <code>object</code> Any Scikit-learn compatible classifier or regressor. <code>policy</code> <code>str</code> Path to the policy for evaluation. <p>Returns: <code>GovernanceWrapper</code> (Preserves original API like <code>.fit()</code> and <code>.predict()</code>).</p>"},{"location":"api/#monitorname","title":"<code>monitor(name)</code>","text":"<p>A context manager to track training metrics, hardware health, and environmental impact.</p> <pre><code>with vl.monitor(name=\"CreditModel-v1\"):\n    model.fit(X, y)\n</code></pre> <p>Collected Telemetry: - \u23f1 Duration: Execution time of the block. - \ud83c\udf31 Emissions: Carbon footprint (requires <code>codecarbon</code>). - \ud83d\udee1 Stability: Model fingerprinting and integrity verification.</p>"},{"location":"api/#utility-functions","title":"\ud83d\udee0 Utility Functions","text":""},{"location":"api/#list_scenarios","title":"<code>list_scenarios()</code>","text":"<p>Returns a dictionary of available scenarios and their descriptions.</p>"},{"location":"api/#load_samplescenario","title":"<code>load_sample(scenario)</code>","text":"<p>Loads the corresponding UCI dataset for a scenario as a Pandas DataFrame.</p>"},{"location":"compliance-dashboard/","title":"The Compliance Dashboard: A Glass Box for AI","text":"<p>The Venturalitica Compliance Dashboard is your local control center for AI Governance. Unlike \"Black Box\" compliance tools that operate behind closed doors, Venturalitica provides is a Glass Box experience: it exposes the exact technical evidence your system is producing and maps it directly to regulatory obligations.</p> <p>The dashboard makes the abstract concrete. It takes the invisible artifacts of your ML pipeline\u2014metrics, logs, dependencies\u2014and renders them into a Regulatory Traceability Matrix.</p>"},{"location":"compliance-dashboard/#the-sequential-regulatory-map-articles-9-15","title":"The Sequential Regulatory Map (Articles 9-15)","text":"<p>The core feature of the dashboard is the strict sequential mapping of the EU AI Act requirements for High-Risk AI Systems (Chapter III, Section 2). This \"Compliance Walk\" guides you through the lifecycle of a compliant system.</p>"},{"location":"compliance-dashboard/#the-traceability-flow","title":"The Traceability Flow","text":""},{"location":"compliance-dashboard/#1-article-9-risk-management-system","title":"1. Article 9: Risk Management System","text":"<ul> <li>The Law: You must identify and mitigate risks to health, safety, and fundamental rights.</li> <li>The Code: Venturalitica maps your Fairness Audits here. If you run a bias check (e.g., <code>gender-bias</code>), the result is the technical evidence that you are monitoring Fundamental Rights risks.</li> <li>Status:<ul> <li><code>Mitigation Verified</code>: Your fairness tests passed.</li> <li><code>Risk Materialized</code>: A test failed (e.g., Disparate Impact detected).</li> </ul> </li> </ul>"},{"location":"compliance-dashboard/#2-article-10-data-governance","title":"2. Article 10: Data Governance","text":"<ul> <li>The Law: Training, validation, and testing data must be relevant, representative, and error-free.</li> <li>The Code: Maps to your Data Quality Checks (e.g., class imbalance, missing values) and usage of data libraries (<code>pandas</code>, <code>numpy</code>).</li> <li>Status: Flags if data validation was skipped or failed.</li> </ul>"},{"location":"compliance-dashboard/#3-article-11-technical-documentation-annex-iv","title":"3. Article 11: Technical Documentation (Annex IV)","text":"<ul> <li>The Law: You must maintain up-to-date technical documentation demonstrating conformity.</li> <li>The Code: Checks for the presence of your Software Bill of Materials (SBOM) (generated by <code>venturalitica scan</code>) and the Technical File Draft (generated by <code>venturalitica doc</code>).</li> <li>Status: Green if artifacts exist; Yellow/Red if documentation is missing.</li> </ul>"},{"location":"compliance-dashboard/#4-article-12-record-keeping","title":"4. Article 12: Record-Keeping","text":"<ul> <li>The Law: Automatic logging of events over the system's lifetime to ensure traceability.</li> <li>The Code: Verifies two critical components:<ul> <li>Cryptographic Anchoring: Displays the SHA-256 hash of your evidence, proving data integrity.</li> <li>Execution Traces: Confirms that runtime metadata (<code>runtime_meta</code>) was captured during training/inference.</li> </ul> </li> </ul>"},{"location":"compliance-dashboard/#5-article-13-transparency-information","title":"5. Article 13: Transparency &amp; Information","text":"<ul> <li>The Law: The system must be sufficiently transparent to allow users to interpret outputs.</li> <li>The Code: Checks for Code Opacity. Is the source code accessible for audit? Are instructions provided?</li> </ul>"},{"location":"compliance-dashboard/#6-article-14-human-oversight","title":"6. Article 14: Human Oversight","text":"<ul> <li>The Law: The system must be designed to be overseen by natural persons (human-in-the-loop).</li> <li>The Code: Scans for \"Stop Button\" logic or interactive interfaces (e.g., Streamlit apps, Jupyter notebooks) that imply human control capability.</li> </ul>"},{"location":"compliance-dashboard/#7-article-15-accuracy-robustness-cybersecurity","title":"7. Article 15: Accuracy, Robustness &amp; Cybersecurity","text":"<ul> <li>The Law: The system must be resilient to errors and attacks.</li> <li>The Code:<ul> <li>Accuracy: Maps to your Performance Metrics (Accuracy, F1, Recall).</li> <li>Cybersecurity: Checks for Supply Chain Vulnerabilities (CVEs) in your dependencies via the SBOM scan.</li> </ul> </li> </ul>"},{"location":"compliance-dashboard/#why-this-matters","title":"Why This Matters","text":"<p>This sequential layout transforms compliance from a chaotic checklist into a logical engineering workflow:</p> <ol> <li>Assess Risk (Art 9)</li> <li>Clean Data (Art 10)</li> <li>Document It (Art 11)</li> <li>Log It (Art 12)</li> <li>Explain It (Art 13)</li> <li>control It (Art 14)</li> <li>Secure It (Art 15)</li> </ol> <p>By following this flow, you are structurally aligning your AI system with the law, line by line.</p>"},{"location":"evidence-collection/","title":"Evidence Collection: The Black Box Recorder","text":"<p>While Policies (the Enforcer) stop bad models from reaching production, Evidence Collection (the Recorder) ensures you can prove exactly what happened during training. This is your \"Black Box\" flight recorder for AI.</p> <p>In Venturalitica, evidence collection is distinct from policy enforcement. You can record evidence without blocking a deployment, or enforce strictly without saving traces. However, for full EU AI Act compliance (Article 12: Record-Keeping), you need both.</p>"},{"location":"evidence-collection/#two-ways-to-record","title":"Two Ways to Record","text":""},{"location":"evidence-collection/#1-the-automatic-wrapper-vlwrap","title":"1. The Automatic Wrapper (<code>vl.wrap</code>)","text":"<p>The easiest way to collect evidence is to wrap your estimator. This automatically hooks into <code>.fit()</code> and <code>.predict()</code> to capture inputs, outputs, and metadata.</p> <pre><code>import venturalitica as vl\nfrom sklearn.ensemble import RandomForestClassifier\n\n# 1. Wrap the model\nmodel = vl.wrap(RandomForestClassifier(), policy=\"my_policy.yaml\")\n\n# 2. Train as usual (Evidence is auto-collected)\nmodel.fit(X_train, y_train, audit_data=train_df, gender=\"sex\")\n</code></pre> <p>What is recorded? *   Timestamp: Precise start/end times. *   Model Config: Hyperparameters (<code>n_estimators</code>, <code>max_depth</code>, etc.). *   Data Shape: Number of rows/columns used. *   Code Context: The filename and AST analysis of the script that called <code>fit</code>.</p>"},{"location":"evidence-collection/#2-the-trace-collector-vltracecollector","title":"2. The Trace Collector (<code>vl.tracecollector</code>)","text":"<p>For custom training loops (e.g., PyTorch, TensorFlow) or complex pipelines where <code>fit()</code> isn't enough, use the context manager.</p> <pre><code>import venturalitica as vl\n\n# Start the recording session\nwith vl.tracecollector(\"custom_training_run\"):\n    # Your custom logic here\n    model = train_custom_model(data)\n    evaluate_model(model)\n\n# Evidence is saved to .venturalitica/trace_custom_training_run.json\n</code></pre>"},{"location":"evidence-collection/#where-does-the-evidence-go","title":"Where does the evidence go?","text":"<p>All evidence is secured locally in the <code>.venturalitica/</code> directory:</p> <ul> <li><code>results.json</code>: The outcome of your policy audits (Pass/Fail).</li> <li><code>trace_{name}.json</code>: The execution metadata (timestamps, code analysis).</li> <li><code>bom.json</code>: The software supply chain inventory (dependencies).</li> </ul>"},{"location":"evidence-collection/#compliance-impact","title":"Compliance Impact","text":"<p>For Article 12 (EU AI Act), this evidence is mandatory. The Venturalitica Dashboard reads these files to prove: 1.  Traceability: \"We know exactly which code and data produced Model v1.0.\" 2.  Integrity: \"The evidence has not been tampered with\" (via SHA-256 anchoring).</p> <p>[!TIP] View Your Traces: After running your training script, launch the dashboard (<code>venturalitica ui</code>) to visualize these traces in the Article 12 section.</p>"},{"location":"quickstart/","title":"60-Second Quickstart","text":"<p>Goal: Your first bias audit in under 60 seconds.</p>"},{"location":"quickstart/#step-1-install","title":"Step 1: Install","text":"<pre><code>pip install venturalitica\n</code></pre>"},{"location":"quickstart/#step-2-run-your-first-audit","title":"Step 2: Run Your First Audit","text":"<pre><code>import venturalitica as vl\n\nvl.quickstart('loan')\n</code></pre> <p>Output:</p> <pre><code>[Venturalitica v0.2.4] \ud83c\udf93 Scenario: Credit Scoring Fairness\n[Venturalitica v0.2.4] \ud83d\udcca Loaded: UCI Dataset #144 (1000 samples)\n\n  CONTROL                DESCRIPTION                            ACTUAL     LIMIT      RESULT\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  credit-data-imbalance  Data Quality                           0.431      &gt; 0.2      \u2705 PASS\n  credit-data-bias       Disparate impact                       0.836      &gt; 0.8      \u2705 PASS\n  credit-age-disparate   Age disparity                          0.361      &gt; 0.5      \u274c FAIL\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  Audit Summary: \u274c VIOLATION | 2/3 controls passed\n</code></pre> <p>\ud83d\udca1 The audit detected age-based bias in the UCI German Credit dataset.</p>"},{"location":"quickstart/#step-3-whats-happening-under-the-hood","title":"Step 3: What's Happening Under the Hood","text":"<p>The <code>quickstart()</code> function is a wrapper that:</p> <ol> <li>Downloads data from UCI Machine Learning Repository</li> <li>Loads a policy that defines fairness rules</li> <li>Calls <code>enforce()</code> to run the audit</li> </ol> <p>Here's the equivalent code:</p> <pre><code>from ucimlrepo import fetch_ucirepo\nimport venturalitica as vl\n\n# 1. Load UCI German Credit dataset\ndataset = fetch_ucirepo(id=144)\ndf = dataset.data.features\ndf['class'] = dataset.data.targets\n\n# 2. Run audit with policy\nvl.enforce(\n    data=df,\n    target=\"class\",\n    gender=\"Attribute9\",\n    age=\"Attribute13\",\n    policy=\"risks.oscal.yaml\"\n)\n</code></pre>"},{"location":"quickstart/#the-policy-file","title":"The Policy File","text":"<p>The policy (<code>risks.oscal.yaml</code>) defines the rules:</p> <pre><code>assessment-plan:\n  uuid: credit-risk-policy\n  metadata:\n    title: \"Credit Scoring Fairness\"\n  reviewed-controls:\n    control-selections:\n      - include-controls:\n        - control-id: credit-data-bias\n          description: \"Disparate impact ratio must be &gt; 0.8 (80% rule)\"\n          props:\n            - name: metric_key\n              value: disparate_impact\n            - name: threshold\n              value: \"0.8\"\n            - name: operator\n              value: \"&gt;\"\n            - name: \"input:dimension\"\n              value: gender\n            - name: \"input:target\"\n              value: target\n</code></pre> <p>Each control defines: - metric_key: What to measure (<code>disparate_impact</code>) - threshold: The limit (<code>0.8</code>) - operator: How to compare (<code>&gt;</code>) - inputs: Which columns to use</p>"},{"location":"quickstart/#whats-next","title":"What's Next?","text":"<ul> <li>API Reference - Full documentation</li> <li>Create your own policy - Copy the YAML above and modify thresholds</li> </ul>"},{"location":"training/","title":"Training Tutorial","text":"<p>Integrate fairness and performance checks into your ML workflow.</p>"},{"location":"training/#overview","title":"Overview","text":"<p>\ud83d\udcd3 Interactive Version: You can run this tutorial in a Jupyter Notebook: 01-training-tutorial.ipynb</p> Phase Check Function Pre-training Data bias <code>enforce(data=train_df)</code> Post-training Model fairness + Performance <code>enforce(data=test_df, prediction=pred)</code>"},{"location":"training/#step-1-load-and-prepare-data","title":"Step 1: Load and Prepare Data","text":"<p>Since the German Credit dataset contains categorical strings, we must encode them before training.</p> <pre><code>from ucimlrepo import fetch_ucirepo\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\n\n# Fetch UCI German Credit\ndataset = fetch_ucirepo(id=144)\ndf = dataset.data.features.copy()\ndf['class'] = dataset.data.targets\n\n# Split raw data for the audit\ntrain_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n\n# Encode data for Scikit-Learn training\ndf_encoded = pd.get_dummies(df.drop(columns=['class']))\nX_train, X_test, y_train, y_test = train_test_split(\n    df_encoded, \n    df['class'].values.ravel(), \n    test_size=0.2, \n    random_state=42\n)\n</code></pre>"},{"location":"training/#step-2-pre-training-audit-data-bias","title":"Step 2: Pre-Training Audit (Data Bias)","text":"<p>Check your training data for bias before starting the compute-heavy training phase.</p> <pre><code>import venturalitica as vl\n\nvl.enforce(\n    data=train_df,\n    target=\"class\",\n    gender=\"Attribute9\",  # Gender/Status column\n    age=\"Attribute13\",    # Age column\n    policy=\"loan-policy.yaml\"\n)\n</code></pre> <p>Real Output: <pre><code>[Venturalitica v0.2.4] \ud83d\udee1  Enforcing policy: loan-policy.yaml\n\n  CONTROL                DESCRIPTION                            ACTUAL     LIMIT      RESULT\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  imbalance              Minority ratio                         0.431      &gt; 0.2      \u2705 PASS\n  gender-bias            Disparate impact                       0.836      &gt; 0.8      \u2705 PASS\n  age-bias               Age disparity                          0.361      &gt; 0.5      \u274c FAIL\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  Audit Summary: \u274c VIOLATION | 2/3 controls passed\n</code></pre></p>"},{"location":"training/#step-3-train-and-evaluate","title":"Step 3: Train and Evaluate","text":"<pre><code>from sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\nmodel.fit(X_train, y_train)\n\n# Get predictions on test set\npredictions = model.predict(X_test)\n</code></pre>"},{"location":"training/#step-4-post-training-audit-fairness-performance","title":"Step 4: Post-Training Audit (Fairness + Performance)","text":"<p>Audit the model's behavior on unseen data.</p> <pre><code># Create audit dataframe (raw features + predictions)\ntest_audit_df = df.iloc[test_df.index].copy()\ntest_audit_df['prediction'] = predictions\n\nvl.enforce(\n    data=test_audit_df,\n    target=\"class\",\n    prediction=\"prediction\",\n    gender=\"Attribute9\",\n    age=\"Attribute13\",\n    policy=\"loan-policy.yaml\"\n)\n</code></pre> <p>Real Output: <pre><code>[Venturalitica v0.2.4] \ud83d\udee1  Enforcing policy: loan-policy.yaml\n\n  CONTROL                DESCRIPTION                            ACTUAL     LIMIT      RESULT\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  imbalance              Minority ratio                         0.418      &gt; 0.2      \u2705 PASS\n  gender-bias            Disparate impact                       0.905      &gt; 0.8      \u2705 PASS\n  age-bias               Age disparity                          0.600      &gt; 0.5      \u2705 PASS\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  Audit Summary: \u2705 POLICY MET | 3/3 controls passed\n</code></pre></p> <p>[!WARNING] While the training data failed the Age check (0.361), the model's predictions on the test set (0.600) managed to pass the policy limit (&gt;0.5). However, this improvement should be closely monitored to ensure it generalizes beyond this specific test slice.</p> <p>[!IMPORTANT] Why 0.361 vs 1.000?  If you see a perfect <code>1.000</code> but expect bias, check your column binding. If a column is missing or mismatched, Venturalitica may default to 1.0. Always verify your column names (like <code>Attribute9</code> vs <code>gender</code>) in the <code>enforce()</code> call. v0.2.4 also includes a minimum support filter (N&gt;=5) to ensure statistical significance, which contributes to the precise 0.361 reading.</p>"},{"location":"training/#step-5-including-performance-metrics","title":"Step 5: Including Performance Metrics","text":"<p>It makes perfect sense to audit performance alongside fairness. If you \"fix\" bias but destroy the model's utility (e.g., 20% accuracy), the system is still failing.</p> <p>You can define performance thresholds in the same policy:</p> <pre><code>- control-id: accuracy-threshold\n  description: \"Model must achieve at least 75% accuracy\"\n  props:\n    - name: metric_key\n      value: accuracy\n    - name: threshold\n      value: \"0.75\"\n    - name: operator\n      value: gt\n</code></pre> <p>Venturalitica supports: <code>accuracy</code>, <code>precision</code>, <code>recall</code>, and <code>f1</code>.</p> <p>Example Output with Performance: <pre><code>[Venturalitica v0.2.4] \ud83d\udee1  Enforcing policy: tutorial_policy.yaml\n\n  CONTROL                DESCRIPTION                            ACTUAL     LIMIT      RESULT\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  gender-disparate       Gender fairness (DI &gt; 0.8)             0.905      &gt; 0.8      \u2705 PASS\n  age-disparate          Age fairness (DI &gt; 0.5)                0.600      &gt; 0.5      \u2705 PASS\n  accuracy-check         Accuracy &gt; 70%                         0.795      &gt; 0.7      \u2705 PASS\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  Audit Summary: \u2705 POLICY MET | 3/3 controls passed\n</code></pre></p>"},{"location":"training/#step-6-automatic-governance-with-vlwrap-experimental","title":"Step 6: Automatic Governance with <code>vl.wrap</code> (Experimental)","text":"<p>[!WARNING] Experimental Feature: <code>vl.wrap</code> is currently in preview. Its API and behavior may change in future versions. Use with caution.</p> <p>If you are using Scikit-Learn, you can automate the entire audit process by wrapping your model. This ensures that every <code>.fit()</code> and <code>.predict()</code> call is audited against your policy.</p> <pre><code># Wrap your model\nbase_model = RandomForestClassifier(n_estimators=100, random_state=42)\ngoverned_model = vl.wrap(base_model, policy=\"loan-policy.yaml\")\n\n# Audits are automated! \n# Just provide the raw data for attribution mapping (e.g., gender, age)\ngoverned_model.fit(\n    X_train, y_train, \n    audit_data=train_df, \n    gender=\"Attribute9\", \n    age=\"Attribute13\"\n)\n\n# Predict also triggers the fairness + performance audit\npredictions = governed_model.predict(\n    X_test, \n    audit_data=test_df, \n    gender=\"Attribute9\", \n    age=\"Attribute13\"\n)\n</code></pre> <p>This pattern reduces boilerplate and guarantees that no model goes to production without a verified audit trail.</p>"},{"location":"training/#step-7-activating-evidence-collection","title":"Step 7: Activating Evidence Collection","text":"<p>Policy enforcement stops bad models, but Evidence Collection proves you followed the rules.</p> <p>To learn how to record these audits for the Article 12 Record-Keeping requirement, see the Evidence Collection Guide.</p>"},{"location":"tutorials/local-audit/","title":"Tutorial: Your First Local Audit","text":"<p>This tutorial demonstrates the \"Zero-Setup\" power of Venturalitica. You will audit a project folder without writing a single line of Python training code.</p> <p>Goal: Generate a compliance report for an existing project directory.</p>"},{"location":"tutorials/local-audit/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install the SDK:     <pre><code>pip install venturalitica\n</code></pre></li> <li>Have a project folder ready (e.g., <code>my-ml-project/</code>) containing some <code>.py</code> files and a <code>requirements.txt</code>.</li> </ol>"},{"location":"tutorials/local-audit/#step-1-scan-the-project","title":"Step 1: Scan the Project","text":"<p>The scanner acts like an automated auditor. It reads your file structure to inventory your \"Software Bill of Materials\" (SBOM).</p> <pre><code>cd my-ml-project\nventuralitica scan\n</code></pre> <p>Output: <pre><code>Scanning target: .\n\u2713 BOM generated: ./bom.json\nFound 42 components.\n</code></pre></p> <p>What just happened? *   Venturalitica parsed your dependencies (<code>numpy</code>, <code>pandas</code>, <code>scikit-learn</code>). *   It detected your ML models (e.g., <code>RandomForestClassifier</code>) by analyzing your source code (AST). *   It saved everything into a standard <code>bom.json</code> file.</p>"},{"location":"tutorials/local-audit/#step-2-launch-the-dashboard","title":"Step 2: Launch the Dashboard","text":"<p>Now that you have evidence (the SBOM), let's inspect it.</p> <pre><code>venturalitica ui\n</code></pre> <p>This opens the Compliance Dashboard in your browser (<code>http://localhost:8501</code>).</p> <p>What to look for: 1.  Navigate to Article 11 (Documentation). 2.  You should see your Software Bill of Materials marked as PRESENT. 3.  Check Article 15 (Security): Are there any known vulnerabilities in your dependencies?</p>"},{"location":"tutorials/local-audit/#step-3-generate-the-technical-file","title":"Step 3: Generate the Technical File","text":"<p>Finally, let's create the official document required by the EU AI Act (Annex IV).</p> <pre><code>venturalitica doc --output technical_file_draft.md\n</code></pre> <p>Output: <pre><code>\ud83d\udcc4 Generating Technical Documentation: technical_file_draft.md\n\u2713 Documentation draft created: technical_file_draft.md\n</code></pre></p> <p>Open <code>technical_file_draft.md</code>. You will see a structured template pre-filled with the data from your scan: *   System Description: Placeholders for you to fill. *   Technical Implementation: A list of the ML models and libraries detected in Step 1. *   Risk Management: Status of any fairness audits (if you had run <code>enforce</code> scripts).</p>"},{"location":"tutorials/local-audit/#summary","title":"Summary","text":"<p>In less than 2 minutes, you have: 1.  Inventoried your supply chain. 2.  Visualized your compliance status. 3.  Drafted your legal documentation.</p> <p>This is the Local First philosophy: immediate value, zero cloud dependency.</p>"}]}