{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Ventural\u00edtica","text":"<p>The Glass Box for High-Risk AI.</p> <p>Ventural\u00edtica transforms your Python code into Legal Evidence. It automatically maps your technical metrics, data audits, and execution logs to the EU AI Act (Articles 9-15) without leaving your local environment.</p>"},{"location":"#quickstart-in-60-seconds","title":"\u26a1\ufe0f Quickstart in 60 Seconds","text":"<p>Detect bias in your datasets or models with one line of code.</p> <pre><code>import venturalitica as vl\n\n# 1. Run Audit (Auto-Records Evidence)\nresults = vl.quickstart('loan')\n</code></pre> <p>Then, verify the results in the Glass Box Dashboard:</p> <pre><code>venturalitica ui\n</code></pre>"},{"location":"#key-features","title":"\ud83d\udee1 Key Features","text":"Feature Description TraceCollector Unified evidence gathering for BOM, metrics, and logs. Glass Box Sequential regulatory mapping (Art 9-15) for total transparency. Local Sovereignty Zero-cloud dependency. All enforcement runs locally. Bias Detection Quantitative fairness audits (Disparate Impact, Class Balance). Policy as Code Define governance rules in standard OSCAL/YAML formats. Annex IV Auto-draft technical documentation from local traces."},{"location":"#explore-tutorials","title":"\ud83d\udcda Explore Tutorials","text":"<p>Start with our interactive Jupyter notebooks:</p> <ul> <li>\u26a1\ufe0f Zero-Setup Audit - Run a full compliance scan on any project folder in 2 minutes.</li> <li>\ud83d\udee0\ufe0f Training Workflow - Learn how to audit data before training and verify models post-training.</li> <li>\ud83d\udcca Regulatory Mapping - Deep dive into how Ventural\u00edtica maps technical evidence to the EU AI Act.</li> </ul>"},{"location":"#installation","title":"\u2699\ufe0f Installation","text":"<pre><code>pip install git+https://github.com/Venturalitica/venturalitica-sdk.git\n</code></pre> <p>Quickstart Guide | Regulatory Map | API Reference</p>"},{"location":"#join-the-governance-revolution","title":"\ud83e\udd1d Join the Governance Revolution","text":"<p>Ventural\u00edtica is an open-source movement to bring transparency to AI.</p> <ul> <li>Have a specific compliance need? Check our Compliance Gap Roadmap.</li> <li>Found a bug or want to propose a feature? Open a GitHub Issue.</li> </ul> <p>\u00a9 2026 Ventural\u00edtica | Built for Responsible AI</p>"},{"location":"api/","title":"API Reference","text":"<p>Ventural\u00edtica provides a simple, unified interface for AI governance.</p>"},{"location":"api/#core-functions","title":"\ud83d\ude80 Core Functions","text":""},{"location":"api/#quickstartscenario-verbosetrue","title":"<code>quickstart(scenario, verbose=True)</code>","text":"<p>Run a pre-configured bias audit demo on a standard dataset.</p> Parameter Type Description <code>scenario</code> <code>str</code> Predefined scenario: <code>'loan'</code>, <code>'hiring'</code>, <code>'health'</code>. <code>verbose</code> <code>bool</code> Whether to print the structured table report to the console. <p>Returns: <code>List[ComplianceResult]</code></p>"},{"location":"api/#enforcedata-target-predictionnone-policynone-attributes","title":"<code>enforce(data, target, prediction=None, policy=None, **attributes)</code>","text":"<p>The main entry point for auditing datasets and models.</p> Parameter Type Description <code>data</code> <code>DataFrame</code> Pandas DataFrame containing features, targets, and optionally predictions. <code>target</code> <code>str</code> Name of the column with ground truth labels. <code>prediction</code> <code>str\\|array</code> (Optional) Column name or array of model predictions. <code>policy</code> <code>str</code> Path to the OSCAL/YAML policy file. <code>**attributes</code> <code>str</code> Mappings for protected variables (e.g., <code>gender=\"attr9\"</code>, <code>age=\"age_col\"</code>). <p>Returns: <code>List[ComplianceResult]</code></p> <p>Note</p> <p>If <code>prediction</code> is omitted, fairness metrics automatically fall back to using <code>target</code> to audit data bias.</p>"},{"location":"api/#wrapmodel-policy-experimental","title":"<code>wrap(model, policy)</code> (Experimental)","text":"<p>PREVIEW</p> <p>This function is experimental and its API might change.</p> <p>Transparently audit your model during Scikit-Learn standard workflows.</p> Parameter Type Description <code>model</code> <code>object</code> Any Scikit-learn compatible classifier or regressor. <code>policy</code> <code>str</code> Path to the policy for evaluation. <p>Returns: <code>GovernanceWrapper</code> (Preserves original API like <code>.fit()</code> and <code>.predict()</code>).</p>"},{"location":"api/#monitorname","title":"<code>monitor(name)</code>","text":"<p>A context manager to track training metrics, hardware health, and environmental impact.</p> <pre><code>with vl.monitor(name=\"CreditModel-v1\"):\n    model.fit(X, y)\n</code></pre> <p>Collected Telemetry:</p> <ul> <li>\u23f1 Duration: Execution time of the block.</li> <li>\ud83c\udf31 Emissions: Carbon footprint (requires <code>codecarbon</code>).</li> <li>\ud83d\udee1 Stability: Model fingerprinting and integrity verification.</li> </ul>"},{"location":"api/#utility-functions","title":"\ud83d\udee0 Utility Functions","text":""},{"location":"api/#list_scenarios","title":"<code>list_scenarios()</code>","text":"<p>Returns a dictionary of available scenarios and their descriptions.</p>"},{"location":"api/#load_samplescenario","title":"<code>load_sample(scenario)</code>","text":"<p>Loads the corresponding UCI dataset for a scenario as a Pandas DataFrame.</p>"},{"location":"compliance-dashboard/","title":"The Compliance Dashboard: A Glass Box for AI","text":"<p>The Ventural\u00edtica Compliance Dashboard is your local control center for AI Governance. Unlike \"Black Box\" compliance tools that operate behind closed doors, Ventural\u00edtica provides is a Glass Box experience: it exposes the exact technical evidence your system is producing and maps it directly to regulatory obligations.</p> <p>The dashboard makes the abstract concrete. It takes the invisible artifacts of your ML pipeline\u2014metrics, logs, dependencies\u2014and renders them into a Regulatory Traceability Matrix.</p>"},{"location":"compliance-dashboard/#the-sequential-regulatory-map-articles-9-15","title":"The Sequential Regulatory Map (Articles 9-15)","text":"<p>The core feature of the dashboard is the strict sequential mapping of the EU AI Act requirements for High-Risk AI Systems (Chapter III, Section 2). This \"Compliance Walk\" guides you through the lifecycle of a compliant system.</p>"},{"location":"compliance-dashboard/#the-traceability-flow","title":"The Traceability Flow","text":""},{"location":"compliance-dashboard/#1-article-9-risk-management-system","title":"1. Article 9: Risk Management System","text":"<ul> <li>The Law: You must identify and mitigate risks to health, safety, and fundamental rights.</li> <li>The Code: Ventural\u00edtica maps your Fairness Audits here. If you run a bias check (e.g., <code>gender-bias</code>), the result is the technical evidence that you are monitoring Fundamental Rights risks.</li> <li>Status:<ul> <li><code>Mitigation Verified</code>: Your fairness tests passed.</li> <li><code>Risk Materialized</code>: A test failed (e.g., Disparate Impact detected).</li> </ul> </li> </ul>"},{"location":"compliance-dashboard/#2-article-10-data-governance","title":"2. Article 10: Data Governance","text":"<ul> <li>The Law: Training, validation, and testing data must be relevant, representative, and error-free.</li> <li>The Code: Maps to your Data Quality Checks (e.g., class imbalance, missing values) and usage of data libraries (<code>pandas</code>, <code>numpy</code>).</li> <li>Status: Flags if data validation was skipped or failed.</li> </ul>"},{"location":"compliance-dashboard/#3-article-11-technical-documentation","title":"3. Article 11: Technical Documentation","text":"<ul> <li>The Law: You must maintain up-to-date technical documentation demonstrating conformity.</li> <li>The Code: Checks for the presence of your Software Bill of Materials (SBOM) (generated by <code>venturalitica scan</code>) and the Technical File Draft (generated by <code>venturalitica doc</code>).</li> <li>Status: Green if artifacts exist; Yellow/Red if documentation is missing.</li> </ul>"},{"location":"compliance-dashboard/#4-article-12-record-keeping","title":"4. Article 12: Record-Keeping","text":"<ul> <li>The Law: Automatic logging of events over the system's lifetime to ensure traceability.</li> <li>The Code: Verifies two critical components:<ul> <li>Cryptographic Anchoring: Displays the SHA-256 hash of your evidence, proving data integrity.</li> <li>Execution Traces: Confirms that runtime metadata (<code>runtime_meta</code>) was captured during training/inference.</li> </ul> </li> </ul>"},{"location":"compliance-dashboard/#5-article-13-transparency-information","title":"5. Article 13: Transparency &amp; Information","text":"<ul> <li>The Law: The system must be sufficiently transparent to allow users to interpret outputs.</li> <li>The Code: Checks for Code Opacity. Is the source code accessible for audit? Are instructions provided?</li> </ul>"},{"location":"compliance-dashboard/#6-article-14-human-oversight","title":"6. Article 14: Human Oversight","text":"<ul> <li>The Law: The system must be designed to be overseen by natural persons (human-in-the-loop).</li> <li>The Code: Scans for \"Stop Button\" logic or interactive interfaces (e.g., Streamlit apps, Jupyter notebooks) that imply human control capability.</li> </ul>"},{"location":"compliance-dashboard/#7-article-15-accuracy-robustness-cybersecurity","title":"7. Article 15: Accuracy, Robustness &amp; Cybersecurity","text":"<ul> <li>The Law: The system must be resilient to errors and attacks.</li> <li>The Code:<ul> <li>Accuracy: Maps to your Performance Metrics (Accuracy, F1, Recall).</li> <li>Cybersecurity: Checks for Supply Chain Vulnerabilities (CVEs) in your dependencies via the SBOM scan.</li> </ul> </li> </ul>"},{"location":"compliance-dashboard/#why-this-matters","title":"Why This Matters","text":"<p>This sequential layout transforms compliance from a chaotic checklist into a logical engineering workflow:</p> <ol> <li>Assess Risk (Art 9)</li> <li>Clean Data (Art 10)</li> <li>Document It (Art 11)</li> <li>Log It (Art 12)</li> <li>Explain It (Art 13)</li> <li>control It (Art 14)</li> <li>Secure It (Art 15)</li> </ol> <p>By following this flow, you are structurally aligning your AI system with the law, line by line.</p>"},{"location":"compliance-gap/","title":"The Compliance Gap (Roadmap)","text":"<p>Ventural\u00edtica v0.3 provides the foundation for Glass Box AI, but high-risk systems (EU AI Act) require continuous improvement. This document identifies the current technical gaps and the features required to turn \"Technical Evidence\" into \"Legal Certainty.\"</p>"},{"location":"compliance-gap/#missing-features-open-gaps","title":"\ud83d\udee0 Missing Features &amp; Open Gaps","text":""},{"location":"compliance-gap/#1-evidence-hardening-article-12","title":"1. Evidence Hardening (Article 12)","text":"<ul> <li>Current State: SHA-256 hashing of evidence files.</li> <li>The Gap: No native Digital Signing.</li> <li>Requirement: Implementation of GPG/X.509 signing for <code>trace.json</code> files to ensure non-repudiation in legal audits.</li> </ul>"},{"location":"compliance-gap/#2-deep-data-governance-article-10","title":"2. Deep Data Governance (Article 10)","text":"<ul> <li>Current State: Basic class balance and missing value checks.</li> <li>The Gap: Lack of Data Lineage and Annotation Provenance.</li> <li>Requirement: Tools to log the source of labels, inter-annotator agreement metrics, and \"poisoning\" detection for training sets.</li> </ul>"},{"location":"compliance-gap/#3-human-oversight-interactive-checks-article-14","title":"3. Human Oversight Interactive Checks (Article 14)","text":"<ul> <li>Current State: Static check for interactive elements (AST analysis).</li> <li>The Gap: No runtime verification of \"Human-in-the-loop\" (HITL) actions.</li> <li>Requirement: A <code>vl.oversight()</code> wrapper to record when a human actually approves/rejects a high-risk prediction.</li> </ul>"},{"location":"compliance-gap/#4-adversarial-robustness-article-15","title":"4. Adversarial Robustness (Article 15)","text":"<ul> <li>Current State: Performance metrics (Accuracy/F1).</li> <li>The Gap: No native Attack Scanners.</li> <li>Requirement: Integration with robustness libraries (e.g., ART, CleverHans) to automate adversarial testing as part of the <code>enforce()</code> pipeline.</li> </ul>"},{"location":"compliance-gap/#5-automated-bias-mitigation","title":"5. Automated Bias Mitigation","text":"<ul> <li>Current State: Detection only.</li> <li>The Gap: Friction in fixing detected bias.</li> <li>Requirement: Integration with Fairlearn/AIF360 for \"suggested mitigations\" directly in the Dashboard.</li> </ul>"},{"location":"compliance-gap/#propose-a-feature","title":"\ud83d\ude80 Propose a Feature","text":"<p>We are building the future of Responsible AI. If you have a specific requirement to fulfill a compliance mandate, we want to hear from you.</p> <ol> <li>Open a GitHub Issue.</li> <li>Tag it as <code>feature-request</code> + <code>compliance-gap</code>.</li> <li>Describe the Legal Article (e.g., Art 13) or Technical Pain you are addressing.</li> </ol> <p>View Roadmap Discussions</p>"},{"location":"evidence-collection/","title":"Evidence Collection: The Black Box Recorder","text":"<p>While Policies (the Enforcer) stop bad models from reaching production, Evidence Collection (the Recorder) ensures you can prove exactly what happened during training. This is your \"Black Box\" flight recorder for AI.</p> <p>In Ventural\u00edtica, evidence collection is distinct from policy enforcement. You can record evidence without blocking a deployment, or enforce strictly without saving traces. However, for full EU AI Act compliance (Article 12: Record-Keeping), you need both.</p>"},{"location":"evidence-collection/#two-ways-to-record","title":"Two Ways to Record","text":""},{"location":"evidence-collection/#1-the-automatic-wrapper-vlwrap","title":"1. The Automatic Wrapper (<code>vl.wrap</code>)","text":"<p>The easiest way to collect evidence is to wrap your estimator. This automatically hooks into <code>.fit()</code> and <code>.predict()</code> to capture inputs, outputs, and metadata.</p> <pre><code>import venturalitica as vl\nfrom sklearn.ensemble import RandomForestClassifier\n\n# 1. Wrap the model\nmodel = vl.wrap(RandomForestClassifier(), policy=\"my_policy.yaml\")\n\n# 2. Train as usual (Evidence is auto-collected)\nmodel.fit(X_train, y_train, audit_data=train_df, gender=\"sex\")\n</code></pre> <p>What is recorded? *   Timestamp: Precise start/end times. *   Model Config: Hyperparameters (<code>n_estimators</code>, <code>max_depth</code>, etc.). *   Data Shape: Number of rows/columns used. *   Code Context: The filename and AST analysis of the script that called <code>fit</code>.</p>"},{"location":"evidence-collection/#2-the-trace-collector-vltracecollector","title":"2. The Trace Collector (<code>vl.tracecollector</code>)","text":"<p>For custom training loops (e.g., PyTorch, TensorFlow) or complex pipelines where <code>fit()</code> isn't enough, use the context manager.</p> <pre><code>import venturalitica as vl\n\n# Start the recording session\nwith vl.tracecollector(\"custom_training_run\"):\n    # Your custom logic here\n    model = train_custom_model(data)\n    evaluate_model(model)\n\n# Evidence is saved to .venturalitica/trace_custom_training_run.json\n</code></pre>"},{"location":"evidence-collection/#where-does-the-evidence-go","title":"Where does the evidence go?","text":"<p>All evidence is secured locally in the <code>.venturalitica/</code> directory:</p> <ul> <li><code>results.json</code>: The outcome of your policy audits (Pass/Fail).</li> <li><code>trace_{name}.json</code>: The execution metadata (timestamps, code analysis).</li> <li><code>bom.json</code>: The software supply chain inventory (dependencies).</li> </ul>"},{"location":"evidence-collection/#compliance-impact","title":"Compliance Impact","text":"<p>For Article 12 (EU AI Act), this evidence is mandatory. The Ventural\u00edtica Dashboard reads these files to prove: 1.  Traceability: \"We know exactly which code and data produced Model v1.0.\" 2.  Integrity: \"The evidence has not been tampered with\" (via SHA-256 anchoring).</p> <p>View Your Traces</p> <p>After running your training script, launch the dashboard (<code>venturalitica ui</code>) to visualize these traces in the Article 12 section.</p>"},{"location":"quickstart/","title":"60-Second Quickstart","text":"<p>Goal: Your first bias audit in under 60 seconds.</p>"},{"location":"quickstart/#the-fundamentals-from-risk-to-code","title":"The Fundamentals: From Risk to Code","text":"<p>Building High-Risk AI requires a fundamental shift in how we approach testing. It is no longer enough to check for technical accuracy (e.g., F1 Score); we must now mathematically prove that the system respects fundamental rights, such as non-discrimination or data quality, as mandated by the EU AI Act.</p> <p>Ventural\u00edtica automates this by treating \"Governance\" as a dependency. Instead of vague legal requirements, you define strict policies (OSCAL) that your model must pass before it can be deployed. This turns compliance into a deterministic engineering problem.</p> <p>Is my System High-Risk?</p> <p>According to Article 6 of EU AI Act, a system is High-Risk if it is covered by Annex I (Safety Components like machinery/medical devices) or listed in Annex III (Biometrics, Critical Infrastructure, Education, Employment, Essential Services, Law Enforcement, Migration, Justice/Democracy).</p> <p>The Translation Layer:</p> <ol> <li> <p>Fundamental Risk: \"The model must not discriminate against protected groups\" (Art 9).</p> </li> <li> <p>Policy Control: \"Disparate Impact Ratio must be &gt; 0.8\".</p> </li> <li> <p>Code Assertion: <code>assert calculated_metric &gt; 0.8</code>.</p> </li> </ol> <p>When you run <code>quickstart()</code>, you are technically running a Unit Test for Ethics.</p>"},{"location":"quickstart/#step-1-install","title":"Step 1: Install","text":"<pre><code>pip install git+https://github.com/Venturalitica/venturalitica-sdk.git\n</code></pre>"},{"location":"quickstart/#step-2-run-your-first-audit","title":"Step 2: Run Your First Audit","text":"<pre><code>import venturalitica as vl\n\nvl.quickstart('loan')\n</code></pre> <p>Output:</p> <pre><code>[Ventural\u00edtica v0.3.0] \ud83c\udf93 Scenario: Credit Scoring Fairness\n[Ventural\u00edtica v0.3.0] \ud83d\udcca Loaded: UCI Dataset #144 (1000 samples)\n\n  CONTROL                DESCRIPTION                            ACTUAL     LIMIT      RESULT\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  credit-data-imbalance  Data Quality                           0.431      &gt; 0.2      \u2705 PASS\n  credit-data-bias       Disparate impact                       0.836      &gt; 0.8      \u2705 PASS\n  credit-age-disparate   Age disparity                          0.361      &gt; 0.5      \u274c FAIL\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  Audit Summary: \u274c VIOLATION | 2/3 controls passed\n</code></pre> <p>Info</p> <p>The audit detected age-based bias in the UCI German Credit dataset.</p>"},{"location":"quickstart/#step-3-whats-happening-under-the-hood","title":"Step 3: What's Happening Under the Hood","text":"<p>The <code>quickstart()</code> function is a wrapper that performs the full compliance lifecycle in one go:</p> <ol> <li>Downloads Data: Fetches the UCI German Credit dataset.  </li> <li>Loads Policy: Reads <code>risks.oscal.yaml</code> which defines the fairness rules.</li> <li>Enforces: Runs the audit (<code>vl.enforce</code>).</li> <li>Records: Captures the evidence (<code>trace.json</code>) for the dashboard.</li> </ol> <p>Here's the equivalent \"manual\" code:</p> <pre><code>from ucimlrepo import fetch_ucirepo\nimport venturalitica as vl\n\n# 1. Load Data (The \"Risk Source\")\ndataset = fetch_ucirepo(id=144)\ndf = dataset.data.features\ndf['class'] = dataset.data.targets\n\n# 2. Define the Policy (The \"Law\")\n# We load a pre-defined policies/risks.oscal.yaml\n\n# 3. Run the Audit (The \"Test\")\n# This automatically generates the Evidence Bill of Materials (BOM)\nwith vl.tracecollector(\"manual_audit\"):\n    vl.enforce(\n        data=df,\n        target=\"class\",          # The outcome (True/False)\n        gender=\"Attribute9\",     # Protected Group A\n        age=\"Attribute13\",       # Protected Group B\n        policy=\"risks.oscal.yaml\"\n    )\n</code></pre>"},{"location":"quickstart/#the-policy-logic","title":"The Policy Logic","text":"<p>The policy (<code>risks.oscal.yaml</code>) is the bridge. It tells the SDK what to check so you don't have to hardcode it.</p> <pre><code># ... inside the OSCAL YAML ...\n- control-id: credit-data-bias\n  description: \"Disparate impact ratio must be &gt; 0.8 (80% rule)\"\n  props:\n    - name: metric_key\n      value: disparate_impact   # &lt;--- The Python Function to call\n    - name: threshold\n      value: \"0.8\"              # &lt;--- The Limit to enforce\n    - name: operator\n      value: \"&gt;\"                # &lt;--- The Logic (&gt; 0.8)\n    - name: \"input:dimension\"\n      value: gender             # &lt;--- Maps to \"Attribute9\"\n</code></pre> <p>This design decouples Governance (the policy file) from Engineering (the python code).</p>"},{"location":"quickstart/#why-this-matters","title":"Why This Matters","text":"<p>Without this mechanism, your AI model is a legal \"Black Box\":</p> <ul> <li>Liability: You cannot prove you checked for bias before deployment (Art 9).</li> <li>Fragility: Compliance is a manual checklist, easily forgotten or skipped.</li> <li>Opacity: Auditors cannot see the link between your code and the law.</li> </ul> <p>By running <code>quickstart()</code>, you have just generated an immutable Compliance Artifact. Even if the laws change, your evidence remains.</p>"},{"location":"quickstart/#step-4-the-glass-box-dashboard","title":"Step 4: The \"Glass Box\" Dashboard \ud83d\udcca","text":"<p>Now that we have the evidence (the \"Black Box\" recording), let's inspect it in the Regulatory Map.</p> <pre><code>venturalitica ui\n</code></pre> <p>Navigate through the Compliance Map tabs:</p> <ul> <li>Article 9 (Risk): See the failed <code>credit-age-disparate</code> control. This is your technical evidence of \"Risk Monitoring\".</li> <li>Article 10 (Data): See the data distribution and quality checks.</li> <li>Article 13 (Transparency): Review the \"Transparency Feed\" to see your Python dependencies (BOM).</li> </ul>"},{"location":"quickstart/#step-5-generate-documentation-annex-iv","title":"Step 5: Generate Documentation (Annex IV) \ud83d\udcdd","text":"<p>The final step is to turn this evidence into a legal document.</p> <ol> <li>In the Dashboard, go to the \"Generation\" tab.</li> <li>Select \"English\" (or Spanish/Catalan/Euskera).</li> <li>Click \"Generate Annex IV\".</li> </ol> <p>Ventural\u00edtica will draft a technical document that references your specific run:</p> <p>\"As evidenced in <code>trace_quickstart_loan.json</code>, the system was audited against [OSCAL Policy: Credit Scoring Fairness]. A deviation was detected in Age Disparity (0.36), identifying a potential risk of bias...\"</p>"},{"location":"quickstart/#references","title":"References","text":"<ul> <li>Policy Used: <code>loan/risks.oscal.yaml</code></li> <li>Legal Basis:<ul> <li>EU AI Act Article 9 (Risk Management)</li> <li>EU AI Act Article 11 (Technical Documentation)</li> </ul> </li> </ul>"},{"location":"quickstart/#whats-next","title":"What's Next?","text":"<ul> <li>API Reference - Full documentation</li> <li>Create your own policy - Copy the YAML above and modify thresholds</li> </ul>"},{"location":"training/","title":"\ud83d\udee0\ufe0f Model Training Integration (Ventural\u00edtica)","text":"<p>Integrate fairness and performance checks into your ML workflow with Ventural\u00edtica.</p>"},{"location":"training/#overview","title":"Overview","text":"<p>Interactive Version</p> <p>You can run this tutorial in a Jupyter Notebook: 01-training-tutorial.ipynb</p> Phase Check Function Pre-training Data bias <code>enforce(data=train_df)</code> Post-training Model fairness + Performance <code>enforce(data=test_df, prediction=pred)</code>"},{"location":"training/#step-1-load-and-prepare-data","title":"Step 1: Load and Prepare Data","text":"<p>Since the German Credit dataset contains categorical strings, we must encode them before training.</p> <pre><code>from ucimlrepo import fetch_ucirepo\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\n\n# Fetch UCI German Credit\ndataset = fetch_ucirepo(id=144)\ndf = dataset.data.features.copy()\ndf['class'] = dataset.data.targets\n\n# Split raw data for the audit\ntrain_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n\n# Encode data for Scikit-Learn training\ndf_encoded = pd.get_dummies(df.drop(columns=['class']))\nX_train, X_test, y_train, y_test = train_test_split(\n    df_encoded, \n    df['class'].values.ravel(), \n    test_size=0.2, \n    random_state=42\n)\n</code></pre>"},{"location":"training/#step-2-pre-training-audit-data-bias","title":"Step 2: Pre-Training Audit (Data Bias)","text":"<p>Check your training data for bias before starting the compute-heavy training phase.</p> <p>Why do we need <code>tracecollector</code>?</p> <p>Compliance requires proof. Use <code>vl.tracecollector</code> to record the \"Code Story\" (BOM, Headers) along with the audit results. This is required for Annex IV generation.</p> <pre><code>import venturalitica as vl\n\n# Start the 'evidence recorder'\nwith vl.tracecollector(\"training_audit\"):\n\n    # Run the Data Audit\n    vl.enforce(\n        data=train_df,\n        target=\"class\",\n        gender=\"Attribute9\",  # Gender/Status column\n        age=\"Attribute13\",    # Age column\n        policy=\"loan-policy.yaml\"\n    )\n</code></pre> <p>Real Output: <pre><code>[Ventural\u00edtica v0.3.0] \ud83d\ude80 TraceCollector [training_audit] starting...\n[Ventural\u00edtica v0.3.0] \ud83d\udee1  Enforcing policy: loan-policy.yaml\n\n  CONTROL                DESCRIPTION                            ACTUAL     LIMIT      RESULT\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  imbalance              Minority ratio                         0.431      &gt; 0.2      \u2705 PASS\n  gender-bias            Disparate impact                       0.836      &gt; 0.8      \u2705 PASS\n  age-bias               Age disparity                          0.361      &gt; 0.5      \u274c FAIL\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  Audit Summary: \u274c VIOLATION | 2/3 controls passed\n\n  \u2705 TraceCollector [training_audit] evidence saved to .venturalitica/trace_training_audit.json\n</code></pre></p>"},{"location":"training/#step-3-train-and-evaluate","title":"Step 3: Train and Evaluate","text":"<pre><code>from sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\nmodel.fit(X_train, y_train)\n\n# Get predictions on test set\npredictions = model.predict(X_test)\n</code></pre>"},{"location":"training/#step-4-post-training-audit-fairness-performance","title":"Step 4: Post-Training Audit (Fairness + Performance)","text":"<p>Audit the model's behavior on unseen data. We reuse the same trace collector (or start a new one) to capture this phase.</p> <pre><code># Create audit dataframe (raw features + predictions)\ntest_audit_df = df.iloc[test_df.index].copy()\ntest_audit_df['prediction'] = predictions\n\nwith vl.tracecollector(\"model_eval\"):\n    vl.enforce(\n        data=test_audit_df,\n        target=\"class\",\n        prediction=\"prediction\",\n        gender=\"Attribute9\",\n        age=\"Attribute13\",\n        policy=\"loan-policy.yaml\"\n    )\n</code></pre> <p>Real Output: <pre><code>[Ventural\u00edtica v0.3.0] \ud83d\udee1  Enforcing policy: loan-policy.yaml\n\n  CONTROL                DESCRIPTION                            ACTUAL     LIMIT      RESULT\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  imbalance              Minority ratio                         0.418      &gt; 0.2      \u2705 PASS\n  gender-bias            Disparate impact                       0.905      &gt; 0.8      \u2705 PASS\n  age-bias               Age disparity                          0.600      &gt; 0.5      \u2705 PASS\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  Audit Summary: \u2705 POLICY MET | 3/3 controls passed\n</code></pre></p> <p>Warning</p> <p>While the training data failed the Age check (0.361), the model's predictions on the test set (0.600) managed to pass the policy limit (&gt;0.5). However, this improvement should be closely monitored to ensure it generalizes beyond this specific test slice.</p> <p>Why 0.361 vs 1.000?</p> <p>If you see a perfect <code>1.000</code> but expect bias, check your column binding. If a column is missing or mismatched, Ventural\u00edtica may default to 1.0. Always verify your column names (like <code>Attribute9</code> vs <code>gender</code>) in the <code>enforce()</code> call. v0.3.0 also includes a minimum support filter (N&gt;=5) to ensure statistical significance, which contributes to the precise 0.361 reading.</p>"},{"location":"training/#step-5-including-performance-metrics","title":"Step 5: Including Performance Metrics","text":"<p>It makes perfect sense to audit performance alongside fairness. If you \"fix\" bias but destroy the model's utility (e.g., 20% accuracy), the system is still failing.</p> <p>You can define performance thresholds in the same policy:</p> <pre><code>- control-id: accuracy-threshold\n  description: \"Model must achieve at least 75% accuracy\"\n  props:\n    - name: metric_key\n      value: accuracy\n    - name: threshold\n      value: \"0.75\"\n    - name: operator\n      value: gt\n</code></pre> <p>Ventural\u00edtica supports: <code>accuracy</code>, <code>precision</code>, <code>recall</code>, and <code>f1</code>.</p> <p>Example Output with Performance: <pre><code>[Ventural\u00edtica v0.3.0] \ud83d\udee1  Enforcing policy: tutorial_policy.yaml\n\n  CONTROL                DESCRIPTION                            ACTUAL     LIMIT      RESULT\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  gender-disparate       Gender fairness (DI &gt; 0.8)             0.905      &gt; 0.8      \u2705 PASS\n  age-disparate          Age fairness (DI &gt; 0.5)                0.600      &gt; 0.5      \u2705 PASS\n  accuracy-check         Accuracy &gt; 70%                         0.795      &gt; 0.7      \u2705 PASS\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  Audit Summary: \u2705 POLICY MET | 3/3 controls passed\n</code></pre></p>"},{"location":"training/#step-6-automatic-governance-with-vlwrap-experimental","title":"Step 6: Automatic Governance with <code>vl.wrap</code> (Experimental)","text":"<p>Experimental Feature</p> <p><code>vl.wrap</code> is currently in preview. Its API and behavior may change in future versions. Use with caution.</p> <p>If you are using Scikit-Learn, you can automate the entire audit process by wrapping your model. This ensures that every <code>.fit()</code> and <code>.predict()</code> call is audited against your policy.</p> <pre><code># Wrap your model\nbase_model = RandomForestClassifier(n_estimators=100, random_state=42)\ngoverned_model = vl.wrap(base_model, policy=\"loan-policy.yaml\") # Ventural\u00edtica Governance\n\n# Audits are automated! \n# Just provide the raw data for attribution mapping (e.g., gender, age)\ngoverned_model.fit(\n    X_train, y_train, \n    audit_data=train_df, \n    gender=\"Attribute9\", \n    age=\"Attribute13\"\n)\n\n# Predict also triggers the fairness + performance audit\npredictions = governed_model.predict(\n    X_test, \n    audit_data=test_df, \n    gender=\"Attribute9\", \n    age=\"Attribute13\"\n)\n</code></pre> <p>This pattern reduces boilerplate and guarantees that no model goes to production without a verified audit trail.</p>"},{"location":"training/#step-7-view-evidence-in-dashboard","title":"Step 7: View Evidence in Dashboard","text":"<p>Now that you have run the training and evaluation with <code>tracecollector</code>, you have generated the artifacts required for the EU AI Act.</p> <p>Inspect them in the Glass Box Dashboard:</p> <pre><code>venturalitica ui\n</code></pre> <p>This will launch the local server where you can see:</p> <ul> <li>Article 9: Your Fairness &amp; Performance Audit results.</li> <li>Article 13: The BOM of your training environment.</li> <li>Generation: The draft of your technical documentation.</li> </ul>"}]}