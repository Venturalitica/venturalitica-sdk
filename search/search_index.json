{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Venturalitica","text":"<p>Frictionless Governance for AI.</p> <p>Venturalitica is a lightweight Python SDK designed to enforce policies, audit fairness, and track environmental impact in your ML workflows with zero friction.</p>"},{"location":"#quickstart-in-60-seconds","title":"\u26a1\ufe0f Quickstart in 60 Seconds","text":"<p>Detect bias in your datasets or models with one line of code.</p> <pre><code>import venturalitica as vl\n\n# Auto-download UCI data, load policy, and run bias audit\nresults = vl.quickstart('loan')\n</code></pre>"},{"location":"#key-features","title":"\ud83d\udee1 Key Features","text":"Feature Description Bias Detection Quantitative fairness audits (Disparate Impact, Class Balance). Integrity Checks Immutable audit trails and model fingerprints. Green AI Native carbon emission and energy consumption tracking. Policy as Code Define governance rules in standard OSCAL/YAML formats. Framework Agnostic Works with Scikit-learn, PyTorch, TensorFlow, and more."},{"location":"#explore-tutorials","title":"\ud83d\udcda Explore Tutorials","text":"<p>Start with our interactive Jupyter notebooks:</p> <ul> <li>00: Quickstart - Fast one-liner audit on the German Credit dataset.</li> <li>01: Training Workflow - Learn how to audit data before training and verify models post-training.</li> </ul>"},{"location":"#installation","title":"\u2699\ufe0f Installation","text":"<pre><code>pip install venturalitica\n</code></pre> <p>Quickstart Guide | API Reference | GitHub</p> <p>\u00a9 2026 Venturalitica | Built for Responsible AI</p>"},{"location":"api/","title":"API Reference","text":"<p>Venturalitica provides a simple, unified interface for AI governance.</p>"},{"location":"api/#core-functions","title":"\ud83d\ude80 Core Functions","text":""},{"location":"api/#quickstartscenario-verbosetrue","title":"<code>quickstart(scenario, verbose=True)</code>","text":"<p>Run a pre-configured bias audit demo on a standard dataset.</p> Parameter Type Description <code>scenario</code> <code>str</code> Predefined scenario: <code>'loan'</code>, <code>'hiring'</code>, <code>'health'</code>. <code>verbose</code> <code>bool</code> Whether to print the structured table report to the console. <p>Returns: <code>List[ComplianceResult]</code></p>"},{"location":"api/#enforcedata-target-predictionnone-policynone-attributes","title":"<code>enforce(data, target, prediction=None, policy=None, **attributes)</code>","text":"<p>The main entry point for auditing datasets and models.</p> Parameter Type Description <code>data</code> <code>DataFrame</code> Pandas DataFrame containing features, targets, and optionally predictions. <code>target</code> <code>str</code> Name of the column with ground truth labels. <code>prediction</code> <code>str\\|array</code> (Optional) Column name or array of model predictions. <code>policy</code> <code>str</code> Path to the OSCAL/YAML policy file. <code>**attributes</code> <code>str</code> Mappings for protected variables (e.g., <code>gender=\"attr9\"</code>, <code>age=\"age_col\"</code>). <p>Returns: <code>List[ComplianceResult]</code></p> <p>[!NOTE] If <code>prediction</code> is omitted, fairness metrics automatically fall back to using <code>target</code> to audit data bias.</p>"},{"location":"api/#wrapmodel-policy","title":"<code>wrap(model, policy)</code>","text":"<p>Transparently audit your model during Scikit-Learn standard workflows.</p> Parameter Type Description <code>model</code> <code>object</code> Any Scikit-learn compatible classifier or regressor. <code>policy</code> <code>str</code> Path to the policy for evaluation. <p>Returns: <code>GovernanceWrapper</code> (Preserves original API like <code>.fit()</code> and <code>.predict()</code>).</p>"},{"location":"api/#monitorname","title":"<code>monitor(name)</code>","text":"<p>A context manager to track training metrics, hardware health, and environmental impact.</p> <pre><code>with vl.monitor(name=\"CreditModel-v1\"):\n    model.fit(X, y)\n</code></pre> <p>Collected Telemetry: - \u23f1 Duration: Execution time of the block. - \ud83c\udf31 Emissions: Carbon footprint (requires <code>codecarbon</code>). - \ud83d\udee1 Stability: Model fingerprinting and integrity verification.</p>"},{"location":"api/#utility-functions","title":"\ud83d\udee0 Utility Functions","text":""},{"location":"api/#list_scenarios","title":"<code>list_scenarios()</code>","text":"<p>Returns a dictionary of available scenarios and their descriptions.</p>"},{"location":"api/#load_samplescenario","title":"<code>load_sample(scenario)</code>","text":"<p>Loads the corresponding UCI dataset for a scenario as a Pandas DataFrame.</p>"},{"location":"quickstart/","title":"60-Second Quickstart","text":"<p>Goal: Your first bias audit in under 60 seconds.</p>"},{"location":"quickstart/#step-1-install","title":"Step 1: Install","text":"<pre><code>pip install venturalitica\n</code></pre>"},{"location":"quickstart/#step-2-run-your-first-audit","title":"Step 2: Run Your First Audit","text":"<pre><code>import venturalitica as vl\n\nvl.quickstart('loan')\n</code></pre> <p>Output:</p> <pre><code>[Venturalitica v0.2.4] \ud83c\udf93 Scenario: Credit Scoring Fairness\n[Venturalitica v0.2.4] \ud83d\udcca Loaded: UCI Dataset #144 (1000 samples)\n\n  CONTROL                DESCRIPTION                            ACTUAL     LIMIT      RESULT\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  credit-data-imbalance  Data Quality                           0.431      &gt; 0.2      \u2705 PASS\n  credit-data-bias       Disparate impact                       0.836      &gt; 0.8      \u2705 PASS\n  credit-age-disparate   Age disparity                          0.361      &gt; 0.5      \u274c FAIL\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  Audit Summary: \u274c VIOLATION | 2/3 controls passed\n</code></pre> <p>\ud83d\udca1 The audit detected age-based bias in the UCI German Credit dataset.</p>"},{"location":"quickstart/#step-3-whats-happening-under-the-hood","title":"Step 3: What's Happening Under the Hood","text":"<p>The <code>quickstart()</code> function is a wrapper that:</p> <ol> <li>Downloads data from UCI Machine Learning Repository</li> <li>Loads a policy that defines fairness rules</li> <li>Calls <code>enforce()</code> to run the audit</li> </ol> <p>Here's the equivalent code:</p> <pre><code>from ucimlrepo import fetch_ucirepo\nimport venturalitica as vl\n\n# 1. Load UCI German Credit dataset\ndataset = fetch_ucirepo(id=144)\ndf = dataset.data.features\ndf['class'] = dataset.data.targets\n\n# 2. Run audit with policy\nvl.enforce(\n    data=df,\n    target=\"class\",\n    gender=\"Attribute9\",\n    age=\"Attribute13\",\n    policy=\"risks.oscal.yaml\"\n)\n</code></pre>"},{"location":"quickstart/#the-policy-file","title":"The Policy File","text":"<p>The policy (<code>risks.oscal.yaml</code>) defines the rules:</p> <pre><code>assessment-plan:\n  uuid: credit-risk-policy\n  metadata:\n    title: \"Credit Scoring Fairness\"\n  reviewed-controls:\n    control-selections:\n      - include-controls:\n        - control-id: credit-data-bias\n          description: \"Disparate impact ratio must be &gt; 0.8 (80% rule)\"\n          props:\n            - name: metric_key\n              value: disparate_impact\n            - name: threshold\n              value: \"0.8\"\n            - name: operator\n              value: \"&gt;\"\n            - name: \"input:dimension\"\n              value: gender\n            - name: \"input:target\"\n              value: target\n</code></pre> <p>Each control defines: - metric_key: What to measure (<code>disparate_impact</code>) - threshold: The limit (<code>0.8</code>) - operator: How to compare (<code>&gt;</code>) - inputs: Which columns to use</p>"},{"location":"quickstart/#whats-next","title":"What's Next?","text":"<ul> <li>API Reference - Full documentation</li> <li>Create your own policy - Copy the YAML above and modify thresholds</li> </ul>"},{"location":"training/","title":"Training Tutorial","text":"<p>Integrate fairness and performance checks into your ML workflow.</p>"},{"location":"training/#overview","title":"Overview","text":"<p>\ud83d\udcd3 Interactive Version: You can run this tutorial in a Jupyter Notebook: 01-training-tutorial.ipynb</p> Phase Check Function Pre-training Data bias <code>enforce(data=train_df)</code> Post-training Model fairness + Performance <code>enforce(data=test_df, prediction=pred)</code>"},{"location":"training/#step-1-load-and-prepare-data","title":"Step 1: Load and Prepare Data","text":"<p>Since the German Credit dataset contains categorical strings, we must encode them before training.</p> <pre><code>from ucimlrepo import fetch_ucirepo\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\n\n# Fetch UCI German Credit\ndataset = fetch_ucirepo(id=144)\ndf = dataset.data.features.copy()\ndf['class'] = dataset.data.targets\n\n# Split raw data for the audit\ntrain_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n\n# Encode data for Scikit-Learn training\ndf_encoded = pd.get_dummies(df.drop(columns=['class']))\nX_train, X_test, y_train, y_test = train_test_split(\n    df_encoded, \n    df['class'].values.ravel(), \n    test_size=0.2, \n    random_state=42\n)\n</code></pre>"},{"location":"training/#step-2-pre-training-audit-data-bias","title":"Step 2: Pre-Training Audit (Data Bias)","text":"<p>Check your training data for bias before starting the compute-heavy training phase.</p> <pre><code>import venturalitica as vl\n\nvl.enforce(\n    data=train_df,\n    target=\"class\",\n    gender=\"Attribute9\",  # Gender/Status column\n    age=\"Attribute13\",    # Age column\n    policy=\"loan-policy.yaml\"\n)\n</code></pre> <p>Real Output: <pre><code>[Venturalitica v0.2.4] \ud83d\udee1  Enforcing policy: loan-policy.yaml\n\n  CONTROL                DESCRIPTION                            ACTUAL     LIMIT      RESULT\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  imbalance              Minority ratio                         0.431      &gt; 0.2      \u2705 PASS\n  gender-bias            Disparate impact                       0.836      &gt; 0.8      \u2705 PASS\n  age-bias               Age disparity                          0.361      &gt; 0.5      \u274c FAIL\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  Audit Summary: \u274c VIOLATION | 2/3 controls passed\n</code></pre></p>"},{"location":"training/#step-3-train-and-evaluate","title":"Step 3: Train and Evaluate","text":"<pre><code>from sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\nmodel.fit(X_train, y_train)\n\n# Get predictions on test set\npredictions = model.predict(X_test)\n</code></pre>"},{"location":"training/#step-4-post-training-audit-fairness-performance","title":"Step 4: Post-Training Audit (Fairness + Performance)","text":"<p>Audit the model's behavior on unseen data.</p> <pre><code># Create audit dataframe (raw features + predictions)\ntest_audit_df = df.iloc[test_df.index].copy()\ntest_audit_df['prediction'] = predictions\n\nvl.enforce(\n    data=test_audit_df,\n    target=\"class\",\n    prediction=\"prediction\",\n    gender=\"Attribute9\",\n    age=\"Attribute13\",\n    policy=\"loan-policy.yaml\"\n)\n</code></pre> <p>Real Output: <pre><code>[Venturalitica v0.2.4] \ud83d\udee1  Enforcing policy: loan-policy.yaml\n\n  CONTROL                DESCRIPTION                            ACTUAL     LIMIT      RESULT\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  imbalance              Minority ratio                         0.418      &gt; 0.2      \u2705 PASS\n  gender-bias            Disparate impact                       0.905      &gt; 0.8      \u2705 PASS\n  age-bias               Age disparity                          0.600      &gt; 0.5      \u2705 PASS\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  Audit Summary: \u2705 POLICY MET | 3/3 controls passed\n</code></pre></p> <p>[!WARNING] While the training data failed the Age check (0.361), the model's predictions on the test set (0.600) managed to pass the policy limit (&gt;0.5). However, this improvement should be closely monitored to ensure it generalizes beyond this specific test slice.</p> <p>[!IMPORTANT] Why 0.361 vs 1.000?  If you see a perfect <code>1.000</code> but expect bias, check your column binding. If a column is missing or mismatched, Venturalitica may default to 1.0. Always verify your column names (like <code>Attribute9</code> vs <code>gender</code>) in the <code>enforce()</code> call. v0.2.4 also includes a minimum support filter (N&gt;=5) to ensure statistical significance, which contributes to the precise 0.361 reading.</p>"},{"location":"training/#step-5-including-performance-metrics","title":"Step 5: Including Performance Metrics","text":"<p>It makes perfect sense to audit performance alongside fairness. If you \"fix\" bias but destroy the model's utility (e.g., 20% accuracy), the system is still failing.</p> <p>You can define performance thresholds in the same policy:</p> <pre><code>- control-id: accuracy-threshold\n  description: \"Model must achieve at least 75% accuracy\"\n  props:\n    - name: metric_key\n      value: accuracy\n    - name: threshold\n      value: \"0.75\"\n    - name: operator\n      value: gt\n</code></pre> <p>Venturalitica supports: <code>accuracy</code>, <code>precision</code>, <code>recall</code>, and <code>f1</code>.</p> <p>Example Output with Performance: <pre><code>[Venturalitica v0.2.4] \ud83d\udee1  Enforcing policy: tutorial_policy.yaml\n\n  CONTROL                DESCRIPTION                            ACTUAL     LIMIT      RESULT\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  gender-disparate       Gender fairness (DI &gt; 0.8)             0.905      &gt; 0.8      \u2705 PASS\n  age-disparate          Age fairness (DI &gt; 0.5)                0.600      &gt; 0.5      \u2705 PASS\n  accuracy-check         Accuracy &gt; 70%                         0.795      &gt; 0.7      \u2705 PASS\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  Audit Summary: \u2705 POLICY MET | 3/3 controls passed\n</code></pre></p>"}]}