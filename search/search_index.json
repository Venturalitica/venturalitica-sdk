{"config":{"lang":["en","es"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Ventural\u00edtica","text":"<p>The Glass Box for High-Risk AI.</p> <p>Ventural\u00edtica transforms your Python code into Legal Evidence. It automatically maps your technical metrics, data audits, and execution logs to the EU AI Act (Articles 9-15) without leaving your local environment.</p>"},{"location":"#quickstart-in-60-seconds","title":"\u26a1\ufe0f Quickstart in 60 Seconds","text":"<p>Detect bias in your datasets or models with one line of code.</p> <pre><code>import venturalitica as vl\n\n# 1. Run Audit (Auto-Records Evidence)\nresults = vl.quickstart('loan')\n</code></pre> <p>Then, verify the results in the Glass Box Dashboard:</p> <pre><code>venturalitica ui\n</code></pre>"},{"location":"#key-features","title":"\ud83d\udee1 Key Features","text":"Feature Description TraceCollector Unified evidence gathering for BOM, metrics, and logs. Glass Box Sequential regulatory mapping (Art 9-15) for total transparency. Local Sovereignty Zero-cloud dependency. All enforcement runs locally. Bias Detection Quantitative fairness audits (Disparate Impact, Class Balance). Policy as Code Define governance rules in standard OSCAL/YAML formats. Annex IV Auto-draft technical documentation from local traces."},{"location":"#explore-tutorials","title":"\ud83d\udcda Explore Tutorials","text":"<p>Start with our interactive Jupyter notebooks:</p> <ul> <li>\u26a1\ufe0f Zero-Setup Audit - Run a full compliance scan on any project folder in 2 minutes.</li> <li>\ud83d\udee0\ufe0f Training Workflow - Learn how to audit data before training and verify models post-training.</li> <li>\ud83d\udcca Regulatory Mapping - Deep dive into how Ventural\u00edtica maps technical evidence to the EU AI Act.</li> </ul>"},{"location":"#installation","title":"\u2699\ufe0f Installation","text":"<pre><code>pip install git+https://github.com/Venturalitica/venturalitica-sdk.git\n</code></pre> <p>Quickstart Guide | Regulatory Map | API Reference</p>"},{"location":"#join-the-governance-revolution","title":"\ud83e\udd1d Join the Governance Revolution","text":"<p>Ventural\u00edtica is an open-source movement to bring transparency to AI.</p> <ul> <li>Have a specific compliance need? Check our Compliance Gap Roadmap.</li> <li>Found a bug or want to propose a feature? Open a GitHub Issue.</li> </ul> <p>\u00a9 2026 Ventural\u00edtica | Built for Responsible AI</p>"},{"location":"annex-iv/","title":"Generating Technical Documentation (Annex IV)","text":"<p>One of the most tedious parts of the EU AI Act is Annex IV: the requirement to maintain up-to-date technical documentation.</p> <p>Ventural\u00edtica automates this by treating your code execution traces as the source of truth.</p>"},{"location":"annex-iv/#the-annex-iv-generator","title":"The Annex IV Generator","text":"<p>You can generate a compliant draft of your Technical Documentation directly from the Ventural\u00edtica Dashboard.</p>"},{"location":"annex-iv/#step-1-launch-the-dashboard","title":"Step 1: Launch the Dashboard","text":"<p>Run the UI from your terminal in the root of your project:</p> <pre><code>venturalitica ui\n</code></pre>"},{"location":"annex-iv/#step-2-navigate-to-annex-iv-generator","title":"Step 2: Navigate to \"Annex IV Generator\"","text":"<ol> <li>Go to the \"Annex IV Generator\" tab in the top navigation.</li> <li>Select your Inference Provider:<ul> <li>Local (Ollama): Standard offline mode.</li> <li>Cloud (Mistral): High-quality, EU-hosted generation.</li> <li>Local (ALIA - Experimental): Spanish Sovereign model (Requires significant hardware).</li> </ul> </li> <li>Click \"Generate Annex IV\".</li> </ol> <p>The system will analyze your local <code>.venturalitica/</code> folder and pull:     *   System Architecture (from <code>bom.json</code>)     *   Risk Management Status (from Article 9 Audit Results)     *   Data Governance (from Article 10 Audit Results)     *   Cybersecurity (from CVE scans)</p>"},{"location":"annex-iv/#step-3-download-the-draft","title":"Step 3: Download the Draft","text":"<p>You will see a live preview of the generated markdown file.</p> <ul> <li>Click Download Draft to save it as <code>Annex_IV_Draft.md</code>.</li> <li>You can then convert this Markdown file to PDF using your preferred tool (e.g., Pandoc or VS Code).</li> </ul> <p>Dynamic Updates</p> <p>Each time you run <code>vl.enforce()</code>, the underlying evidence updates. Generating a new report will always reflect the latest state of your system.</p>"},{"location":"annex-iv/#via-cli-alternative","title":"Via CLI (Alternative)","text":"<p>For CI/CD pipelines, you can also generate this documentation without opening the UI:</p> <pre><code>venturalitica doc --output docs/technical_file.md\n</code></pre> <p>This command performs the same logic but saves the file directly to your specified path.</p>"},{"location":"api/","title":"API Reference","text":"<p>Ventural\u00edtica provides a simple, unified interface for AI governance.</p>"},{"location":"api/#core-functions","title":"\ud83d\ude80 Core Functions","text":""},{"location":"api/#quickstartscenario-verbosetrue","title":"<code>quickstart(scenario, verbose=True)</code>","text":"<p>Run a pre-configured bias audit demo on a standard dataset.</p> Parameter Type Description <code>scenario</code> <code>str</code> Predefined scenario: <code>'loan'</code>, <code>'hiring'</code>, <code>'health'</code>. <code>verbose</code> <code>bool</code> Whether to print the structured table report to the console. <p>Returns: <code>List[ComplianceResult]</code></p>"},{"location":"api/#enforcedata-target-predictionnone-policynone-attributes","title":"<code>enforce(data, target, prediction=None, policy=None, **attributes)</code>","text":"<p>The main entry point for auditing datasets and models.</p> Parameter Type Description <code>data</code> <code>DataFrame</code> Pandas DataFrame containing features, targets, and optionally predictions. <code>target</code> <code>str</code> Name of the column with ground truth labels. <code>prediction</code> <code>str\\|array</code> (Optional) Column name or array of model predictions. <code>policy</code> <code>str</code> Path to the OSCAL/YAML policy file. <code>**attributes</code> <code>str</code> Mappings for protected variables (e.g., <code>gender=\"attr9\"</code>, <code>age=\"age_col\"</code>). <p>Returns: <code>List[ComplianceResult]</code></p> <p>Note</p> <p>If <code>prediction</code> is omitted, fairness metrics automatically fall back to using <code>target</code> to audit data bias.</p>"},{"location":"api/#wrapmodel-policy-experimental","title":"<code>wrap(model, policy)</code> (Experimental)","text":"<p>PREVIEW</p> <p>This function is experimental and its API might change.</p> <p>Transparently audit your model during Scikit-Learn standard workflows.</p> Parameter Type Description <code>model</code> <code>object</code> Any Scikit-learn compatible classifier or regressor. <code>policy</code> <code>str</code> Path to the policy for evaluation. <p>Returns: <code>GovernanceWrapper</code> (Preserves original API like <code>.fit()</code> and <code>.predict()</code>).</p>"},{"location":"api/#monitorname","title":"<code>monitor(name)</code>","text":"<p>A context manager to track training metrics, hardware health, and environmental impact.</p> <pre><code>with vl.monitor(name=\"CreditModel-v1\"):\n    model.fit(X, y)\n</code></pre> <p>Collected Telemetry:</p> <ul> <li>\u23f1 Duration: Execution time of the block.</li> <li>\ud83c\udf31 Emissions: Carbon footprint (requires <code>codecarbon</code>).</li> <li>\ud83d\udee1 Stability: Model fingerprinting and integrity verification.</li> </ul>"},{"location":"api/#utility-functions","title":"\ud83d\udee0 Utility Functions","text":""},{"location":"api/#list_scenarios","title":"<code>list_scenarios()</code>","text":"<p>Returns a dictionary of available scenarios and their descriptions.</p>"},{"location":"api/#load_samplescenario","title":"<code>load_sample(scenario)</code>","text":"<p>Loads the corresponding UCI dataset for a scenario as a Pandas DataFrame.</p>"},{"location":"compliance-dashboard/","title":"The Compliance Dashboard: A Glass Box for AI","text":"<p>The Ventural\u00edtica Compliance Dashboard is your local control center for AI Governance. Unlike \"Black Box\" compliance tools that operate behind closed doors, Ventural\u00edtica provides is a Glass Box experience: it exposes the exact technical evidence your system is producing and maps it directly to regulatory obligations.</p> <p>The dashboard makes the abstract concrete. It takes the invisible artifacts of your ML pipeline\u2014metrics, logs, dependencies\u2014and renders them into a Regulatory Traceability Matrix.</p>"},{"location":"compliance-dashboard/#the-sequential-regulatory-map-articles-9-15","title":"The Sequential Regulatory Map (Articles 9-15)","text":"<p>The core feature of the dashboard is the strict sequential mapping of the EU AI Act requirements for High-Risk AI Systems (Chapter III, Section 2). This \"Compliance Walk\" guides you through the lifecycle of a compliant system.</p>"},{"location":"compliance-dashboard/#the-traceability-flow","title":"The Traceability Flow","text":""},{"location":"compliance-dashboard/#1-article-9-risk-management-system","title":"1. Article 9: Risk Management System","text":"<ul> <li>The Law: You must identify and mitigate risks to health, safety, and fundamental rights.</li> <li>The Code: Ventural\u00edtica maps your Fairness Audits here. If you run a bias check (e.g., <code>gender-bias</code>), the result is the technical evidence that you are monitoring Fundamental Rights risks.</li> <li>Status:<ul> <li><code>Mitigation Verified</code>: Your fairness tests passed.</li> <li><code>Risk Materialized</code>: A test failed (e.g., Disparate Impact detected).</li> </ul> </li> </ul>"},{"location":"compliance-dashboard/#2-article-10-data-governance","title":"2. Article 10: Data Governance","text":"<ul> <li>The Law: Training, validation, and testing data must be relevant, representative, and error-free.</li> <li>The Code: Maps to your Data Quality Checks (e.g., class imbalance, missing values) and usage of data libraries (<code>pandas</code>, <code>numpy</code>).</li> <li>Status: Flags if data validation was skipped or failed.</li> </ul>"},{"location":"compliance-dashboard/#3-article-11-technical-documentation","title":"3. Article 11: Technical Documentation","text":"<ul> <li>The Law: You must maintain up-to-date technical documentation demonstrating conformity.</li> <li>The Code: Checks for the presence of your Software Bill of Materials (SBOM) (generated by <code>venturalitica scan</code>) and the Technical File Draft (generated by <code>venturalitica doc</code>).</li> <li>Status: Green if artifacts exist; Yellow/Red if documentation is missing.</li> </ul>"},{"location":"compliance-dashboard/#4-article-12-record-keeping","title":"4. Article 12: Record-Keeping","text":"<ul> <li>The Law: Automatic logging of events over the system's lifetime to ensure traceability.</li> <li>The Code: Verifies two critical components:<ul> <li>Cryptographic Anchoring: Displays the SHA-256 hash of your evidence, proving data integrity.</li> <li>Execution Traces: Confirms that runtime metadata (<code>runtime_meta</code>) was captured during training/inference.</li> </ul> </li> </ul>"},{"location":"compliance-dashboard/#5-article-13-transparency-information","title":"5. Article 13: Transparency &amp; Information","text":"<ul> <li>The Law: The system must be sufficiently transparent to allow users to interpret outputs.</li> <li>The Code: Checks for Code Opacity. Is the source code accessible for audit? Are instructions provided?</li> </ul>"},{"location":"compliance-dashboard/#6-article-14-human-oversight","title":"6. Article 14: Human Oversight","text":"<ul> <li>The Law: The system must be designed to be overseen by natural persons (human-in-the-loop).</li> <li>The Code: Scans for \"Stop Button\" logic or interactive interfaces (e.g., Streamlit apps, Jupyter notebooks) that imply human control capability.</li> </ul>"},{"location":"compliance-dashboard/#7-article-15-accuracy-robustness-cybersecurity","title":"7. Article 15: Accuracy, Robustness &amp; Cybersecurity","text":"<ul> <li>The Law: The system must be resilient to errors and attacks.</li> <li>The Code:<ul> <li>Accuracy: Maps to your Performance Metrics (Accuracy, F1, Recall).</li> <li>Cybersecurity: Checks for Supply Chain Vulnerabilities (CVEs) in your dependencies via the SBOM scan.</li> </ul> </li> </ul>"},{"location":"compliance-dashboard/#why-this-matters","title":"Why This Matters","text":"<p>This sequential layout transforms compliance from a chaotic checklist into a logical engineering workflow:</p> <ol> <li>Assess Risk (Art 9)</li> <li>Clean Data (Art 10)</li> <li>Document It (Art 11)</li> <li>Log It (Art 12)</li> <li>Explain It (Art 13)</li> <li>control It (Art 14)</li> <li>Secure It (Art 15)</li> </ol> <p>By following this flow, you are structurally aligning your AI system with the law, line by line.</p>"},{"location":"compliance-gap/","title":"The Compliance Gap (Roadmap)","text":"<p>Ventural\u00edtica v0.4 provides the foundation for Glass Box AI, but high-risk systems (EU AI Act) require continuous improvement. This document identifies the current technical gaps and the features required to turn \"Technical Evidence\" into \"Legal Certainty.\"</p>"},{"location":"compliance-gap/#recently-closed-gaps-v04","title":"\u2705 Recently Closed Gaps (v0.4)","text":"<p>The \"Deep Strategic Audit\" and the Academy release have closed the following critical gaps:</p>"},{"location":"compliance-gap/#1-technical-documentation-article-11","title":"1. Technical Documentation (Article 11)","text":"<ul> <li>Previous Gap: Manual writing of technical files.</li> <li>Solution: Annex IV Generator (Mistral &amp; ALIA Sovereign AI) now automates the drafting of regulatory documents.</li> </ul>"},{"location":"compliance-gap/#2-transparency-trust-article-13","title":"2. Transparency &amp; Trust (Article 13)","text":"<ul> <li>Previous Gap: No public-facing proof of compliance.</li> <li>Solution: The Digital Seal. Instead of a static SVG badge, Ventural\u00edtica now hashes the Trace Evidence (SHA-256) to create a tamper-proof cryptographic signature.</li> </ul>"},{"location":"compliance-gap/#3-resource-efficiency-article-15","title":"3. Resource Efficiency (Article 15)","text":"<ul> <li>Previous Gap: No tracking of energy or hardware usage.</li> <li>Solution: <code>vl.monitor()</code> now automatically logs CO2 emissions and GPU/RAM consumption.</li> </ul>"},{"location":"compliance-gap/#missing-features-open-gaps","title":"\ud83d\udee0 Missing Features &amp; Open Gaps","text":""},{"location":"compliance-gap/#1-evidence-hardening-article-12","title":"1. Evidence Hardening (Article 12)","text":"<ul> <li>Current State: SHA-256 hashing of evidence files (The \"Digital Seal\").</li> <li>The Gap: No native Digital Signing (Non-repudiation).</li> <li>Requirement: Implementation of GPG/X.509 signing for <code>trace.json</code> files to ensure they cannot be forged even by the system owner.</li> </ul>"},{"location":"compliance-gap/#2-deep-data-governance-article-10","title":"2. Deep Data Governance (Article 10)","text":"<ul> <li>Current State: Basic class balance and missing value checks.</li> <li>The Gap: Lack of Data Lineage and Annotation Provenance.</li> <li>Requirement: Tools to log the source of labels, inter-annotator agreement metrics, and \"poisoning\" detection for training sets.</li> </ul>"},{"location":"compliance-gap/#3-human-oversight-interactive-checks-article-14","title":"3. Human Oversight Interactive Checks (Article 14)","text":"<ul> <li>Current State: Static check for interactive elements (AST analysis).</li> <li>The Gap: No runtime verification of \"Human-in-the-loop\" (HITL) actions.</li> <li>Requirement: A <code>vl.oversight()</code> wrapper to record when a human actually approves/rejects a high-risk prediction in production.</li> </ul>"},{"location":"compliance-gap/#4-adversarial-robustness-article-15","title":"4. Adversarial Robustness (Article 15)","text":"<ul> <li>Current State: Efficiency &amp; Accuracy tracking (<code>vl.monitor</code>).</li> <li>The Gap: No native Attack Scanners for security.</li> <li>Requirement: Integration with robustness libraries (e.g., ART, CleverHans) to automate adversarial testing as part of the <code>enforce()</code> pipeline.</li> </ul>"},{"location":"compliance-gap/#5-automated-bias-mitigation","title":"5. Automated Bias Mitigation","text":"<ul> <li>Current State: Detection only.</li> <li>The Gap: Friction in fixing detected bias.</li> <li>Requirement: Integration with Fairlearn/AIF360 for \"suggested mitigations\" directly in the Dashboard.</li> </ul>"},{"location":"compliance-gap/#propose-a-feature","title":"\ud83d\ude80 Propose a Feature","text":"<p>We are building the future of Responsible AI. If you have a specific requirement to fulfill a compliance mandate, we want to hear from you.</p> <ol> <li>Open a GitHub Issue.</li> <li>Tag it as <code>feature-request</code> + <code>compliance-gap</code>.</li> <li>Describe the Legal Article (e.g., Art 13) or Technical Pain you are addressing.</li> </ol> <p>View Roadmap Discussions</p>"},{"location":"evidence-collection/","title":"Evidence Collection: The Black Box Recorder","text":"<p>While Policies (the Enforcer) stop bad models from reaching production, Evidence Collection (the Recorder) ensures you can prove exactly what happened during training. This is your \"Black Box\" flight recorder for AI.</p> <p>In Ventural\u00edtica, evidence collection is distinct from policy enforcement. You can record evidence without blocking a deployment, or enforce strictly without saving traces. However, for full EU AI Act compliance (Article 12: Record-Keeping), you need both.</p>"},{"location":"evidence-collection/#two-ways-to-record","title":"Two Ways to Record","text":""},{"location":"evidence-collection/#1-the-automatic-wrapper-vlwrap","title":"1. The Automatic Wrapper (<code>vl.wrap</code>)","text":"<p>The easiest way to collect evidence is to wrap your estimator. This automatically hooks into <code>.fit()</code> and <code>.predict()</code> to capture inputs, outputs, and metadata.</p> <pre><code>import venturalitica as vl\nfrom sklearn.ensemble import RandomForestClassifier\n\n# 1. Wrap the model\nmodel = vl.wrap(RandomForestClassifier(), policy=\"model_policy.yaml\")\n\n# 2. Train as usual (Evidence is auto-collected)\nmodel.fit(X_train, y_train, audit_data=train_df, gender=\"Attribute9\")\n</code></pre> <p>What is recorded? *   Timestamp: Precise start/end times. *   Model Config: Hyperparameters (<code>n_estimators</code>, <code>max_depth</code>, etc.). *   Data Shape: Number of rows/columns used. *   Code Context: The filename and AST analysis of the script that called <code>fit</code>.</p>"},{"location":"evidence-collection/#2-the-multimodal-monitor-vlmonitor","title":"2. The Multimodal Monitor (<code>vl.monitor</code>)","text":"<p>For custom training loops (e.g., PyTorch, TensorFlow) or complex pipelines where <code>fit()</code> isn't enough, use the context manager.</p> <pre><code>import venturalitica as vl\n\n# Start the recording session\nwith vl.monitor(\"training_run_v1\"):\n    # Your custom logic here\n    model = train_custom_model(data)\n    evaluate_model(model)\n\n# Evidence is saved to .venturalitica/trace_training_run_v1.json\n</code></pre>"},{"location":"evidence-collection/#where-does-the-evidence-go","title":"Where does the evidence go?","text":"<p>All evidence is secured locally in the <code>.venturalitica/</code> directory:</p> <ul> <li><code>results.json</code>: The outcome of your policy audits (Pass/Fail).</li> <li><code>trace_{name}.json</code>: The execution metadata (timestamps, code analysis).</li> <li><code>bom.json</code>: The software supply chain inventory (dependencies).</li> </ul>"},{"location":"evidence-collection/#compliance-impact","title":"Compliance Impact","text":"<p>For Article 12 (EU AI Act), this evidence is mandatory. The Ventural\u00edtica Dashboard reads these files to prove: 1.  Traceability: \"We know exactly which code and data produced Model v1.0.\" 2.  Integrity: \"The evidence has not been tampered with\" (via SHA-256 anchoring).</p> <p>View Your Traces</p> <p>After running your training script, launch the dashboard (<code>venturalitica ui</code>) to visualize these traces in the Article 12 section.</p>"},{"location":"integrations/","title":"MLOps Integrations (The Ops Guide)","text":"<p>This guide focuses on the MLOps Persona: the one who automates the pipeline. Ventural\u00edtica integrates strictly with your existing tools to ensure that Evidence (Article 12) is automatically collected during your CI/CD runs.</p>"},{"location":"integrations/#the-concept","title":"The Concept","text":"<p>We do not want to replace your MLOps stack. We want to certify it.</p> Tool Integration Benefit MLflow / WandB <code>vl.wrap()</code> Automatically links Policy <code>model_policy.yaml</code> to the run artifacts. Status Dashboard <code>venturalitica ui</code> Provides \"Traffic Light\" health checks for your compliance pipeline."},{"location":"integrations/#1-regulatory-versioning","title":"1. Regulatory Versioning","text":"<p>Every time you train a model using <code>vl.wrap()</code> or <code>vl.monitor()</code>, Ventural\u00edtica automatically snapshots your governance policy (<code>model_policy.yaml</code>) and uploads it to your active tracking server.</p> <ul> <li>Why? Ensures that your audit trail is strictly reproducible. You can prove exactly which rules were active during training (e.g., \"Policy v1.2 vs v1.3\").</li> <li>Where? Look for <code>policy_snapshot</code> in your MLflow artifacts or WandB files.</li> </ul>"},{"location":"integrations/#2-setup-guide","title":"2. Setup Guide","text":""},{"location":"integrations/#weights-biases-cloud","title":"Weights &amp; Biases (Cloud)","text":"<p>Ventural\u00edtica automatically detects <code>wandb</code> runs.</p> <ol> <li>Configure: Set <code>WANDB_API_KEY</code> in your <code>.env</code>.</li> <li>Run: Just use <code>vl.wrap(model)</code> inside your script.</li> <li>Verify: Open <code>venturalitica ui</code> -&gt; Integrations.</li> </ol>"},{"location":"integrations/#mlflow-localremote","title":"MLflow (Local/Remote)","text":"<p>Compatible with both local <code>mlruns</code> and remote Tracking Servers.</p> <ol> <li>Configure: Set <code>MLFLOW_TRACKING_URI</code> (optional, defaults to <code>./mlruns</code>).</li> <li>Run: Ensure <code>mlflow.start_run()</code> is active when you call <code>fit()</code>.</li> <li>Verify: The UI will generate deep links to your specific Experiment and Run ID.</li> </ol>"},{"location":"integrations/#3-example-loan-scenario","title":"3. Example (Loan Scenario)","text":"<p>Here is how you automate the Article 15 Audit inside a standard pipeline.</p> <pre><code>import venturalitica as vl\nimport mlflow\nfrom sklearn.ensemble import RandomForestClassifier\n\n# 1. Define Policy (The Standard)\npolicy = \"model_policy.yaml\"\n\n# 2. Start MLOps Run\nwith mlflow.start_run():\n\n    # 3. Transparent Wrapping (The Governance Layer)\n    # This automatically captures the 'model_policy.yaml' snapshot\n    model = vl.wrap(RandomForestClassifier(), policy=policy)\n\n    # 4. Train (Evidence &amp; Artifacts auto-uploaded)\n    model.fit(\n        X_train, y_train,\n        audit_data=train_df,\n        gender=\"Attribute9\",  # Strict mapping for audit\n        age=\"Attribute13\"\n    ) \n</code></pre>"},{"location":"quickstart/","title":"60-Second Quickstart","text":"<p>Goal: Your first bias audit in under 60 seconds.</p>"},{"location":"quickstart/#the-fundamentals-from-risk-to-code","title":"The Fundamentals: From Risk to Code","text":"<p>Building High-Risk AI requires a fundamental shift in how we approach testing. It is no longer enough to check for technical accuracy (e.g., F1 Score); we must now mathematically prove that the system respects fundamental rights, such as non-discrimination or data quality, as mandated by the EU AI Act.</p> <p>Ventural\u00edtica automates this by treating \"Governance\" as a dependency. Instead of vague legal requirements, you define strict policies (OSCAL) that your model must pass before it can be deployed. This turns compliance into a deterministic engineering problem.</p> <p>Is my System High-Risk?</p> <p>According to Article 6 of EU AI Act, a system is High-Risk if it is covered by Annex I (Safety Components like machinery/medical devices) or listed in Annex III (Biometrics, Critical Infrastructure, Education, Employment, Essential Services, Law Enforcement, Migration, Justice/Democracy).</p> <p>The Translation Layer:</p> <ol> <li> <p>Fundamental Risk: \"The model must not discriminate against protected groups\" (Art 9).</p> </li> <li> <p>Policy Control: \"Disparate Impact Ratio must be &gt; 0.8\".</p> </li> <li> <p>Code Assertion: <code>assert calculated_metric &gt; 0.8</code>.</p> </li> </ol> <p>When you run <code>quickstart()</code>, you are technically running a Unit Test for Ethics.</p>"},{"location":"quickstart/#step-1-install","title":"Step 1: Install","text":"<pre><code>pip install git+https://github.com/Venturalitica/venturalitica-sdk.git\n</code></pre>"},{"location":"quickstart/#step-2-run-your-first-audit","title":"Step 2: Run Your First Audit","text":"<pre><code>import venturalitica as vl\n\nvl.quickstart('loan')\n</code></pre> <p>Output:</p> <pre><code>[Ventural\u00edtica v0.4.1] \ud83c\udf93 Scenario: Credit Scoring Fairness\n[Ventural\u00edtica v0.4.1] \ud83d\udcca Loaded: UCI Dataset #144 (1000 samples)\n\n  CONTROL                DESCRIPTION                            ACTUAL     LIMIT      RESULT\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  credit-data-imbalance  Data Quality                           0.431      &gt; 0.2      \u2705 PASS\n  credit-data-bias       Disparate impact                       0.836      &gt; 0.8      \u2705 PASS\n  credit-age-disparate   Age disparity                          0.361      &gt; 0.5      \u274c FAIL\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  Audit Summary: \u274c VIOLATION | 2/3 controls passed\n</code></pre> <p>Info</p> <p>The audit detected age-based bias in the UCI German Credit dataset.</p>"},{"location":"quickstart/#step-3-whats-happening-under-the-hood","title":"Step 3: What's Happening Under the Hood","text":"<p>The <code>quickstart()</code> function is a wrapper that performs the full compliance lifecycle in one go:</p> <ol> <li>Downloads Data: Fetches the UCI German Credit dataset.  </li> <li>Loads Policy: Reads <code>risks.oscal.yaml</code> which defines the fairness rules.</li> <li>Enforces: Runs the audit (<code>vl.enforce</code>).</li> <li>Records: Captures the evidence (<code>trace.json</code>) for the dashboard.</li> </ol> <p>Here's the equivalent \"manual\" code:</p> <pre><code>from ucimlrepo import fetch_ucirepo\nimport venturalitica as vl\n\n# 1. Load Data (The \"Risk Source\")\ndataset = fetch_ucirepo(id=144)\ndf = dataset.data.features\ndf['class'] = dataset.data.targets\n\n# 2. Define the Policy (The \"Law\")\n# We load a pre-defined policies/risks.oscal.yaml\n\n# 3. Run the Audit (The \"Test\")\n# This automatically generates the Evidence Bill of Materials (BOM)\nwith vl.monitor(\"manual_audit\"):\n    vl.enforce(\n        data=df,\n        target=\"class\",          # The outcome (True/False)\n        gender=\"Attribute9\",     # Protected Group A\n        age=\"Attribute13\",       # Protected Group B\n        policy=\"risks.oscal.yaml\"\n    )\n</code></pre>"},{"location":"quickstart/#the-policy-logic","title":"The Policy Logic","text":"<p>The policy (<code>risks.oscal.yaml</code>) is the bridge. It tells the SDK what to check so you don't have to hardcode it.</p> <pre><code># ... inside the OSCAL YAML ...\n- control-id: credit-data-bias\n  description: \"Disparate impact ratio must be &gt; 0.8 (80% rule)\"\n  props:\n    - name: metric_key\n      value: disparate_impact   # &lt;--- The Python Function to call\n    - name: threshold\n      value: \"0.8\"              # &lt;--- The Limit to enforce\n    - name: operator\n      value: \"&gt;\"                # &lt;--- The Logic (&gt; 0.8)\n    - name: \"input:dimension\"\n      value: gender             # &lt;--- Maps to \"Attribute9\"\n</code></pre> <p>This design decouples Governance (the policy file) from Engineering (the python code).</p>"},{"location":"quickstart/#why-this-matters","title":"Why This Matters","text":"<p>Without this mechanism, your AI model is a legal \"Black Box\":</p> <ul> <li>Liability: You cannot prove you checked for bias before deployment (Art 9).</li> <li>Fragility: Compliance is a manual checklist, easily forgotten or skipped.</li> <li>Opacity: Auditors cannot see the link between your code and the law.</li> </ul> <p>By running <code>quickstart()</code>, you have just generated an immutable Compliance Artifact. Even if the laws change, your evidence remains.</p>"},{"location":"quickstart/#step-4-the-glass-box-dashboard","title":"Step 4: The \"Glass Box\" Dashboard \ud83d\udcca","text":"<p>Now that we have the evidence (the \"Black Box\" recording), let's inspect it in the Regulatory Map.</p> <pre><code>venturalitica ui\n</code></pre> <p>Navigate through the Compliance Map tabs:</p> <ul> <li>Article 9 (Risk): See the failed <code>credit-age-disparate</code> control. This is your technical evidence of \"Risk Monitoring\".</li> <li>Article 10 (Data): See the data distribution and quality checks.</li> <li>Article 13 (Transparency): Review the \"Transparency Feed\" to see your Python dependencies (BOM).</li> </ul>"},{"location":"quickstart/#step-5-generate-documentation-annex-iv","title":"Step 5: Generate Documentation (Annex IV) \ud83d\udcdd","text":"<p>The final step is to turn this evidence into a legal document.</p> <ol> <li>In the Dashboard, go to the \"Generation\" tab.</li> <li>Select \"English\" (or Spanish/Catalan/Euskera).</li> <li>Click \"Generate Annex IV\".</li> </ol> <p>Ventural\u00edtica will draft a technical document that references your specific run:</p> <p>\"As evidenced in <code>trace_quickstart_loan.json</code>, the system was audited against [OSCAL Policy: Credit Scoring Fairness]. A deviation was detected in Age Disparity (0.36), identifying a potential risk of bias...\"</p>"},{"location":"quickstart/#references","title":"References","text":"<ul> <li>Policy Used: <code>loan/risks.oscal.yaml</code></li> <li>Legal Basis:<ul> <li>EU AI Act Article 9 (Risk Management)</li> <li>EU AI Act Article 11 (Technical Documentation)</li> </ul> </li> </ul>"},{"location":"quickstart/#whats-next","title":"What's Next?","text":"<ul> <li>API Reference - Full documentation</li> <li>Create your own policy - Copy the YAML above and modify thresholds</li> </ul>"},{"location":"training/","title":"\ud83d\udee0\ufe0f Model Training (The Builder)","text":"<p>This guide focuses on the Builder Persona: the Data Scientist who trains the model. In the Ventural\u00edtica workflow, your job is to \"manufacture\" the AI system according to the specifications defined by the Engineer (Level 1).</p>"},{"location":"training/#the-two-policy-handshake","title":"The Two-Policy Handshake","text":"<p>Compliance is not a single step. It is a handshake between Data (Article 10) and Model (Article 15).</p> Phase Policy Article (EU AI Act) Function 1. Data Audit <code>data_policy.yaml</code> Art. 10: Data Governance <code>vl.enforce(data=train_df)</code> 2. Model Audit <code>model_policy.yaml</code> Art. 15: Accuracy &amp; Robustness <code>vl.enforce(data=test_df, prediction=pred)</code>"},{"location":"training/#step-1-load-data-split","title":"Step 1: Load Data &amp; Split","text":"<p>We use the standard Loan Credit Scoring dataset.</p> <pre><code>from ucimlrepo import fetch_ucirepo\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\n\n# 1. Fetch Data\ndataset = fetch_ucirepo(id=144)\ndf = dataset.data.features.copy()\ndf['class'] = dataset.data.targets\n\n# 2. Split (Train/Test)\ntrain_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n\n# 3. Encode for Training (One-Hot)\ndf_encoded = pd.get_dummies(df.drop(columns=['class']))\nX_train, X_test, y_train, y_test = train_test_split(\n    df_encoded, \n    df['class'].values.ravel(), \n    test_size=0.2, \n    random_state=42\n)\n</code></pre>"},{"location":"training/#step-2-pre-training-audit-article-10","title":"Step 2: Pre-Training Audit (Article 10)","text":"<p>Before you invest compute time, verify the raw material.</p> <pre><code>import venturalitica as vl\n\n# Start the 'evidence recorder' for the Training Phase\nwith vl.monitor(\"training_run_v1\"):\n\n    # \ud83d\udd0d AUDIT 1: DATA GOVERNANCE (The Ingredients)\n    print(\"\ud83d\udee1\ufe0f Auditing Data (Article 10)...\")\n    vl.enforce(\n        data=train_df,\n        target=\"class\",\n        gender=\"Attribute9\",  # Mapping strictly defined by policy\n        age=\"Attribute13\",\n        policy=\"data_policy.yaml\"\n    )\n</code></pre> <p>Real Output: <pre><code>[Ventural\u00edtica v0.4.1] \ud83d\udee1  Enforcing policy: data_policy.yaml\n\n  CONTROL                DESCRIPTION                            ACTUAL     LIMIT      RESULT\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  imbalance              Minority ratio                         0.431      &gt; 0.2      \u2705 PASS\n  gender-bias            Disparate impact                       0.836      &gt; 0.8      \u2705 PASS\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n</code></pre></p>"},{"location":"training/#step-3-train-the-model","title":"Step 3: Train the Model","text":"<p>If the data passes, proceed to manufacture the model.</p> <pre><code>    # \ud83c\udfed MANUFACTURE: Train the Model\n    from sklearn.ensemble import RandomForestClassifier\n\n    print(\"\ud83e\udd16 Training Model...\")\n    model = RandomForestClassifier(n_estimators=100, random_state=42)\n    model.fit(X_train, y_train)\n\n    # Generate predictions for the next audit\n    predictions = model.predict(X_test)\n</code></pre>"},{"location":"training/#step-4-post-training-audit-article-15","title":"Step 4: Post-Training Audit (Article 15)","text":"<p>Now verify the finished product against the performance requirements.</p> <pre><code>    # \ud83d\udd0d AUDIT 2: MODEL ACCURACY &amp; FAIRNESS (The Product)\n    print(\"\ud83d\udee1\ufe0f Auditing Model (Article 15)...\")\n\n    # Prepare audit dataframe\n    audit_df = df.iloc[test_df.index].copy()\n    audit_df['prediction'] = predictions\n\n    vl.enforce(\n        data=audit_df,\n        target=\"class\",\n        prediction=\"prediction\", # Now we evaluate the OUTPUT using the same sensitive attributes\n        gender=\"Attribute9\",\n        age=\"Attribute13\",\n        policy=\"model_policy.yaml\"\n    )\n</code></pre> <p>Real Output: <pre><code>[Ventural\u00edtica v0.4.1] \ud83d\udee1  Enforcing policy: model_policy.yaml\n\n  CONTROL                DESCRIPTION                            ACTUAL     LIMIT      RESULT\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  accuracy-check         Minimum Accuracy                       0.760      &gt; 0.7      \u2705 PASS\n  recall-check           Recall (Risk Aversion)                 0.720      &gt; 0.6      \u2705 PASS\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  Audit Summary: \u2705 POLICY MET | 2/2 controls passed\n\n  \u2705 TraceCollector [training_run_v1] evidence saved to .venturalitica/trace_training_run_v1.json\n</code></pre></p>"},{"location":"training/#step-5-view-evidence","title":"Step 5: View Evidence","text":"<p>You have now completed the Builder's Job. Run the dashboard to see your \"Glass Box\".</p> <pre><code>venturalitica ui\n</code></pre>"},{"location":"academy/","title":"Zero to Pro: The 5-Minute Journey \ud83d\ude80","text":"<p>Goal: Transform from \"Python Developer\" to \"AI Governance Engineer\" in 3 steps.</p>"},{"location":"academy/#the-philosophy-compliance-as-code","title":"The Philosophy: Compliance as Code","text":"<p>You are used to <code>pytest</code> for checking if your function adds 2+2 correctly. But how do you test if your AI model respects Human Rights?</p> <p>Ventural\u00edtica treats \"Governance\" as a dependency. Instead of vague legal advice, you define stricter Policies (OSCAL). Your CI/CD pipeline enforces them just like linter rules.</p>"},{"location":"academy/#the-curriculum","title":"The Curriculum","text":"Level Role Goal Project Start Here Developer Run your first audit in &lt; 60s. loan-credit-scoring Level 1 Engineer Implement Controls for identified Risks. 00_engineer_policy.ipynb Level 2 Integrator Viz &amp; MLOps: \"Compliance as Metadata\". 03_mlops_integration.py Level 3 Auditor Proof: \"Trust the Glass Box\". 01_governance_audit.ipynb Level 4 Architect GenAI Docs: \"Annex IV\". <code>loan-credit-scoring</code> (Annex IV)"},{"location":"academy/#step-1-install","title":"Step 1: Install","text":"<p>We recommend uv for blazing speed, or standard <code>pip</code>.</p> <pre><code>uv pip install git+https://github.com/Venturalitica/venturalitica-sdk.git\n# OR\npip install git+https://github.com/Venturalitica/venturalitica-sdk.git\n</code></pre>"},{"location":"academy/#step-2-get-the-code","title":"Step 2: Get the Code \ud83d\udce6","text":"<p>To follow the Academy, clone the samples repository. This will be your working directory for all levels.</p> <pre><code>git clone https://github.com/venturalitica/venturalitica-sdk-samples.git\ncd venturalitica-sdk-samples/scenarios/loan-credit-scoring\n</code></pre>"},{"location":"academy/#step-3-run-your-first-audit","title":"Step 3: Run Your First Audit \u26a1","text":"<p>Run this single line of code. It downloads a dataset, loads a policy, and audits a model.</p> <pre><code>import venturalitica as vl\n\n# Run the 'loan' scenario\nvl.quickstart('loan')\n</code></pre> <p>Output:</p> <pre><code>  CONTROL                DESCRIPTION                            RESULT\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  credit-data-bias       Disparate impact ratio &gt; 0.8           \u2705 PASS\n  credit-age-disparate   Age disparity ratio &gt; 0.5              \u274c FAIL\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  Audit Summary: \u274c VIOLATION | 1/2 controls passed\n</code></pre>"},{"location":"academy/#take-home-message","title":"\ud83d\udca1 Take Home Message","text":"<p>\"Compliance transforms vague Principles into verifiable Engineering constraints.\"</p> <ul> <li>The Policy: <code>ratio &gt; 0.5</code> (The Law).</li> <li>The Reality: <code>0.361</code> (Your Code).</li> <li>The Verdict: <code>\u274c FAIL</code> (The Compliance Gap).</li> </ul> <p>You didn't need a lawyer. You just needed a visible test failure.</p>"},{"location":"academy/#step-4-choose-your-path","title":"Step 4: Choose Your Path","text":"<p>Now that you've seen the failure, learn how to fix it and verify it.</p> <ul> <li> <p> Level 1: The Engineer     ---     Learn how to implement Controls that mitigate identified Risks. Detect &amp; Block non-compliant models.</p> </li> <li> <p> Level 2: The Integrator     ---     Log outcomes to MLOps tools and verify results visually in the Dashboard.</p> </li> <li> <p> Level 3: The Auditor     ---     Learn how to perform a \"Glass Box\" audit on the loan model and generate cryptographic proofs.</p> </li> <li> <p> Level 4: The Architect     ---     The Boss Level. Train a high-risk financial model and generate the massive Technical Documentation required by the EU AI Act.</p> </li> </ul>"},{"location":"academy/#external-references","title":"\ud83d\udcda External References","text":"<ul> <li>EU AI Act: Full Legal Text (EUR-Lex)</li> <li>ISO 42001: Artificial Intelligence Management System (AIMS)</li> <li>NIST AI RMF: Risk Management Framework 1.0</li> </ul>"},{"location":"academy/level1_policy/","title":"Level 1: The Engineer (Policy &amp; Configuration) \ud83d\udfe2","text":"<p>Goal: Learn how to implement Controls that mitigate Risks.</p> <p>Prerequisite: Zero to Pro (Index)</p>"},{"location":"academy/level1_policy/#1-the-scenario-from-risk-to-control","title":"1. The Scenario: From Risk to Control","text":"<p>In a formal Management System (ISO 42001), governance follows a top-down flow:</p> <ol> <li>Risk Assessment: The Compliance Officer (CO) identifies a business risk (e.g., \"Our lending AI might discriminate against elderly applicants, causing legal and reputational damage\").</li> <li>Control Definition: To mitigate this risk, the CO sets a Control (e.g., \"The Age Disparity Ratio must always be &gt; 0.5\").</li> <li>Technical Implementation: That's your job. You take the CO's requirement and turn it into the technical \"Law\" (Article 10: Data Governance).</li> </ol> <p>In the Zero to Pro quickstart, <code>vl.quickstart('loan')</code> FAILED:</p> <pre><code>credit-age-disparate   Age disparity          0.361      &gt; 0.5      \u274c FAIL\n</code></pre>"},{"location":"academy/level1_policy/#what-happened","title":"What happened?","text":"<p>The Control successfully detected a Compliance Gap. The \"Reality\" of the data (<code>0.361</code>) violated the requirement set to mitigate the \"Age Bias\" risk.</p> <p>Rule #1: The Handshake of Responsibility. Compliance Officers identify Risks and establish Controls.  Engineers implement and Verify those controls using Evidence.</p> <p>If you lower the threshold to 0.3 just to make the test \"pass,\" you aren't fixing the code\u2014you are bypassing a security control and exposing the company to the original risk.</p>"},{"location":"academy/level1_policy/#2-anatomy-of-a-control-oscal","title":"2. Anatomy of a Control (OSCAL)","text":"<p>Your job is to translate the CO's requirement into Code.  Create a file named <code>data_policy.oscal.yaml</code> (or download it from GitHub). Keep the threshold at 0.5 (The Organizational Standard).</p> <pre><code>assessment-plan:\n  metadata:\n    title: \"Article 10: Data Governance Standard\"\n  control-implementations:\n    - description: \"Fairness Monitoring\"\n      implemented-requirements:\n        # \ud83d\udfe2 Control 1: The Bias Check\n        - control-id: age-check\n          description: \"Age Disparity must be standard (&gt; 0.5)\"\n          props:\n            - name: metric_key\n              value: disparate_impact        # The Python metric to run\n            - name: \"input:dimension\"\n              value: age                    # The abstract concept\n            - name: operator\n              value: gt                     # Greater Than\n            - name: threshold\n              value: \"0.5\"                  # \ud83d\udd12 DO NOT CHANGE THIS\n</code></pre>"},{"location":"academy/level1_policy/#3-run-your-custom-policy","title":"3. Run Your Custom Policy","text":"<p>Now, let's run the audit again with your configuration. Observe how we map the abstract <code>age</code> concept to your specific data column.</p> <p>\ud83d\udca1 Full Code: You can find the complete, ready-to-run notebook for this level here: 00_engineer_policy.ipynb</p> <pre><code>import venturalitica as vl\nfrom ucimlrepo import fetch_ucirepo\n\n# 1. Get Data (Messy CSV)\ndataset = fetch_ucirepo(id=144)\ndf = dataset.data.features\ndf['class'] = dataset.data.targets\n\n# 2. Run Audit (The Mapping)\nresults = vl.enforce(\n    data=df,\n    target=\"class\",\n    age=\"Attribute13\",    # \ud83d\udddd\ufe0f MAPPING: 'age' is actually 'Attribute13'\n    policy=\"data_policy.oscal.yaml\"\n)\n\n# 3. Check Results\nif all(r.passed for r in results):\n    print(\"\u2705 Audit Passed!\")\nelse:\n    print(\"\u274c BLOCKED: Compliance Violation detected.\")\n    print(\"\ud83d\udc49 Action: Push trace.json to SaaS for Compliance Officer review.\")\n</code></pre>"},{"location":"academy/level1_policy/#the-translation-handshake","title":"\ud83e\udd1d The \"Translation\" Handshake","text":"<p>Notice what just happened.</p> <ul> <li>Legal: \"Be fair (&gt; 0.5).\" (Defined in your YAML)</li> <li>Dev: \"This column <code>Attribute13</code> is <code>age</code>.\" (Defined in your Python)</li> </ul> <p>This mapping is the Handshake. You bridge the gap between messy Data and rigid Law. This is how you implement ISO 42001 without losing your mind in spreadsheets.</p>"},{"location":"academy/level1_policy/#4-visual-verification","title":"4. Visual Verification","text":"<p>When you run this, it will FAIL in your terminal. And that is GOOD. But compliance is not just about terminal logs.</p> <p>To see the professional report and visualization of this failure, run the local dashboard:</p> <pre><code>uv run venturalitica ui\n</code></pre> <p>Navigate to the Policy tab. You will see the visual proof of your identified risk:</p> <p></p> <p>You have successfully prevented a non-compliant AI from reaching production by measuring risk against a verifiable standard.</p>"},{"location":"academy/level1_policy/#5-take-home-messages","title":"5. Take Home Messages \ud83c\udfe0","text":"<ol> <li>Policy as Code: Governance is just a <code>.yaml</code> file. It defines the Control.</li> <li>The Handshake: You define the Mapping (<code>age</code>=<code>Attribute13</code>). The Officer defines the Requirement (<code>&gt; 0.5</code>).</li> <li>Treatment starts with Detection: The local failure is the signal necessary to start a formal ISO 42001 risk treatment plan.</li> </ol> <p>Next Step: The build failed locally. How do we tell the Compliance Officer? \ud83d\udc49 Go to Level 2: The Integrator (MLOps)</p>"},{"location":"academy/level2_integrator/","title":"Level 2: The Integrator (GovOps &amp; Visibility) \ud83d\udfe1","text":"<p>Goal: Transform MLOps artifacts into Regulatory Evidence with a GovOps layer.</p> <p>Prerequisite: Level 1 (The Engineer)</p> <p>Context: Continuing with \"The Project\" (Loan Credit Scoring).</p>"},{"location":"academy/level2_integrator/#1-the-bottleneck-it-works-on-my-machine","title":"1. The Bottleneck: \"It works on my machine\"","text":"<p>In Level 1, you fixed the bias locally. But your manager denies it because they can't see the proof. Emails with screenshots are not compliance.</p>"},{"location":"academy/level2_integrator/#2-the-solution-the-govops-layer","title":"2. The Solution: The GovOps Layer","text":"<p>In GovOps (Governance over MLOps), we don't treat compliance as a separate manual step. Instead, we use your existing MLOps infrastructure (MLflow, WandB) as an Evidence Buffer that automatically harvests the proof of safety during the training process.</p>"},{"location":"academy/level2_integrator/#a-the-integration-implicit-governance","title":"A. The Integration (Implicit Governance)","text":"<p>In a professional pipeline, governance is a layer that wraps your training. Every time you train a model, you verify its compliance.</p> <p>Your experiment tracker now tracks two types of performance: Accuracy (Operational) and Compliance (Regulatory).</p> <p>\ud83d\udca1 Full Code: You can find the complete, ready-to-run script for this level here: 03_mlops_integration.py</p> MLflowWeights &amp; Biases <pre><code>import mlflow\nimport venturalitica as vl\nfrom dataclasses import asdict\n\nmlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\nmlflow.set_experiment(\"loan-credit-scoring\")\n\n# 0. Data Preparation\ndf = vl.load_sample(\"loan\")\nX = df.select_dtypes(include=['number']).drop(columns=['class'])\ny = df['class']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# 1. Start the GovOps Session (Implicitly captures 'Audit Trace')\nwith mlflow.start_run(), vl.monitor(\"train_v1\"):\n    # 2. Pre-training Data Audit (Article 10)\n    vl.enforce(\n        data=df,\n        target=\"class\",\n        gender=\"Attribute9\",\n        policy=\"data_policy.oscal.yaml\"\n    )\n\n    # 3. Train your model\n    model = LogisticRegression()\n    model.fit(X_train, y_train)\n\n    # 4. Post-training Model Audit (Article 15: Human Oversight)\n    # Download model_policy.oscal.yaml: https://github.com/venturalitica/venturalitica-sdk-samples/blob/main/scenarios/loan-credit-scoring/policies/loan/model_policy.oscal.yaml\n    results = vl.enforce(\n        data=X_test.assign(prediction=model.predict(X_test)),\n        target=\"prediction\",               # \ud83e\udde0 Checking Model Behavior\n        gender=\"gender\",\n        policy=\"model_policy.oscal.yaml\"   # \ud83d\udddd\ufe0f New policy for Model Governance\n    )\n\n    # 5. Log everything to the Evidence Buffer\n    passed = all(r.passed for r in results)\n    mlflow.log_metric(\"val_accuracy\", 0.92)\n    mlflow.log_metric(\"compliance_score\", 1.0 if passed else 0.0)\n    mlflow.log_dict([asdict(r) for r in results], \"compliance_results.json\")\n\n    if not passed:\n        # \ud83d\uded1 CRITICAL: Block the pipeline if the model is unethical\n        raise ValueError(\"Model failed ISO 42001 compliance check. See audit trace.\")\n</code></pre> <p>Note: <code>vl.monitor()</code> now captures Multimodal Evidence: hardware/carbon metrics AND the logical execution trace (AST code story).</p> <pre><code>import wandb\nimport venturalitica as vl\n\nwandb.init(project=\"loan-credit-scoring\")\n\n# 0. Data Preparation\ndf = pd.read_csv(\"loan_data.csv\")\nX_train, X_test, y_train, y_test = train_test_split(df.drop('class', axis=1), df['class'])\n\n# 1. Open a Monitor Context\nwith vl.monitor(\"wandb_sync\"):\n    # Pre-training Audit (Article 10)\n    vl.enforce(data=df, policy=\"data_policy.oscal.yaml\", target=\"class\")\n\n    # 2. Train and Audit\n    model.fit(X_train, y_train)\n\n    # Post-training Audit (Article 15)\n    # Download model_policy.oscal.yaml: https://github.com/venturalitica/venturalitica-sdk-samples/blob/main/scenarios/loan-credit-scoring/policies/loan/model_policy.oscal.yaml\n    audit = vl.enforce(\n        data=pd.read_csv(\"val_data.csv\"),\n        policy=\"model_policy.oscal.yaml\",\n        target=\"prediction\"\n    )\n\n# 3. Log Compliance Artifacts\nartifact = wandb.Artifact('compliance-bundle', type='evidence')\nartifact.add_file(\".venturalitica/results.json\")\nartifact.add_file(\".venturalitica/trace_wandb_sync.json\")\nwandb.log_artifact(artifact)\n\npassed = all(r.passed for r in audit)\nwandb.log({\"accuracy\": 0.89, \"compliance\": 1.0 if passed else 0.0})\n\nif not passed:\n    raise ValueError(\"Model rejected by GovOps policy.\")\n</code></pre>"},{"location":"academy/level2_integrator/#b-the-verification-dashboard","title":"B. The Verification (Dashboard)","text":"<p>Now that the code has run, let's verify what we shipped.</p> <ol> <li>Run the UI:     <pre><code>uv run venturalitica ui\n</code></pre></li> <li>Log Check: Verify that <code>.venturalitica/results.json</code> exists (this is the default output of <code>enforce</code>).</li> <li>Navigate to \"Policy Status\": Confirm your \"Risk Treatment\" (the adjusted threshold) is recorded.</li> </ol> <p>Key Insight: \"The report looks professional, and I didn't write a single word of it.\"</p> <p></p>"},{"location":"academy/level2_integrator/#3-deep-dive-the-two-policy-handshake-art-10-vs-15","title":"3. Deep Dive: The Two-Policy Handshake (Art 10 vs 15)","text":"<p>Professional GovOps requires a separation of concerns. You are now managing two distinct governance layers:</p> <ol> <li>Level 1 (Article 10): Checked the Raw Data against <code>data_policy.yaml</code>. The goal was to prove the dataset itself was fair before wasting energy on training.</li> <li>Level 2 (Article 15): Checks the Model Behavior against <code>model_policy.yaml</code>. The goal is to prove the AI makes fair decisions in a \"Glass Box\" execution.</li> </ol> Stage Variable Mapping Policy File Mandatory Requirement Data Audit <code>target=\"class\"</code> data_policy.oscal.yaml Article 10 (Data Governance) Model Audit <code>target=\"prediction\"</code> model_policy.oscal.yaml Article 15 (Human Oversight) <p>This decoupling is the core of the Handshake. Even if the Law (<code>&gt; 0.5</code>) stays the same, the subject of the law changes from Data to Math.</p>"},{"location":"academy/level2_integrator/#4-the-gate-cicd","title":"4. The Gate (CI/CD)","text":"<p>If <code>compliance_score == 0</code>, the build fails. GitLab CI / GitHub Actions can now block a deployment based on ethics, just like they block on syntax errors.</p>"},{"location":"academy/level2_integrator/#5-take-home-messages","title":"5. Take Home Messages \ud83c\udfe0","text":"<ol> <li>GovOps is Native: Governance isn't an extra step; it's a context manager (<code>vl.monitor</code>) around your training.</li> <li>Telemetry is Evidence: RAM, CO2, and Trace results are not just for metrics\u2014they fulfill Article 15 oversight.</li> <li>Unified Trace: <code>vl.monitor()</code> captures everything from hardware usage to AST code analysis in a single <code>.json</code> file.</li> <li>Zero Friction: The Data Scientist continues to use MLflow/WandB, while the SDK harvests the evidence.</li> </ol> <p>\ud83d\udc49 Next: Level 3 (The Auditor)</p>"},{"location":"academy/level3_auditor/","title":"Level 3: The Auditor (Glass Box Trace) \ud83d\udfe0","text":"<p>Goal: Verify your policy visually and cryptographically using the Glass Box method.</p> <p>Prerequisite: Level 2 (The Integrator)</p>"},{"location":"academy/level3_auditor/#1-the-problem-it-passed-but-can-we-trust-the-process","title":"1. The Problem: \"It passed, but can we trust the process?\"","text":"<p>In Level 2, you logged the compliance score. But for High-Risk AI (like Credit Scoring), metrics aren't enough. An Auditor asks: \"Did you test on the real dataset, or did you filter out the rejected loans?\" and \"Can you prove this code was actually run?\"</p>"},{"location":"academy/level3_auditor/#2-the-solution-the-glass-box-trace","title":"2. The Solution: The \"Glass Box\" Trace","text":"<p>As per our Strategic Audit Docs, professional auditing requires more than just results\u2014it requires Provenance.</p> <p>Ventural\u00edtica uses a <code>monitor()</code> context manager to record everything:</p> <ul> <li>The Code: AST analysis of your script.</li> <li>The Data: Row count and column schema.</li> <li>The Hardware: Memory, CPU, and Carbon stats (Article 15).</li> <li>The Seal: A cryptographic SHA-256 hash of the entire session.</li> </ul>"},{"location":"academy/level3_auditor/#the-upgrade","title":"The Upgrade","text":"<p>We continue working on the same project. No new setup required.</p>"},{"location":"academy/level3_auditor/#run-with-the-native-monitor","title":"Run with the Native Monitor","text":"<p>Wrap your execution in <code>vl.monitor()</code>. This context manager captures the \"Handshake\" between your code and the policy by harvesting both physical and logical metadata.</p>"},{"location":"academy/level3_auditor/#deep-dive-glass-box-vs-black-box","title":"\ud83d\udd0d Deep Dive: Glass Box vs Black Box","text":""},{"location":"academy/level3_auditor/#deep-dive-glass-box-vs-black-box_1","title":"\ud83d\udd0d Deep Dive: Glass Box vs Black Box","text":"Feature \u2b1b Black Box (Standard) \ud83e\ude9f Glass Box (Ventural\u00edtica) Logic \"Trust me, I ran the code.\" AST Analysis: We record which function mapped code to policy. Data \"Here is the CSV.\" Fingerprint: We record the SHA-256 of the dataset at runtime. Scope Code Code + Environment + Hardware Stats <p>\ud83d\udca1 Full Code: See the professional audit lifecycle in the 01_governance_audit.ipynb notebook.</p> <pre><code>import venturalitica as vl\nfrom ucimlrepo import fetch_ucirepo\n\n# 1. Load Data (The Real Deal)\ndataset = fetch_ucirepo(id=144)\ndf = dataset.data.features\ndf['class'] = dataset.data.targets\n\n# 1. Start the Multimodal Monitor (The Glass Box)\nwith vl.monitor(\"loan_audit_v1\"):\n    # This block is now being watched by the Auditor\n    df = vl.load_sample(\"loan\")\n\n    # Download data_policy.oscal.yaml: https://github.com/venturalitica/venturalitica-sdk-samples/blob/main/scenarios/loan-credit-scoring/policies/loan/data_policy.oscal.yaml\n    results = vl.enforce(\n        data=df,\n        target=\"class\",       # Checking Ground Truth\n        age=\"Attribute13\",    # Mapping Age\n        policy=\"data_policy.oscal.yaml\"\n    )\n    # The session trace file (.venturalitica/trace_loan_audit_v1.json) \n    # will prove NOT just the result, but HOW it was computed.\n</code></pre>"},{"location":"academy/level3_auditor/#3-the-digital-seal-verification","title":"3. The \"Digital Seal\" Verification","text":"<p>After running the audit, launch the UI:</p> <pre><code>uv run venturalitica ui\n</code></pre> <p>Navigate to \"Article 13: Transparency\".</p>"},{"location":"academy/level3_auditor/#finding-the-evidence-hash","title":"Finding the Evidence Hash","text":"<p>Look for the Evidence Hash in the dashboard. <code>Evidence Hash: 89fbf...</code></p> <p>This hash is your \"Digital Seal\". If you change one pixel in the dataset or one line in the policy, this hash changes. You can now prove to a regulator exactly what happened during the audit.</p>"},{"location":"academy/level3_auditor/#4-the-compliance-map","title":"4. The Compliance Map","text":"<p>The Dashboard translates JSON evidence into the language of the EU AI Act.</p> Law Dashboard Tab What to Answer Art 9 Risk Management \"Did we verify bias &lt; 0.1?\" (Your Policy) Art 10 Data Governance \"Is the training data representative?\" Art 13 Transparency \"What libraries (BOM) are we using?\""},{"location":"academy/level3_auditor/#5-take-home-messages","title":"5. Take Home Messages \ud83c\udfe0","text":"<ol> <li>Don't Trust, Verify: The Trace File (captured automatically via <code>monitor()</code>) is the source of truth for the entire execution context.</li> <li>Glass Box Audit: Compliance isn't a \"pass/fail\" boolean; it's a verifiable history of execution.</li> <li>Immutable Proof: The Evidence Hash allows you to prove the integrity of the audit process.</li> </ol> <p>Next Step: You have the Code (Level 1), the Ops (Level 2), and the Proof (Level 3). Now generate the Legal Documents. \ud83d\udc49 Go to Level 4: The Architect</p>"},{"location":"academy/level4_annex_iv/","title":"Level 4: The Architect (Annex IV Generation) \ud83d\udd34","text":"<p>Goal: Automate the creation of 50+ page regulatory documents.</p> <p>Prerequisite: Level 3 (The Auditor)</p>"},{"location":"academy/level4_annex_iv/#1-the-bottleneck-technical-documentation","title":"1. The Bottleneck: \"Technical Documentation\"","text":"<p>According to Article 11 and Annex IV of the EU AI Act, High-Risk systems (like Credit Scoring) require comprehensive Technical Documentation. Writing this manually takes weeks.</p>"},{"location":"academy/level4_annex_iv/#2-the-solution-generative-compliance","title":"2. The Solution: Generative Compliance","text":"<p>We use your Policies (Level 1 &amp; 2) and Evidence (Level 2/3) to prompt an LLM to draft the document for you. </p> <p>Ventural\u00edtica supports:</p> <ul> <li>Cloud: Mistral (via API).</li> <li>Local: Ollama (General purpose).</li> <li>Sovereign (NEW): ALIA (Spanish Native GGUF via Llama.cpp) - Experimental.</li> </ul>"},{"location":"academy/level4_annex_iv/#the-upgrade","title":"The Upgrade","text":"<p>We continue working on the \"Loan Scoring\" project.</p> <p>\ud83d\udca1 Full Code: You can find the automation script for Annex IV generation here: generate_annex_iv.py</p>"},{"location":"academy/level4_annex_iv/#run-the-high-risk-audit","title":"Run the High-Risk Audit","text":"<p>Ensure you have run the collection steps:</p> <pre><code># 1. Load Data\ndf = vl.load_sample(\"loan\")\ntrain_df = df.sample(frac=0.8)\nval_df = df.drop(train_df.index)\n\n# 2. Run the Article 10 (Data) &amp; Article 15 (Model) Governance Audit\nwith vl.monitor(\"loan_annex_audit\"):\n    # 2.1 Verify Training Data (Art 10)\n    # Download data_policy.oscal.yaml: https://github.com/venturalitica/venturalitica-sdk-samples/blob/main/scenarios/loan-credit-scoring/policies/loan/data_policy.oscal.yaml\n    vl.enforce(data=train_df, policy=\"data_policy.oscal.yaml\", target=\"class\")\n\n    # 2.2 Verify Model Performance (Art 15)\n    # Download model_policy.oscal.yaml: https://github.com/venturalitica/venturalitica-sdk-samples/blob/main/scenarios/loan-credit-scoring/policies/loan/model_policy.oscal.yaml\n    vl.enforce(\n        data=val_df.assign(prediction=val_df['class']), # Simulated model\n        policy=\"model_policy.oscal.yaml\", \n        target=\"class\",\n        prediction=\"prediction\"\n    )\n</code></pre>"},{"location":"academy/level4_annex_iv/#3-generate-the-document","title":"3. Generate the Document","text":"<ol> <li>Open the Dashboard: <code>uv run venturalitica ui</code>.</li> <li>Go to the \"Annex IV Generator\" tab.</li> <li>Select Provider: Cloud (Mistral), Local (Ollama), or Sovereign (ALIA - Experimental).</li> <li> <p>Click \"Generate Annex IV\".</p> <p></p> </li> </ol>"},{"location":"academy/level4_annex_iv/#the-generation-process","title":"The Generation Process","text":"<p>Watch the logs. The System is acting as a Team of Agents:</p> <ol> <li>Scanner: Reads your <code>trace.json</code> (The Evidence).</li> <li>Planner: Decides which sections of Annex IV apply to your specific model type.</li> <li>Writer: Drafts \"Section 2.c: Architecture\" using the <code>summary()</code> from your actual Python code.</li> <li>Critic: Reviews the draft against the ISO 42001 standard.</li> </ol> <p>Result: A markdown file (<code>Annex_IV.md</code>) that cites your specific accuracy scores (e.g., <code>Demographic Parity: 0.92</code>) as proof of safety.</p>"},{"location":"academy/level4_annex_iv/#4-selecting-your-llm","title":"4. Selecting your LLM","text":"Feature Cloud (Mistral API) Local (Ollama) Sovereign (ALIA - Experimental) Privacy \u2601\ufe0f Encrypted Transport \ud83d\udd12 100% Offline \ud83d\udee1\ufe0f Hardware Locked Sovereignty \ud83c\uddeb\ud83c\uddf7 Hosted in EU \u2705 Generic \ud83c\uddea\ud83c\uddf8 Spanish Native Speed \u26a1 Fast (Large Model) \ud83d\udc22 Slower \ud83d\udc22 Slow (Experimental) Use Case Final High-Quality Polish Iterative Testing Research Only <p>We currently offer ALIA as an experimental feature for organizations piloting Spanish-native sovereign AI.</p> <p>Experimental Feature &amp; Hardware Requirements</p> <p>ALIA is a 40B parameter model. It is marked as EXPERIMENTAL and requires significant hardware resources:</p> <ul> <li>RAM/VRAM: ~41GB required (Q8 quantization).</li> <li>GPU: A high-end GPU (e.g., RTX 3090/4090 with 24GB+) is recommended for usable speeds.</li> <li>Performance: On consumer hardware or smaller GPUs (like RTX 2000), inference will effectively run on CPU and be very slow.</li> </ul>"},{"location":"academy/level4_annex_iv/#5-export-to-pdf","title":"5. Export to PDF","text":"<p>By default, we generate <code>Annex_IV.md</code> (Markdown) for version control. To convert this to a regulatory-grade PDF:</p> Python (mdpdf)Pandoc (Advanced) <pre><code>uv pip install mdpdf\nuv run mdpdf Annex_IV.md\n</code></pre> <pre><code>pandoc Annex_IV.md -o Annex_IV.pdf --toc --pdf-engine=xelatex\n</code></pre>"},{"location":"academy/level4_annex_iv/#6-take-home-messages","title":"6. Take Home Messages \ud83c\udfe0","text":"<ol> <li>Documentation is a Function: <code>f(Evidence) -&gt; Document</code>. Never write what you can generate.</li> <li>LiveTrace: If your accuracy drops tomorrow, regenerate the document. It will reflect the current state, preventing \"Documentation Drift\".</li> <li>The Full Loop: You have gone from Code -&gt; Policy (L1) -&gt; Ops (L2) -&gt; Evidence (L3) -&gt; Legal Document (L4).</li> </ol>"},{"location":"academy/level4_annex_iv/#congratulations","title":"\ud83c\udf89 Congratulations!","text":"<p>You have completed the Ventural\u00edtica Academy. You are now ready to integrate this into your own CI/CD pipeline.</p> <p>\ud83d\udc49 Deep Dive: MLOps Integration \ud83d\udc49 Deep Dive: Training Loop</p>"},{"location":"tutorials/01_writing_policy/","title":"\ud83d\udee0\ufe0f Writing Code-First Policy (The Engineer)","text":"<p>This guide focuses on the Engineer Persona: the one who translates legal requirements into technical rules (OSCAL). In Level 1, you learned to \"Block\" bad deployments. Now we will write the actual policy file that governs the project.</p>"},{"location":"tutorials/01_writing_policy/#the-policy-file-data_policyyaml","title":"The Policy File (<code>data_policy.yaml</code>)","text":"<p>For Phase 1 (Data Audit), we only care about Article 10 (Data Governance). Your Data Scientist (The Builder) cannot start training until this file is ready.</p>"},{"location":"tutorials/01_writing_policy/#1-the-structure","title":"1. The Structure","text":"<p>Create a file named <code>data_policy.yaml</code> in your project root.</p> <pre><code>assessment-plan:\n  uuid: credit-scoring-v1\n  metadata:\n    title: \"Article 10: Consumer Credit Directive (CCD)\"\n    description: \"Acceptance criteria for training data quality and bias.\"\n  reviewed-controls:\n    control-selections:\n      - include-controls:\n        # RULES GO HERE\n</code></pre>"},{"location":"tutorials/01_writing_policy/#2-defining-the-rules-controls","title":"2. Defining the Rules (Controls)","text":"<p>A \"Control\" is a unit of logic. In the EU AI Act, you must prove you checked for specific risks.</p>"},{"location":"tutorials/01_writing_policy/#rule-a-representation-statistical-support","title":"Rule A: Representation (Statistical Support)","text":"<ul> <li>Legal Requirement: \"Training, validation and testing data sets shall be relevant, representative, free of errors and complete.\" (Art 10.3)</li> <li>Translation: Ensure no demographic group is erased (Min 20% representation).</li> </ul> <pre><code>        - control-id: check-imbalance\n          description: \"Ensure minority groups are statistically significant.\"\n          props:\n            - name: metric_key\n              value: min_class_ratio\n            - name: threshold\n              value: \"0.20\"  # Fail if minority class &lt; 20%\n            - name: operator\n              value: \"&gt;\"\n</code></pre>"},{"location":"tutorials/01_writing_policy/#rule-b-bias-disparate-impact","title":"Rule B: Bias (Disparate Impact)","text":"<ul> <li>Legal Requirement: \"Examination of possible biases.\" (Art 10.2.f)</li> <li>Translation: Acceptance rates must not deviate by more than 20% between groups (Four-Fifths Rule).</li> </ul> <pre><code>        - control-id: check-gender-bias\n          description: \"Disparate Impact Ratio must be within 0.8 - 1.25\"\n          props:\n            - name: metric_key\n              value: disparate_impact_ratio\n            - name: threshold\n              value: \"0.80\"\n            - name: operator\n              value: \"&gt;\"\n</code></pre>"},{"location":"tutorials/01_writing_policy/#3-verify-the-policy","title":"3. Verify the Policy","text":"<p>Before handing it off to the Data Scientist, verify it works.</p> <pre><code>import venturalitica as vl\nfrom venturalitica.quickstart import load_sample\n\n# 1. Load the 'Approved' Dataset (Mock)\ndata = load_sample('loan')\n\n# 2. Dry Run the Policy\ntry:\n    vl.enforce(\n        data=data,\n        target=\"class\",\n        gender=\"Attribute9\",  # \"Personal status and sex\" in German Credit Data\n        policy=\"data_policy.yaml\"\n    )\n    print(\"\u2705 Policy is valid syntax and passes baseline data.\")\nexcept Exception as e:\n    print(f\"\u274c Policy Error: {e}\")\n</code></pre>"},{"location":"tutorials/01_writing_policy/#part-2-the-model-policy-model_policyyaml","title":"Part 2: The Model Policy (<code>model_policy.yaml</code>)","text":"<p>Once the data is approved, you need to define the rules for the final product (the trained model). This corresponds to Article 15 (Accuracy, Robustness, and Cybersecurity).</p> <p>Create a second file: <code>model_policy.yaml</code>.</p>"},{"location":"tutorials/01_writing_policy/#rule-c-performance-accuracy","title":"Rule C: Performance (Accuracy)","text":"<ul> <li>Legal Requirement: \"High-risk AI systems shall be designed ... to achieve an appropriate level of accuracy.\" (Art 15.1)</li> <li>Translation: The model must be better than random guessing (e.g., &gt; 70% accuracy).</li> </ul> <pre><code>        - control-id: accuracy-check\n          description: \"Model must achieve at least 70% accuracy.\"\n          props:\n            - name: metric_key\n              value: accuracy_score\n            - name: threshold\n              value: \"0.70\"\n            - name: operator\n              value: \"&gt;\"\n</code></pre>"},{"location":"tutorials/01_writing_policy/#rule-d-post-training-fairness-outcome","title":"Rule D: Post-Training Fairness (Outcome)","text":"<ul> <li>Legal Requirement: \"Results shall not be biased...\"</li> <li>Translation: Even if data was balanced, the model might still learn to discriminate. Check the predictions again.</li> </ul> <pre><code>        - control-id: gender-fairness-model\n          description: \"Ensure model predictions do not disparately impact women.\"\n          props:\n            - name: metric_key\n              value: disparate_impact_ratio\n            - name: \"input:dimension\"\n              value: \"gender\"         # Explicitly link to the gender column\n            - name: threshold\n              value: \"0.80\"\n            - name: operator\n              value: \"&gt;\"\n</code></pre>"},{"location":"tutorials/01_writing_policy/#whats-next","title":"What's Next?","text":"<p>You have now created the specification. \ud83d\udc49 Hand these files (<code>data_policy.yaml</code> and <code>model_policy.yaml</code>) to your Data Scientist. They will use them in Level 2 to audit their training pipeline.</p>"},{"location":"es/","title":"Ventural\u00edtica SDK","text":"<p>Gobernanza \"Sin Fricci\u00f3n\" para Sistemas de IA.</p> <p>Ventural\u00edtica SDK integra la gobernanza de IA directamente en tu c\u00f3digo Python. Convierte pol\u00edticas legales abstractas (como la norma EU AI Act) en Tests Unitarios Ejecutables.</p>"},{"location":"es/#por-que-venturalitica","title":"\u26a1 \u00bfPor qu\u00e9 Ventural\u00edtica?","text":""},{"location":"es/#cumplimiento-como-codigo","title":"\ud83d\udee1\ufe0f Cumplimiento como C\u00f3digo","text":"<p>Deja de luchar con PDFs legales. Define tus pol\u00edticas en OSCAL (el est\u00e1ndar de NIST) y ejec\u00fatalas autom\u00e1ticamente en tu pipeline de MLOps.</p>"},{"location":"es/#caja-de-cristal-glass-box-transparency","title":"\ud83d\udd0d Caja de Cristal (Glass Box Transparency)","text":"<p>Genera autom\u00e1ticamente la documentaci\u00f3n t\u00e9cnica requerida por el Anexo IV de la EU AI Act y normas ISO 42001.</p>"},{"location":"es/#soberania-local-privacy-first","title":"\ud83c\uddea\ud83c\uddfa Soberan\u00eda Local (Privacy-First)","text":"<p>Tu c\u00f3digo, tus datos, tu infraestructura. El SDK se ejecuta 100% en local. Ni un solo byte de tus datos de entrenamiento sale de tu servidor.</p>"},{"location":"es/#inicio-rapido","title":"\ud83d\ude80 Inicio R\u00e1pido","text":"<p>Instala la librer\u00eda:</p> <pre><code>pip install venturalitica\n</code></pre> <p>Ejecuta tu primera auditor\u00eda de sesgo (Bias Audit):</p> <pre><code>import venturalitica as vl\n\n# Carga un dataset de ejemplo y aud\u00edtalo contra la EU AI Act\nresultados = vl.quickstart('loan')\n</code></pre> <p>Resultado en consola: <pre><code>[Ventural\u00edtica] \ud83c\udf93 Escenario: Credit Scoring Fairness\n[Ventural\u00edtica] \ud83d\udee1\ufe0f  Pol\u00edtica: EU AI Act - Pr\u00e9stamos Justos\n\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Resultados de Auditor\u00eda \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Control  \u2502 M\u00e9trica              \u2502 Valor \u2502 Estado \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 fair-gen \u2502 demographic_parity   \u2502 0.08  \u2502 \u2713 PASS \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\n\ud83c\udf89 \u00a1Todas las m\u00e9tricas de equidad aprobadas!\n</code></pre></p>"},{"location":"es/#documentacion","title":"\ud83d\udcda Documentaci\u00f3n","text":"<ul> <li>Tutorial: Primera Auditor\u00eda</li> <li>Integraci\u00f3n con Entrenamiento (MLOps)</li> <li>El Mapa Regulatorio (Art 9-15)</li> <li>Referencia de API</li> </ul>"},{"location":"es/#arquitectura","title":"\ud83c\udfd7\ufe0f Arquitectura","text":"<p>El SDK act\u00faa como un puente entre tus datos y la regulaci\u00f3n:</p> <pre><code>graph LR\n    A[Datos / Modelo] --&gt; B(SDK Ventural\u00edtica);\n    C[Pol\u00edtica OSCAL] --&gt; B;\n    B --&gt; D{Validador};\n    D --&gt;|Cumple| E[Log MLflow / WandB];\n    D --&gt;|Falla| F[Alerta Bloqueante];\n</code></pre>      Hecho con \u2764\ufe0f en Europa para una IA confiable."},{"location":"es/annex-iv/","title":"Generando Documentaci\u00f3n T\u00e9cnica (Anexo IV)","text":"<p>Una de las partes m\u00e1s tediosas de la Ley de IA de la UE es el Anexo IV: el requisito de mantener documentaci\u00f3n t\u00e9cnica actualizada.</p> <p>Ventural\u00edtica automatiza esto tratando tus trazas de ejecuci\u00f3n de c\u00f3digo como la fuente de verdad.</p>"},{"location":"es/annex-iv/#el-generador-del-anexo-iv","title":"El Generador del Anexo IV","text":"<p>Puedes generar un borrador conforme de tu Documentaci\u00f3n T\u00e9cnica directamente desde el Panel de Ventural\u00edtica.</p>"},{"location":"es/annex-iv/#paso-1-lanzar-el-panel","title":"Paso 1: Lanzar el Panel","text":"<p>Ejecuta la UI desde tu terminal en la ra\u00edz de tu proyecto:</p> <pre><code>venturalitica ui\n</code></pre>"},{"location":"es/annex-iv/#paso-2-navegar-al-generador-de-anexo-iv","title":"Paso 2: Navegar al \"Generador de Anexo IV\"","text":"<p>En la barra lateral izquierda, busca la secci\u00f3n GENERAR REPORTES.</p> <ol> <li>Haz clic en \ud83d\udcc4 technical_doc.md.</li> <li>El sistema analizar\u00e1 tu carpeta local <code>.venturalitica/</code>.</li> <li>Extraer\u00e1:<ul> <li>Arquitectura del Sistema (de <code>bom.json</code>)</li> <li>Estado de Gesti\u00f3n de Riesgos (de los Resultados de Auditor\u00eda del Art\u00edculo 9)</li> <li>Gobernanza de Datos (de los Resultados de Auditor\u00eda del Art\u00edculo 10)</li> <li>Ciberseguridad (de los escaneos CVE)</li> </ul> </li> </ol>"},{"location":"es/annex-iv/#paso-3-descargar-el-borrador","title":"Paso 3: Descargar el Borrador","text":"<p>Ver\u00e1s una vista previa en vivo del archivo markdown generado.</p> <ul> <li>Haz clic en Descargar Borrador para guardarlo como <code>Anexo_IV_Borrador.md</code>.</li> <li>Luego puedes convertir este archivo Markdown a PDF usando tu herramienta preferida (ej., Pandoc o VS Code).</li> </ul> <p>Actualizaciones Din\u00e1micas</p> <p>Cada vez que ejecutas <code>vl.enforce()</code>, la evidencia subyacente se actualiza. Generar un nuevo reporte siempre reflejar\u00e1 el \u00faltimo estado de tu sistema.</p>"},{"location":"es/annex-iv/#via-cli-alternativa","title":"V\u00eda CLI (Alternativa)","text":"<p>Para canalizaciones de CI/CD, tambi\u00e9n puedes generar esta documentaci\u00f3n sin abrir la UI:</p> <pre><code>venturalitica doc --output docs/technical_file.md\n</code></pre> <p>Este comando realiza la misma l\u00f3gica pero guarda el archivo directamente en tu ruta especificada.</p>"},{"location":"es/api/","title":"Referencia de API","text":"<p>Ventural\u00edtica proporciona una interfaz simple y unificada para la gobernanza de IA.</p>"},{"location":"es/api/#funciones-principales","title":"\ud83d\ude80 Funciones Principales","text":""},{"location":"es/api/#quickstartscenario-verbosetrue","title":"<code>quickstart(scenario, verbose=True)</code>","text":"<p>Ejecuta una demostraci\u00f3n de auditor\u00eda de sesgo preconfigurada en un conjunto de datos est\u00e1ndar.</p> Par\u00e1metro Tipo Descripci\u00f3n <code>scenario</code> <code>str</code> Escenario predefinido: <code>'loan'</code>, <code>'hiring'</code>, <code>'health'</code>. <code>verbose</code> <code>bool</code> Si imprimir el reporte de tabla estructurado en la consola. <p>Retorna: <code>List[ComplianceResult]</code></p>"},{"location":"es/api/#enforcedata-target-predictionnone-policynone-attributes","title":"<code>enforce(data, target, prediction=None, policy=None, **attributes)</code>","text":"<p>El punto de entrada principal para auditar conjuntos de datos y modelos.</p> Par\u00e1metro Tipo Descripci\u00f3n <code>data</code> <code>DataFrame</code> DataFrame de Pandas conteniendo caracter\u00edsticas, objetivos, y opcionalmente predicciones. <code>target</code> <code>str</code> Nombre de la columna con etiquetas de verdad fundamental. <code>prediction</code> <code>str\\|array</code> (Opcional) Nombre de columna o array de predicciones del modelo. <code>policy</code> <code>str</code> Ruta al archivo de pol\u00edtica OSCAL/YAML. <code>**attributes</code> <code>str</code> Mapeos para variables protegidas (ej., <code>gender=\"attr9\"</code>, <code>age=\"age_col\"</code>). <p>Retorna: <code>List[ComplianceResult]</code></p> <p>Note</p> <p>Si se omite <code>prediction</code>, las m\u00e9tricas de equidad recurren autom\u00e1ticamente a usar <code>target</code> para auditar el sesgo de datos.</p>"},{"location":"es/api/#wrapmodel-policy-experimental","title":"<code>wrap(model, policy)</code> (Experimental)","text":"<p>VISTA PREVIA</p> <p>Esta funci\u00f3n es experimental y su API podr\u00eda cambiar.</p> <p>Audita transparentemente tu modelo durante flujos de trabajo est\u00e1ndar de Scikit-Learn.</p> Par\u00e1metro Tipo Descripci\u00f3n <code>model</code> <code>object</code> Cualquier clasificador o regresor compatible con Scikit-learn. <code>policy</code> <code>str</code> Ruta a la pol\u00edtica para evaluaci\u00f3n. <p>Retorna: <code>GovernanceWrapper</code> (Preserva la API original como <code>.fit()</code> y <code>.predict()</code>).</p>"},{"location":"es/api/#monitorname","title":"<code>monitor(name)</code>","text":"<p>Un gestor de contexto para rastrear m\u00e9tricas de entrenamiento, salud del hardware e impacto ambiental.</p> <pre><code>with vl.monitor(name=\"CreditModel-v1\"):\n    model.fit(X, y)\n</code></pre> <p>Telemetr\u00eda Recolectada:</p> <ul> <li>\u23f1 Duraci\u00f3n: Tiempo de ejecuci\u00f3n del bloque.</li> <li>\ud83c\udf31 Emisiones: Huella de carbono (requiere <code>codecarbon</code>).</li> <li>\ud83d\udee1 Estabilidad: Huella digital del modelo y verificaci\u00f3n de integridad.</li> </ul>"},{"location":"es/api/#funciones-de-utilidad","title":"\ud83d\udee0 Funciones de Utilidad","text":""},{"location":"es/api/#list_scenarios","title":"<code>list_scenarios()</code>","text":"<p>Retorna un diccionario de escenarios disponibles y sus descripciones.</p>"},{"location":"es/api/#load_samplescenario","title":"<code>load_sample(scenario)</code>","text":"<p>Carga el conjunto de datos UCI correspondiente para un escenario como un DataFrame de Pandas.</p>"},{"location":"es/compliance-dashboard/","title":"El Panel de Cumplimiento: Una Caja de Cristal para la IA","text":"<p>El Panel de Cumplimiento de Ventural\u00edtica es tu centro de control local para la Gobernanza de IA. A diferencia de las herramientas de cumplimiento de \"Caja Negra\" que operan a puerta cerrada, Ventural\u00edtica proporciona una experiencia de Caja de Cristal: expone la evidencia t\u00e9cnica exacta que tu sistema est\u00e1 produciendo y la mapea directamente a las obligaciones regulatorias.</p> <p>El panel hace concreto lo abstracto. Toma los artefactos invisibles de tu canalizaci\u00f3n de ML\u2014m\u00e9tricas, registros, dependencias\u2014y los convierte en una Matriz de Trazabilidad Regulatoria.</p>"},{"location":"es/compliance-dashboard/#el-mapa-regulatorio-secuencial-articulos-9-15","title":"El Mapa Regulatorio Secuencial (Art\u00edculos 9-15)","text":"<p>La caracter\u00edstica central del panel es el estricto mapeo secuencial de los requisitos de la Ley de IA de la UE para Sistemas de IA de Alto Riesgo (Cap\u00edtulo III, Secci\u00f3n 2). Esta \"Caminata de Cumplimiento\" te gu\u00eda a trav\u00e9s del ciclo de vida de un sistema conforme.</p>"},{"location":"es/compliance-dashboard/#el-flujo-de-trazabilidad","title":"El Flujo de Trazabilidad","text":"<p> # Note: adjusted path</p>"},{"location":"es/compliance-dashboard/#1-articulo-9-sistema-de-gestion-de-riesgos","title":"1. Art\u00edculo 9: Sistema de Gesti\u00f3n de Riesgos","text":"<ul> <li>La Ley: Debes identificar y mitigar riesgos para la salud, seguridad y derechos fundamentales.</li> <li>El C\u00f3digo: Ventural\u00edtica mapea tus Auditor\u00edas de Equidad aqu\u00ed. Si ejecutas una verificaci\u00f3n de sesgo (ej. <code>gender-bias</code>), el resultado es la evidencia t\u00e9cnica de que est\u00e1s monitoreando riesgos de Derechos Fundamentales.</li> <li>Estado:<ul> <li><code>Mitigaci\u00f3n Verificada</code>: Tus pruebas de equidad pasaron.</li> <li><code>Riesgo Materializado</code>: Una prueba fall\u00f3 (ej. Impacto Dispar detectado).</li> </ul> </li> </ul>"},{"location":"es/compliance-dashboard/#2-articulo-10-gobernanza-de-datos","title":"2. Art\u00edculo 10: Gobernanza de Datos","text":"<ul> <li>La Ley: Los datos de entrenamiento, validaci\u00f3n y prueba deben ser relevantes, representativos y libres de errores.</li> <li>El C\u00f3digo: Mapea a tus Verificaciones de Calidad de Datos (ej. desequilibrio de clases, valores faltantes) y uso de bibliotecas de datos (<code>pandas</code>, <code>numpy</code>).</li> <li>Estado: Marca si la validaci\u00f3n de datos fue omitida o fall\u00f3.</li> </ul>"},{"location":"es/compliance-dashboard/#3-articulo-11-documentacion-tecnica","title":"3. Art\u00edculo 11: Documentaci\u00f3n T\u00e9cnica","text":"<ul> <li>La Ley: Debes mantener documentaci\u00f3n t\u00e9cnica actualizada demostrando conformidad.</li> <li>El C\u00f3digo: Verifica la presencia de tu Lista de Materiales de Software (SBOM) (generada por <code>venturalitica scan</code>) y el Borrador de Archivo T\u00e9cnico (generado por <code>venturalitica doc</code>).</li> <li>Estado: Verde si existen artefactos; Amarillo/Rojo si falta documentaci\u00f3n.</li> </ul> <p> # Note: adjusted path</p>"},{"location":"es/compliance-dashboard/#4-articulo-12-mantenimiento-de-registros","title":"4. Art\u00edculo 12: Mantenimiento de Registros","text":"<ul> <li>La Ley: Registro autom\u00e1tico de eventos durante la vida del sistema para asegurar trazabilidad.</li> <li>El C\u00f3digo: Verifica dos componentes cr\u00edticos:<ul> <li>Anclaje Criptogr\u00e1fico: Muestra el hash SHA-256 de tu evidencia, probando la integridad de los datos.</li> <li>Trazas de Ejecuci\u00f3n: Confirma que los metadatos de tiempo de ejecuci\u00f3n (<code>runtime_meta</code>) fueron capturados durante el entrenamiento/inferencia.</li> </ul> </li> </ul>"},{"location":"es/compliance-dashboard/#5-articulo-13-transparencia-e-informacion","title":"5. Art\u00edculo 13: Transparencia e Informaci\u00f3n","text":"<ul> <li>La Ley: El sistema debe ser suficientemente transparente para permitir a los usuarios interpretar los resultados.</li> <li>El C\u00f3digo: Verifica la Opacidad del C\u00f3digo. \u00bfEs accesible el c\u00f3digo fuente para auditor\u00eda? \u00bfSe proporcionan instrucciones?</li> </ul>"},{"location":"es/compliance-dashboard/#6-articulo-14-supervision-humana","title":"6. Art\u00edculo 14: Supervisi\u00f3n Humana","text":"<ul> <li>La Ley: El sistema debe estar dise\u00f1ado para ser supervisado por personas naturales (humano en el bucle).</li> <li>El C\u00f3digo: Escanea en busca de l\u00f3gica de \"Bot\u00f3n de Parada\" o interfaces interactivas (ej. aplicaciones Streamlit, notebooks Jupyter) que impliquen capacidad de control humano.</li> </ul>"},{"location":"es/compliance-dashboard/#7-articulo-15-precision-robustez-y-ciberseguridad","title":"7. Art\u00edculo 15: Precisi\u00f3n, Robustez y Ciberseguridad","text":"<ul> <li>La Ley: El sistema debe ser resistente a errores y ataques.</li> <li>El C\u00f3digo:<ul> <li>Precisi\u00f3n: Mapea a tus M\u00e9tricas de Rendimiento (Accuracy, F1, Recall).</li> <li>Ciberseguridad: Verifica Vulnerabilidades de Cadena de Suministro (CVEs) en tus dependencias a trav\u00e9s del escaneo SBOM.</li> </ul> </li> </ul>"},{"location":"es/compliance-dashboard/#por-que-importa-esto","title":"Por Qu\u00e9 Importa Esto","text":"<p>Este dise\u00f1o secuencial transforma el cumplimiento de una lista de verificaci\u00f3n ca\u00f3tica en un flujo de trabajo de ingenier\u00eda l\u00f3gico:</p> <ol> <li>Evaluar Riesgo (Art 9)</li> <li>Limpiar Datos (Art 10)</li> <li>Documentarlo (Art 11)</li> <li>Registrarlo (Art 12)</li> <li>Explicarlo (Art 13)</li> <li>Controlarlo (Art 14)</li> <li>Asegurarlo (Art 15)</li> </ol> <p>Al seguir este flujo, est\u00e1s alineando estructuralmente tu sistema de IA con la ley, l\u00ednea por l\u00ednea.</p>"},{"location":"es/compliance-gap/","title":"La Brecha de Cumplimiento (Hoja de Ruta)","text":"<p>Ventural\u00edtica v0.4 proporciona la base para la IA de Caja de Cristal, pero los sistemas de alto riesgo (Ley de IA de la UE) requieren una mejora continua. Este documento identifica las brechas t\u00e9cnicas actuales y las caracter\u00edsticas requeridas para convertir la \"Evidencia T\u00e9cnica\" en \"Certeza Legal\".</p>"},{"location":"es/compliance-gap/#brechas-recientemente-cerradas-v04","title":"\u2705 Brechas Recientemente Cerradas (v0.4)","text":"<p>La \"Auditor\u00eda Estrat\u00e9gica Profunda\" y el lanzamiento de la Academy han cerrado las siguientes brechas cr\u00edticas:</p>"},{"location":"es/compliance-gap/#1-documentacion-tecnica-articulo-11","title":"1. Documentaci\u00f3n T\u00e9cnica (Art\u00edculo 11)","text":"<ul> <li>Brecha Anterior: Redacci\u00f3n manual de archivos t\u00e9cnicos.</li> <li>Soluci\u00f3n: El Generador del Anexo IV (Mistral &amp; ALIA IA Soberana) ahora automatiza la redacci\u00f3n de documentos regulatorios.</li> </ul>"},{"location":"es/compliance-gap/#2-transparencia-y-confianza-articulo-13","title":"2. Transparencia y Confianza (Art\u00edculo 13)","text":"<ul> <li>Brecha Anterior: Sin prueba de cumplimiento de cara al p\u00fablico.</li> <li>Soluci\u00f3n: El Sello Digital. En lugar de una insignia SVG est\u00e1tica, Ventural\u00edtica ahora aplica un hash a la Evidencia de Traza (SHA-256) para crear una firma criptogr\u00e1fica a prueba de manipulaciones.</li> </ul>"},{"location":"es/compliance-gap/#3-eficiencia-de-recursos-articulo-15","title":"3. Eficiencia de Recursos (Art\u00edculo 15)","text":"<ul> <li>Brecha Anterior: Sin seguimiento del uso de energ\u00eda o hardware.</li> <li>Soluci\u00f3n: <code>vl.monitor()</code> ahora registra autom\u00e1ticamente las emisiones de CO2 y el consumo de GPU/RAM.</li> </ul>"},{"location":"es/compliance-gap/#caracteristicas-faltantes-y-brechas-abiertas","title":"\ud83d\udee0 Caracter\u00edsticas Faltantes y Brechas Abiertas","text":""},{"location":"es/compliance-gap/#1-endurecimiento-de-evidencia-articulo-12","title":"1. Endurecimiento de Evidencia (Art\u00edculo 12)","text":"<ul> <li>Estado Actual: Hashing SHA-256 de archivos de evidencia (El \"Sello Digital\").</li> <li>La Brecha: Sin Firma Digital nativa (No repudio).</li> <li>Requisito: Implementaci\u00f3n de firma GPG/X.509 para archivos <code>trace.json</code> para asegurar que no puedan ser falsificados ni siquiera por el propietario del sistema.</li> </ul>"},{"location":"es/compliance-gap/#2-gobernanza-de-datos-profunda-articulo-10","title":"2. Gobernanza de Datos Profunda (Art\u00edculo 10)","text":"<ul> <li>Estado Actual: Balance de clases b\u00e1sico y verificaciones de valores faltantes.</li> <li>La Brecha: Falta de Linaje de Datos y Procedencia de Anotaciones.</li> <li>Requisito: Herramientas para registrar la fuente de las etiquetas, m\u00e9tricas de acuerdo entre anotadores y detecci\u00f3n de \"envenenamiento\" para conjuntos de entrenamiento.</li> </ul>"},{"location":"es/compliance-gap/#3-verificaciones-interactivas-de-supervision-humana-articulo-14","title":"3. Verificaciones Interactivas de Supervisi\u00f3n Humana (Art\u00edculo 14)","text":"<ul> <li>Estado Actual: Verificaci\u00f3n est\u00e1tica para elementos interactivos (an\u00e1lisis AST).</li> <li>La Brecha: Sin verificaci\u00f3n en tiempo de ejecuci\u00f3n de acciones \"Humano-en-la-bucle\" (HITL).</li> <li>Requisito: Un envoltorio <code>vl.oversight()</code> para registrar cu\u00e1ndo un humano realmente aprueba/rechaza una predicci\u00f3n de alto riesgo en producci\u00f3n.</li> </ul>"},{"location":"es/compliance-gap/#4-robustez-adversarial-articulo-15","title":"4. Robustez Adversarial (Art\u00edculo 15)","text":"<ul> <li>Estado Actual: Seguimiento de Eficiencia y Precisi\u00f3n (<code>vl.monitor</code>).</li> <li>La Brecha: Sin Esc\u00e1neres de Ataques nativos para seguridad.</li> <li>Requisito: Integraci\u00f3n con bibliotecas de robustez (ej. ART, CleverHans) para automatizar pruebas adversariales como parte del pipeline <code>enforce()</code>.</li> </ul>"},{"location":"es/compliance-gap/#5-mitigacion-de-sesgo-automatizada","title":"5. Mitigaci\u00f3n de Sesgo Automatizada","text":"<ul> <li>Estado Actual: Solo detecci\u00f3n.</li> <li>La Brecha: Fricci\u00f3n al corregir el sesgo detectado.</li> <li>Requisito: Integraci\u00f3n con Fairlearn/AIF360 para \"mitigaciones sugeridas\" directamente en el Panel de Control.</li> </ul>"},{"location":"es/compliance-gap/#propon-una-caracteristica","title":"\ud83d\ude80 Prop\u00f3n una Caracter\u00edstica","text":"<p>Estamos construyendo el futuro de la IA Responsable. Si tienes un requisito espec\u00edfico para cumplir un mandato de cumplimiento, queremos escucharte.</p> <ol> <li>Abre un GitHub Issue.</li> <li>Etiqu\u00e9talo como <code>feature-request</code> + <code>compliance-gap</code>.</li> <li>Describe el Art\u00edculo Legal (ej. Art 13) o Dolor T\u00e9cnico que est\u00e1s abordando.</li> </ol> <p>Ver Discusiones de Hoja de Ruta</p>"},{"location":"es/evidence-collection/","title":"Recopilaci\u00f3n de Evidencia: La Caja Negra","text":"<p>Mientras que las Pol\u00edticas (el Ejecutor) detienen modelos defectuosos antes de llegar a producci\u00f3n, la Recopilaci\u00f3n de Evidencia (el Registrador) asegura que puedas probar exactamente qu\u00e9 sucedi\u00f3 durante el entrenamiento. Esta es tu \"Caja Negra\" de vuelo para la IA.</p> <p>En Ventural\u00edtica, la recopilaci\u00f3n de evidencia es distinta de la aplicaci\u00f3n de pol\u00edticas. Puedes registrar evidencia sin bloquear un despliegue, o aplicar estrictamente sin guardar trazas. Sin embargo, para el cumplimiento total de la Ley de IA de la UE (Art\u00edculo 12: Mantenimiento de Registros), necesitas ambos.</p>"},{"location":"es/evidence-collection/#dos-formas-de-registrar","title":"Dos Formas de Registrar","text":""},{"location":"es/evidence-collection/#1-el-envoltorio-automatico-vlwrap","title":"1. El Envoltorio Autom\u00e1tico (<code>vl.wrap</code>)","text":"<p>La forma m\u00e1s f\u00e1cil de recopilar evidencia es envolver tu estimador. Esto se conecta autom\u00e1ticamente a <code>.fit()</code> y <code>.predict()</code> para capturar entradas, salidas y metadatos.</p> <pre><code>import venturalitica as vl\nfrom sklearn.ensemble import RandomForestClassifier\n\n# 1. Envolver el modelo\nmodel = vl.wrap(RandomForestClassifier(), policy=\"model_policy.yaml\")\n\n# 2. Entrenar como siempre (La evidencia se recolecta autom\u00e1ticamente)\nmodel.fit(X_train, y_train, audit_data=train_df, gender=\"Attribute9\")\n</code></pre> <p>\u00bfQu\u00e9 se registra? *   Marca de tiempo: Tiempos precisos de inicio/fin. *   Configuraci\u00f3n del Modelo: Hiperpar\u00e1metros (<code>n_estimators</code>, <code>max_depth</code>, etc.). *   Forma de Datos: N\u00famero de filas/columnas usadas. *   Contexto de C\u00f3digo: El nombre del archivo y an\u00e1lisis AST del script que llam\u00f3 a <code>fit</code>.</p>"},{"location":"es/evidence-collection/#2-el-monitor-multimodal-vlmonitor","title":"2. El Monitor Multimodal (<code>vl.monitor</code>)","text":"<p>Para bucles de entrenamiento personalizados (ej. PyTorch, TensorFlow) o pipelines complejos donde <code>fit()</code> no es suficiente, usa el gestor de contexto.</p> <pre><code>import venturalitica as vl\n\n# Iniciar la sesi\u00f3n de grabaci\u00f3n\nwith vl.monitor(\"training_run_v1\"):\n    # Tu l\u00f3gica personalizada aqu\u00ed\n    model = train_custom_model(data)\n    evaluate_model(model)\n\n# La evidencia se guarda en .venturalitica/trace_training_run_v1.json\n</code></pre>"},{"location":"es/evidence-collection/#a-donde-va-la-evidencia","title":"\u00bfA d\u00f3nde va la evidencia?","text":"<p>Toda la evidencia se asegura localmente en el directorio <code>.venturalitica/</code>:</p> <ul> <li><code>results.json</code>: El resultado de tus auditor\u00edas de pol\u00edtica (Pasa/Falla).</li> <li><code>trace_{name}.json</code>: Los metadatos de ejecuci\u00f3n (marcas de tiempo, an\u00e1lisis de c\u00f3digo).</li> <li><code>bom.json</code>: El inventario de la cadena de suministro de software (dependencias).</li> </ul>"},{"location":"es/evidence-collection/#impacto-en-el-cumplimiento","title":"Impacto en el Cumplimiento","text":"<p>Para el Art\u00edculo 12 (Ley de IA de la UE), esta evidencia es obligatoria. El Panel de Ventural\u00edtica lee estos archivos para probar: 1.  Trazabilidad: \"Sabemos exactamente qu\u00e9 c\u00f3digo y datos produjeron el Modelo v1.0.\" 2.  Integridad: \"La evidencia no ha sido manipulada\" (mediante anclaje SHA-256).</p> <p>Ver tus Trazas</p> <p>Despu\u00e9s de ejecutar tu script de entrenamiento, lanza el panel (<code>venturalitica ui</code>) para visualizar estas trazas en la secci\u00f3n del Art\u00edculo 12.</p>"},{"location":"es/integrations/","title":"Integraciones MLOps (La Gu\u00eda de Operaciones)","text":"<p>Esta gu\u00eda se centra en la Persona MLOps: quien automatiza el pipeline. Ventural\u00edtica se integra estrictamente con tus herramientas existentes para asegurar que la Evidencia (Art\u00edculo 12) se recopile autom\u00e1ticamente durante tus ejecuciones de CI/CD.</p>"},{"location":"es/integrations/#el-concepto","title":"El Concepto","text":"<p>No queremos reemplazar tu pila de MLOps. Queremos certificarla.</p> Herramienta Integraci\u00f3n Beneficio MLflow / WandB <code>vl.wrap()</code> Vincula autom\u00e1ticamente la Pol\u00edtica <code>model_policy.yaml</code> a los artefactos de la ejecuci\u00f3n. Panel de Estado <code>venturalitica ui</code> Proporciona verificaciones de salud tipo \"Sem\u00e1foro\" para tu pipeline de cumplimiento."},{"location":"es/integrations/#1-versionado-regulatorio","title":"1. Versionado Regulatorio","text":"<p>Cada vez que entrenas un modelo usando <code>vl.wrap()</code> o <code>vl.monitor()</code>, Ventural\u00edtica autom\u00e1ticamente toma una instant\u00e1nea de tu pol\u00edtica de gobernanza (<code>model_policy.yaml</code>) y la sube a tu servidor de seguimiento activo.</p> <ul> <li>\u00bfPor qu\u00e9? Asegura que tu rastro de auditor\u00eda sea estrictamente reproducible. Puedes probar exactamente qu\u00e9 reglas estaban activas durante el entrenamiento (ej. \"Pol\u00edtica v1.2 vs v1.3\").</li> <li>\u00bfD\u00f3nde? Busca <code>policy_snapshot</code> en tus artefactos de MLflow o archivos de WandB.</li> </ul>"},{"location":"es/integrations/#2-guia-de-configuracion","title":"2. Gu\u00eda de Configuraci\u00f3n","text":""},{"location":"es/integrations/#weights-biases-nube","title":"Weights &amp; Biases (Nube)","text":"<p>Ventural\u00edtica detecta autom\u00e1ticamente ejecuciones de <code>wandb</code>.</p> <ol> <li>Configurar: Establece <code>WANDB_API_KEY</code> en tu <code>.env</code>.</li> <li>Ejecutar: Solo usa <code>vl.wrap(model)</code> dentro de tu script.</li> <li>Verificar: Abre <code>venturalitica ui</code> -&gt; Integraciones.</li> </ol>"},{"location":"es/integrations/#mlflow-localremoto","title":"MLflow (Local/Remoto)","text":"<p>Compatible tanto con <code>mlruns</code> locales como con Servidores de Seguimiento remotos.</p> <ol> <li>Configurar: Establece <code>MLFLOW_TRACKING_URI</code> (opcional, predeterminado a <code>./mlruns</code>).</li> <li>Ejecutar: Aseg\u00farate de que <code>mlflow.start_run()</code> est\u00e9 activo cuando llames a <code>fit()</code>.</li> <li>Verificar: La UI generar\u00e1 enlaces profundos a tu Experimento y ID de Ejecuci\u00f3n espec\u00edficos.</li> </ol>"},{"location":"es/integrations/#3-ejemplo-escenario-de-prestamo","title":"3. Ejemplo (Escenario de Pr\u00e9stamo)","text":"<p>Aqu\u00ed se muestra c\u00f3mo automatizar la Auditor\u00eda del Art\u00edculo 15 dentro de un pipeline est\u00e1ndar.</p> <pre><code>import venturalitica as vl\nimport mlflow\nfrom sklearn.ensemble import RandomForestClassifier\n\n# 1. Definir Pol\u00edtica (El Est\u00e1ndar)\npolicy = \"model_policy.yaml\"\n\n# 2. Iniciar Ejecuci\u00f3n MLOps\nwith mlflow.start_run():\n\n    # 3. Envoltura Transparente (La Capa de Gobernanza)\n    # Esto captura autom\u00e1ticamente la instant\u00e1nea 'model_policy.yaml'\n    model = vl.wrap(RandomForestClassifier(), policy=policy)\n\n    # 4. Entrenar (Evidencia y Artefactos auto-subidos)\n    model.fit(\n        X_train, y_train,\n        audit_data=train_df,\n        gender=\"Attribute9\",  # Mapeo estricto para auditor\u00eda\n        age=\"Attribute13\"\n    ) \n</code></pre>"},{"location":"es/quickstart/","title":"Inicio R\u00e1pido en 60 Segundos","text":"<p>Objetivo: Tu primera auditor\u00eda de sesgo en menos de 60 segundos.</p>"},{"location":"es/quickstart/#los-fundamentos-del-riesgo-al-codigo","title":"Los fundamentos: Del Riesgo al C\u00f3digo","text":"<p>Construir una IA de Alto Riesgo requiere un cambio fundamental en c\u00f3mo abordamos las pruebas. Ya no es suficiente verificar la precisi\u00f3n t\u00e9cnica (por ejemplo, F1 Score); ahora debemos probar matem\u00e1ticamente que el sistema respeta los derechos fundamentales, como la no discriminaci\u00f3n o la calidad de los datos, tal como lo exige la Ley de IA de la UE.</p> <p>Ventural\u00edtica automatiza esto tratando la \"Gobernanza\" como una dependencia. En lugar de vagos requisitos legales, defines pol\u00edticas estrictas (OSCAL) que tu modelo debe aprobar antes de ser desplegado. Esto convierte el cumplimiento en un problema de ingenier\u00eda determinista.</p> <p>\u00bfEs mi Sistema de Alto Riesgo?</p> <p>Seg\u00fan el Art\u00edculo 6 de la Ley de IA de la UE, un sistema es de Alto Riesgo si est\u00e1 cubierto por el Anexo I (Componentes de Seguridad como maquinaria/dispositivos m\u00e9dicos) o listado en el Anexo III (Biometr\u00eda, Infraestructura Cr\u00edtica, Educaci\u00f3n, Empleo, Servicios Esenciales, Cumplimiento de la Ley, Migraci\u00f3n, Justicia/Democracia).</p> <p>La Capa de Traducci\u00f3n:</p> <ol> <li> <p>Riesgo Fundamental: \"El modelo no debe discriminar a grupos protegidos\" (Art 9).</p> </li> <li> <p>Control de Pol\u00edtica: \"La Tasa de Impacto Dispar debe ser &gt; 0.8\".</p> </li> <li> <p>Aserci\u00f3n de C\u00f3digo: <code>assert calculated_metric &gt; 0.8</code>.</p> </li> </ol> <p>Cuando ejecutas <code>quickstart()</code>, t\u00e9cnicamente est\u00e1s ejecutando una Prueba Unitaria de \u00c9tica.</p>"},{"location":"es/quickstart/#paso-1-instalacion","title":"Paso 1: Instalaci\u00f3n","text":"<pre><code>pip install git+https://github.com/Venturalitica/venturalitica-sdk.git\n</code></pre>"},{"location":"es/quickstart/#paso-2-ejecuta-tu-primera-auditoria","title":"Paso 2: Ejecuta Tu Primera Auditor\u00eda","text":"<pre><code>import venturalitica as vl\n\nvl.quickstart('loan')\n</code></pre> <p>Salida:</p> <pre><code>[Ventural\u00edtica v0.4.1] \ud83c\udf93 Escenario: Equidad en Calificaci\u00f3n Crediticia\n[Ventural\u00edtica v0.4.1] \ud83d\udcca Cargado: UCI Dataset #144 (1000 muestras)\n\n  CONTROL                DESCRIPCION                            ACTUAL     LIMITE     RESULTADO\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  credit-data-imbalance  Calidad de Datos                       0.431      &gt; 0.2      \u2705 PASS\n  credit-data-bias       Impacto Dispar                         0.836      &gt; 0.8      \u2705 PASS\n  credit-age-disparate   Disparidad por Edad                    0.361      &gt; 0.5      \u274c FAIL\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  Resumen de Auditor\u00eda: \u274c VIOLACI\u00d3N | 2/3 controles pasados\n</code></pre> <p>Info</p> <p>La auditor\u00eda detect\u00f3 un sesgo basado en la edad en el conjunto de datos de Cr\u00e9dito Alem\u00e1n UCI.</p>"},{"location":"es/quickstart/#paso-3-que-sucede-bajo-el-capo","title":"Paso 3: Qu\u00e9 Sucede Bajo el Cap\u00f3","text":"<p>La funci\u00f3n <code>quickstart()</code> es un envoltorio que realiza el ciclo de vida completo de cumplimiento de una sola vez:</p> <ol> <li>Descarga Datos: Obtiene el conjunto de datos de Cr\u00e9dito Alem\u00e1n UCI.</li> <li>Carga Pol\u00edtica: Lee <code>risks.oscal.yaml</code> que define las reglas de equidad.</li> <li>Ejecuta: Corre la auditor\u00eda (<code>vl.enforce</code>).</li> <li>Registra: Captura la evidencia (<code>trace.json</code>) para el panel de control.</li> </ol> <p>Aqu\u00ed est\u00e1 el c\u00f3digo \"manual\" equivalente:</p> <pre><code>from ucimlrepo import fetch_ucirepo\nimport venturalitica as vl\n\n# 1. Cargar Datos (La \"Fuente de Riesgo\")\ndataset = fetch_ucirepo(id=144)\ndf = dataset.data.features\ndf['class'] = dataset.data.targets\n\n# 2. Definir la Pol\u00edtica (La \"Ley\")\n# Cargamos una pre-definida policies/risks.oscal.yaml\n\n# 3. Ejecutar la Auditor\u00eda (La \"Prueba\")\n# Esto genera autom\u00e1ticamente la Lista de Materiales de Evidencia (BOM)\nwith vl.monitor(\"manual_audit\"):\n    vl.enforce(\n        data=df,\n        target=\"class\",          # El resultado (True/False)\n        gender=\"Attribute9\",     # Grupo Protegido A\n        age=\"Attribute13\",       # Grupo Protegido B\n        policy=\"risks.oscal.yaml\"\n    )\n</code></pre>"},{"location":"es/quickstart/#la-logica-de-la-politica","title":"La L\u00f3gica de la Pol\u00edtica","text":"<p>La pol\u00edtica (<code>risks.oscal.yaml</code>) es el puente. Le dice al SDK qu\u00e9 verificar para que no tengas que codificarlo.</p> <pre><code># ... dentro del YAML OSCAL ...\n- control-id: credit-data-bias\n  description: \"La tasa de impacto dispar debe ser &gt; 0.8 (regla del 80%)\"\n  props:\n    - name: metric_key\n      value: disparate_impact   # &lt;--- La Funci\u00f3n Python a llamar\n    - name: threshold\n      value: \"0.8\"              # &lt;--- El L\u00edmite a aplicar\n    - name: operator\n      value: \"&gt;\"                # &lt;--- La L\u00f3gica (&gt; 0.8)\n    - name: \"input:dimension\"\n      value: gender             # &lt;--- Mapea a \"Attribute9\"\n</code></pre> <p>Este dise\u00f1o desacopla la Gobernanza (el archivo de pol\u00edtica) de la Ingenier\u00eda (el c\u00f3digo python).</p>"},{"location":"es/quickstart/#por-que-importa-esto","title":"Por Qu\u00e9 Importa Esto","text":"<p>Sin este mecanismo, tu modelo de IA es una \"Caja Negra\" legal:</p> <ul> <li>Responsabilidad Civil: No puedes probar que verificaste el sesgo antes del despliegue (Art 9).</li> <li>Fragilidad: El cumplimiento es una lista de verificaci\u00f3n manual, f\u00e1cil de olvidar u omitir.</li> <li>Opacidad: Los auditores no pueden ver el v\u00ednculo entre tu c\u00f3digo y la ley.</li> </ul> <p>Al ejecutar <code>quickstart()</code>, acabas de generar un Artefacto de Cumplimiento inmutable. Incluso si las leyes cambian, tu evidencia permanece.</p>"},{"location":"es/quickstart/#paso-4-el-panel-de-control-caja-de-cristal","title":"Paso 4: El Panel de Control \"Caja de Cristal\" \ud83d\udcca","text":"<p>Ahora que tenemos la evidencia (la grabaci\u00f3n de la \"Caja Negra\"), inspeccion\u00e9mosla en el Mapa Regulatorio.</p> <pre><code>venturalitica ui\n</code></pre> <p>Navega a trav\u00e9s de las pesta\u00f1as del Mapa de Cumplimiento:</p> <ul> <li>Art\u00edculo 9 (Riesgo): Ve el control fallido <code>credit-age-disparate</code>. Esta es tu evidencia t\u00e9cnica de \"Monitoreo de Riesgos\".</li> <li>Art\u00edculo 10 (Datos): Ve la distribuci\u00f3n de datos y verificaciones de calidad.</li> <li>Art\u00edculo 13 (Transparencia): Revisa el \"Feed de Transparencia\" para ver tus dependencias de Python (BOM).</li> </ul>"},{"location":"es/quickstart/#paso-5-generar-documentacion-anexo-iv","title":"Paso 5: Generar Documentaci\u00f3n (Anexo IV) \ud83d\udcdd","text":"<p>El paso final es convertir esta evidencia en un documento legal.</p> <ol> <li>En el Panel, ve a la pesta\u00f1a \"Generaci\u00f3n\".</li> <li>Selecciona \"Espa\u00f1ol\".</li> <li>Haz clic en \"Generar Anexo IV\".</li> </ol> <p>Ventural\u00edtica redactar\u00e1 un documento t\u00e9cnico que hace referencia a tu ejecuci\u00f3n espec\u00edfica:</p> <p>\"Como se evidencia en <code>trace_quickstart_loan.json</code>, el sistema fue auditado contra [Pol\u00edtica OSCAL: Equidad en Calificaci\u00f3n Crediticia]. Se detect\u00f3 una desviaci\u00f3n en la Disparidad de Edad (0.36), identificando un riesgo potencial de sesgo...\"</p>"},{"location":"es/quickstart/#referencias","title":"Referencias","text":"<ul> <li>Pol\u00edtica Usada: <code>loan/risks.oscal.yaml</code></li> <li>Base Legal:<ul> <li>Ley de IA de la UE Art\u00edculo 9 (Gesti\u00f3n de Riesgos)</li> <li>Ley de IA de la UE Art\u00edculo 11 (Documentaci\u00f3n T\u00e9cnica)</li> </ul> </li> </ul>"},{"location":"es/quickstart/#que-sigue","title":"\u00bfQu\u00e9 sigue?","text":"<ul> <li>Referencia de API - Documentaci\u00f3n completa</li> <li>Crea tu propia pol\u00edtica - Copia el YAML anterior y modifica los umbrales</li> </ul>"},{"location":"es/training/","title":"\ud83d\udee0\ufe0f Entrenamiento del Modelo (El Constructor)","text":"<p>Esta gu\u00eda se centra en la Persona del Constructor: el Cient\u00edfico de Datos que entrena el modelo. En el flujo de trabajo de Ventural\u00edtica, tu trabajo es \"fabricar\" el sistema de IA de acuerdo con las especificaciones definidas por el Ingeniero (Nivel 1).</p>"},{"location":"es/training/#el-apreton-de-manos-de-dos-politicas","title":"El Apret\u00f3n de Manos de Dos Pol\u00edticas","text":"<p>El cumplimiento no es un solo paso. Es un apret\u00f3n de manos entre Datos (Art\u00edculo 10) y Modelo (Art\u00edculo 15).</p> Fase Pol\u00edtica Art\u00edculo (Ley de IA de la UE) Funci\u00f3n 1. Auditor\u00eda de Datos <code>data_policy.yaml</code> Art. 10: Gobernanza de Datos <code>vl.enforce(data=train_df)</code> 2. Auditor\u00eda del Modelo <code>model_policy.yaml</code> Art. 15: Precisi\u00f3n y Robustez <code>vl.enforce(data=test_df, prediction=pred)</code>"},{"location":"es/training/#paso-1-cargar-y-dividir-datos","title":"Paso 1: Cargar y Dividir Datos","text":"<p>Usamos el conjunto de datos est\u00e1ndar de Evaluaci\u00f3n de Cr\u00e9dito (Loan Credit Scoring).</p> <pre><code>from ucimlrepo import fetch_ucirepo\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\n\n# 1. Obtener Datos\ndataset = fetch_ucirepo(id=144)\ndf = dataset.data.features.copy()\ndf['class'] = dataset.data.targets\n\n# 2. Dividir (Entrenamiento/Prueba)\ntrain_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n\n# 3. Codificar para Entrenamiento (One-Hot)\ndf_encoded = pd.get_dummies(df.drop(columns=['class']))\nX_train, X_test, y_train, y_test = train_test_split(\n    df_encoded, \n    df['class'].values.ravel(), \n    test_size=0.2, \n    random_state=42\n)\n</code></pre>"},{"location":"es/training/#paso-2-auditoria-pre-entrenamiento-articulo-10","title":"Paso 2: Auditor\u00eda Pre-Entrenamiento (Art\u00edculo 10)","text":"<p>Antes de invertir tiempo de c\u00f3mputo, verifica la materia prima.</p> <pre><code>import venturalitica as vl\n\n# Iniciar el 'registrador de evidencia' para la Fase de Entrenamiento\nwith vl.monitor(\"training_run_v1\"):\n\n    # \ud83d\udd0d AUDITOR\u00cdA 1: GOBERNANZA DE DATOS (Los Ingredientes)\n    print(\"\ud83d\udee1\ufe0f Auditando Datos (Art\u00edculo 10)...\")\n    vl.enforce(\n        data=train_df,\n        target=\"class\",\n        gender=\"Attribute9\",  # Mapeo estrictamente definido por la pol\u00edtica\n        age=\"Attribute13\",\n        policy=\"data_policy.yaml\"\n    )\n</code></pre> <p>Salida Real: <pre><code>[Ventural\u00edtica v0.4.1] \ud83d\udee1  Aplicando pol\u00edtica: data_policy.yaml\n\n  CONTROL                DESCRIPCION                            ACTUAL     LIMITE     RESULTADO\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  imbalance              Proporci\u00f3n minoritaria                 0.431      &gt; 0.2      \u2705 PASS\n  gender-bias            Impacto dispar                         0.836      &gt; 0.8      \u2705 PASS\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n</code></pre></p>"},{"location":"es/training/#paso-3-entrenar-el-modelo","title":"Paso 3: Entrenar el Modelo","text":"<p>Si los datos pasan, procede a fabricar el modelo.</p> <pre><code>    # \ud83c\udfed FABRICAR: Entrenar el Modelo\n    from sklearn.ensemble import RandomForestClassifier\n\n    print(\"\ud83e\udd16 Entrenando Modelo...\")\n    model = RandomForestClassifier(n_estimators=100, random_state=42)\n    model.fit(X_train, y_train)\n\n    # Generar predicciones para la siguiente auditor\u00eda\n    predictions = model.predict(X_test)\n</code></pre>"},{"location":"es/training/#paso-4-auditoria-post-entrenamiento-articulo-15","title":"Paso 4: Auditor\u00eda Post-Entrenamiento (Art\u00edculo 15)","text":"<p>Ahora verifica el producto terminado contra los requisitos de rendimiento.</p> <pre><code>    # \ud83d\udd0d AUDITOR\u00cdA 2: PRECISI\u00d3N Y EQUIDAD DEL MODELO (El Producto)\n    print(\"\ud83d\udee1\ufe0f Auditando Modelo (Art\u00edculo 15)...\")\n\n    # Preparar dataframe de auditor\u00eda\n    audit_df = df.iloc[test_df.index].copy()\n    audit_df['prediction'] = predictions\n\n    vl.enforce(\n        data=audit_df,\n        target=\"class\",\n        prediction=\"prediction\", # Ahora evaluamos la SALIDA usando los mismos atributos sensibles\n        gender=\"Attribute9\",\n        age=\"Attribute13\",\n        policy=\"model_policy.yaml\"\n    )\n</code></pre> <p>Salida Real: <pre><code>[Ventural\u00edtica v0.4.1] \ud83d\udee1  Aplicando pol\u00edtica: model_policy.yaml\n\n  CONTROL                DESCRIPCION                            ACTUAL     LIMITE     RESULTADO\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  accuracy-check         Precisi\u00f3n M\u00ednima                       0.760      &gt; 0.7      \u2705 PASS\n  recall-check           Recall (Aversi\u00f3n al Riesgo)            0.720      &gt; 0.6      \u2705 PASS\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  Resumen de Auditor\u00eda: \u2705 POL\u00cdTICA CUMPLIDA | 2/2 controles pasados\n\n  \u2705 TraceCollector [training_run_v1] evidencia guardada en .venturalitica/trace_training_run_v1.json\n</code></pre></p>"},{"location":"es/training/#paso-5-ver-evidencia","title":"Paso 5: Ver Evidencia","text":"<p>Ahora has completado el Trabajo del Constructor. Ejecuta el panel de control para ver tu \"Caja de Cristal\".</p> <pre><code>venturalitica ui\n</code></pre>"},{"location":"es/academy/","title":"De Cero a Pro: El Viaje de 5 Minutos \ud83d\ude80","text":"<p>Objetivo: Transformarte de \"Desarrollador Python\" a \"Ingeniero de Gobernanza IA\" en 3 pasos.</p>"},{"location":"es/academy/#la-filosofia-cumplimiento-como-codigo","title":"La Filosof\u00eda: Cumplimiento como C\u00f3digo","text":"<p>Est\u00e1s acostumbrado a <code>pytest</code> para verificar si tu funci\u00f3n suma 2+2 correctamente. Pero, \u00bfc\u00f3mo pruebas si tu modelo de IA respeta los Derechos Humanos?</p> <p>Ventural\u00edtica trata la \"Gobernanza\" como una dependencia. En lugar de consejos legales vagos, defines Pol\u00edticas (OSCAL) estrictas. Tu pipeline CI/CD las aplica igual que reglas de linter.</p>"},{"location":"es/academy/#el-plan-de-estudios","title":"El Plan de Estudios","text":"Nivel Rol Objetivo Proyecto Empieza Aqu\u00ed Desarrollador Ejecuta tu primera auditor\u00eda en &lt; 60s. <code>loan-credit-scoring</code> Nivel 1 Ingeniero Implementar Controles para Riesgos. Pol\u00edtica Personalizada Nivel 2 Integrador Viz &amp; MLOps: \"Cumplimiento como Metadata\". MLOps / Dashboard Nivel 3 Auditor Prueba: \"Conf\u00eda en la Caja de Cristal\". <code>loan-credit-scoring</code> (Avanzado) Nivel 4 Arquitecto Docs GenAI: \"Anexo IV\". <code>loan-credit-scoring</code> (Anexo IV)"},{"location":"es/academy/#paso-1-instalacion","title":"Paso 1: Instalaci\u00f3n","text":"<p>Recomendamos uv para velocidad extrema, o <code>pip</code> est\u00e1ndar.</p> <pre><code>uv pip install git+https://github.com/Venturalitica/venturalitica-sdk.git\n# O\npip install git+https://github.com/Venturalitica/venturalitica-sdk.git\n</code></pre>"},{"location":"es/academy/#paso-2-obten-el-codigo","title":"Paso 2: Obt\u00e9n el C\u00f3digo \ud83d\udce6","text":"<p>Para seguir la Academia, clona el repositorio de ejemplos. Este ser\u00e1 tu directorio de trabajo para todos los niveles.</p> <pre><code>git clone https://github.com/venturalitica/venturalitica-sdk-samples.git\ncd venturalitica-sdk-samples/scenarios/loan-credit-scoring\n</code></pre>"},{"location":"es/academy/#paso-3-ejecutando-tu-primera-auditoria","title":"Paso 3: Ejecutando Tu Primera Auditor\u00eda \u26a1","text":"<p>Ejecuta esta \u00fanica l\u00ednea de c\u00f3digo. Descarga un dataset, carga una pol\u00edtica y audita un modelo de riesgo crediticio.</p> <pre><code>import venturalitica as vl\n\n# Ejecutar el escenario 'loan' (pr\u00e9stamos)\nvl.quickstart('loan')\n</code></pre> <p>Salida:</p> <pre><code>  CONTROL                DESCRIPTION                            RESULT\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  credit-data-bias       Disparate impact ratio &gt; 0.8           \u2705 PASS\n  credit-age-disparate   Age disparity ratio &gt; 0.5              \u274c FAIL\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  Audit Summary: \u274c VIOLATION | 1/2 controls passed\n</code></pre>"},{"location":"es/academy/#mensaje-para-llevar-a-casa","title":"\ud83d\udca1 Mensaje para Llevar a Casa","text":"<p>\"El Cumplimiento transforma Principios vagos en restricciones de Ingenier\u00eda verificables.\"</p> <ul> <li>La Pol\u00edtica: <code>ratio &gt; 0.5</code> (La Ley).</li> <li>La Realidad: <code>0.361</code> (Tu C\u00f3digo).</li> <li>El Veredicto: <code>\u274c FAIL</code> (La Brecha de Cumplimiento).</li> </ul> <p>No necesitaste un abogado. Solo necesitaste una falla de test visible.</p>"},{"location":"es/academy/#paso-4-elige-tu-camino","title":"Paso 4: Elige Tu Camino","text":"<p>Ahora que has visto la falla, aprende c\u00f3mo arreglarla y verificarla.</p> <ul> <li> <p> Nivel 1: El Ingeniero     ---     Aprende a implementar Controles que mitigan Riesgos identificados. Detecta y Bloquea modelos no conformes.</p> </li> <li> <p> Nivel 2: El Integrador     ---     Registra resultados en herramientas MLOps y verifica resultados visualmente en el Dashboard.</p> </li> <li> <p> Nivel 3: El Auditor     ---     Aprende a realizar una auditor\u00eda de \"Caja de Cristal\" en el modelo de pr\u00e9stamos y genera pruebas criptogr\u00e1ficas.</p> </li> <li> <p> Nivel 4: El Arquitecto     ---     El Nivel Jefe. Entrena un modelo financiero de alto riesgo y genera la masiva Documentaci\u00f3n T\u00e9cnica requerida por la EU AI Act.</p> </li> </ul>"},{"location":"es/academy/#referencias-externas","title":"\ud83d\udcda Referencias Externas","text":"<ul> <li>EU AI Act: Texto Legal Completo (EUR-Lex) (Espa\u00f1ol)</li> <li>ISO 42001: Sistema de Gesti\u00f3n de IA (AIMS)</li> <li>NIST AI RMF: Marco de Gesti\u00f3n de Riesgos 1.0</li> </ul>"},{"location":"es/academy/level1_policy/","title":"Nivel 1: El Ingeniero (Pol\u00edtica y Configuraci\u00f3n) \ud83d\udfe2","text":"<p>Objetivo: Aprender a implementar Controles que mitiguen Riesgos.</p> <p>Prerrequisito: De Cero a Pro (Inicio)</p>"},{"location":"es/academy/level1_policy/#1-el-escenario-del-riesgo-al-control","title":"1. El Escenario: Del Riesgo al Control","text":"<p>En un Sistema de Gesti\u00f3n formal (ISO 42001), la gobernanza sigue un flujo \"top-down\":</p> <ol> <li>Evaluaci\u00f3n de Riesgo: El Oficial de Cumplimiento (CO) identifica un riesgo de negocio (ej. \"Nuestra IA de pr\u00e9stamos podr\u00eda discriminar a los ancianos, causando da\u00f1o legal y reputacional\").</li> <li>Definici\u00f3n del Control: Para mitigar este riesgo, el CO establece un Control (ej. \"El Ratio de Disparidad por Edad debe ser siempre &gt; 0.5\").</li> <li>Implementaci\u00f3n T\u00e9cnica: Ese es tu trabajo. Tomas el requisito del CO y lo conviertes en la \"Ley T\u00e9cnica\" (Art\u00edculo 10: Gobernanza de Datos).</li> </ol> <p>En el inicio r\u00e1pido De Cero a Pro, <code>vl.quickstart('loan')</code> FALL\u00d3:</p> <pre><code>credit-age-disparate   Age disparity          0.361      &gt; 0.5      \u274c FAIL\n</code></pre>"},{"location":"es/academy/level1_policy/#que-paso","title":"\u00bfQu\u00e9 pas\u00f3?","text":"<p>El Control detect\u00f3 exitosamente una Brecha de Cumplimiento. La \"Realidad\" de los datos (<code>0.361</code>) viol\u00f3 el requisito establecido para mitigar el riesgo de \"Sesgo de Edad\".</p> <p>Regla #1: El Handshake de Responsabilidad. El Oficial de Cumplimiento identifica Riesgos y establece Controles.  El Ingeniero implementa y Verifica esos controles usando Evidencia.</p> <p>Si bajas el umbral a 0.3 solo para que el test \"pase\", no est\u00e1s arreglando el c\u00f3digo\u2014est\u00e1s evadiendo un control de seguridad y exponiendo a la empresa al riesgo original.</p>"},{"location":"es/academy/level1_policy/#2-anatomia-de-un-control-oscal","title":"2. Anatom\u00eda de un Control (OSCAL)","text":"<p>Tu trabajo es traducir el requisito del CO a C\u00f3digo. Crea un archivo llamado <code>data_governance.yaml</code>. Mant\u00e9n el umbral en 0.5 (El Est\u00e1ndar Organizacional).</p> <pre><code>assessment-plan:\n  metadata:\n    title: \"Art\u00edculo 10: Est\u00e1ndar de Gobernanza de Datos\"\n  control-implementations:\n    - description: \"Monitoreo de Equidad\"\n      implemented-requirements:\n        # \ud83d\udfe2 Control 1: Chequeo de Sesgo\n        - control-id: age-check\n          description: \"La Disparidad por Edad debe ser est\u00e1ndar (&gt; 0.5)\"\n          props:\n            - name: metric_key\n              value: disparate_impact        # La m\u00e9trica de Python\n            - name: \"input:dimension\"\n              value: age                    # El concepto abstracto\n            - name: operator\n              value: gt                     # Mayor que (Greater Than)\n            - name: threshold\n              value: \"0.5\"                  # \ud83d\udd12 NO CAMBIES ESTO\n</code></pre>"},{"location":"es/academy/level1_policy/#3-ejecuta-tu-politica","title":"3. Ejecuta Tu Pol\u00edtica","text":"<p>Ahora, ejecutemos la auditor\u00eda de nuevo con tu configuraci\u00f3n. Observa c\u00f3mo mapeamos el concepto abstracto <code>age</code> a tu columna espec\u00edfica.</p> <pre><code>import venturalitica as vl\nfrom ucimlrepo import fetch_ucirepo\n\n# 1. Obtener Datos (CSV Sucio)\ndataset = fetch_ucirepo(id=144)\ndf = dataset.data.features\ndf['class'] = dataset.data.targets\n\n# 2. Ejecutar Auditor\u00eda (El Mapeo)\nresults = vl.enforce(\n    data=df,\n    target=\"class\",\n    age=\"Attribute13\",    # \ud83d\udddd\ufe0f MAPEO: 'age' es en realidad 'Attribute13'\n    policy=\"data_governance.yaml\"\n)\n\n# 3. Verificar Resultados\nif all(r.passed for r in results):\n    print(\"\u2705 Auditor\u00eda Aprobada!\")\nelse:\n    print(\"\u274c BLOQUEADO: Violaci\u00f3n de Cumplimiento detectada.\")\n    print(\"\ud83d\udc49 Acci\u00f3n: Enviar trace.json al SaaS para revisi\u00f3n del Oficial.\")\n</code></pre>"},{"location":"es/academy/level1_policy/#el-handshake-la-traduccion","title":"\ud83e\udd1d El \"Handshake\" (La Traducci\u00f3n)","text":"<p>F\u00edjate en lo que acaba de pasar.</p> <ul> <li>Legal: \"S\u00e9 justo (&gt; 0.5).\" (Definido en tu YAML)</li> <li>Dev: \"Esta columna <code>Attribute13</code> es <code>age</code>.\" (Definido en tu Python)</li> </ul> <p>Este mapeo es el Handshake. T\u00fa construyes el puente entre Datos sucios y Leyes r\u00edgidas. As\u00ed es como implementas ISO 42001 sin perder la cabeza en hojas de c\u00e1lculo.</p>"},{"location":"es/academy/level1_policy/#4-verificacion-visual","title":"4. Verificaci\u00f3n Visual","text":"<p>Cuando ejecutes esto, FALLAR\u00c1 en tu terminal. Y eso es BUENO. Pero el cumplimiento no son solo logs de terminal.</p> <p>Para ver el reporte profesional y la visualizaci\u00f3n de esta falla, ejecuta el dashboard local:</p> <pre><code>uv run venturalitica ui\n</code></pre> <p>Navega a la pesta\u00f1a de Pol\u00edtica. Ver\u00e1s la prueba visual de tu riesgo identificado:</p> <p></p> <p>Has prevenido exitosamente que una IA no conforme llegue a producci\u00f3n midiendo el riesgo contra un est\u00e1ndar verificable.</p>"},{"location":"es/academy/level1_policy/#5-mensajes-para-llevar-a-casa","title":"5. Mensajes para Llevar a Casa \ud83c\udfe0","text":"<ol> <li>Pol\u00edtica como C\u00f3digo: La gobernanza es solo un archivo <code>.yaml</code>. Define el Control.</li> <li>El Handshake: T\u00fa defines el Mapeo (<code>age</code>=<code>Attribute13</code>). El Oficial define el Requisito (<code>&gt; 0.5</code>).</li> <li>El Tratamiento empieza con la Detecci\u00f3n: La falla local es la se\u00f1al necesaria para iniciar un plan de tratamiento de riesgos formal ISO 42001.</li> </ol> <p>Siguiente Paso: La build fall\u00f3 localmente. \u00bfC\u00f3mo se lo decimos al Oficial de Cumplimiento? \ud83d\udc49 Ir al Nivel 2: El Integrador (MLOps)</p>"},{"location":"es/academy/level2_integrator/","title":"Nivel 2: El Integrador (GovOps y Visibilidad) \ud83d\udfe1","text":"<p>Objetivo: Transformar artefactos de MLOps en Evidencia Regulatoria con una capa de GovOps.</p> <p>Prerrequisito: Nivel 1 (El Ingeniero)</p> <p>Contexto: Continuando con \"El Proyecto\".</p>"},{"location":"es/academy/level2_integrator/#1-el-cuello-de-botella-en-mi-maquina-funciona","title":"1. El Cuello de Botella: \"En mi m\u00e1quina funciona\"","text":"<p>En el Nivel 1, arreglaste el sesgo localmente. Pero tu manager lo niega porque no puede ver la prueba. Los emails con capturas de pantalla no son cumplimiento.</p>"},{"location":"es/academy/level2_integrator/#2-la-solucion-la-capa-govops","title":"2. La Soluci\u00f3n: La Capa GovOps","text":"<p>En GovOps (Gobernanza sobre MLOps), no tratamos el cumplimiento como un paso manual separado. En su lugar, usamos tu infraestructura existente de MLOps (MLflow, WandB) como un Buffer de Evidencia que cosecha autom\u00e1ticamente la prueba de seguridad durante el proceso de entrenamiento.</p>"},{"location":"es/academy/level2_integrator/#a-la-integracion-gobernanza-implicita","title":"A. La Integraci\u00f3n (Gobernanza Impl\u00edcita)","text":"<p>En un pipeline profesional, la gobernanza es una capa que envuelve tu entrenamiento. Cada vez que entrenas un modelo, verificas su cumplimiento.</p> <p>Tu tracker de experimentos ahora rastrea dos tipos de rendimiento: Precisi\u00f3n (Operacional) y Cumplimiento (Regulatorio).</p> MLflowWeights &amp; Biases <pre><code>import mlflow\nimport venturalitica as vl\nfrom dataclasses import asdict\n\nmlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\nmlflow.set_experiment(\"loan-credit-scoring\")\n\n# 1. Iniciar Sesi\u00f3n GovOps (Captura impl\u00edcita de 'Audit Trace')\nwith mlflow.start_run(), vl.monitor(\"train_v1\"):\n    # 2. Entrenar tu modelo\n    # model.fit(X_train, y_train)\n\n    # 3. Aplicar Cumplimiento (Art\u00edculo 15: Supervisi\u00f3n Humana)\n    results = vl.enforce(\n        data=X_test.assign(prediction=model.predict(X_test)),\n        target=\"prediction\",               # \ud83e\udde0 Comprobando Comportamiento del Modelo\n        gender=\"gender\",\n        policy=\"model_policy.yaml\"         # \ud83d\udddd\ufe0f Nueva pol\u00edtica para Gobernanza del Modelo\n    )\n\n    # 4. Registrar todo en el Buffer de Evidencia\n    passed = all(r.passed for r in results)\n    mlflow.log_metric(\"val_accuracy\", 0.92)\n    mlflow.log_metric(\"compliance_score\", 1.0 if passed else 0.0)\n    mlflow.log_dict([asdict(r) for r in results], \"compliance_results.json\")\n\n    if not passed:\n        # \ud83d\uded1 CR\u00cdTICO: Bloquear el pipeline si el modelo no es \u00e9tico\n        raise ValueError(\"El modelo fall\u00f3 el cumplimiento ISO 42001. Ver traza de auditor\u00eda.\")\n</code></pre> <p>Nota: <code>vl.monitor()</code> ahora captura Evidencia Multimodal: m\u00e9tricas de hardware/carbono Y la traza l\u00f3gica de ejecuci\u00f3n (historia del c\u00f3digo AST).</p> <pre><code>import wandb\nimport venturalitica as vl\n\nwandb.init(project=\"loan-credit-scoring\")\n\n# 1. Abrir Contexto de Monitor\nwith vl.monitor(\"wandb_sync\"):\n    # model.fit(X_train, y_train)\n\n    # 2. Ejecutar Enforce (Art\u00edculo 15)\n    audit = vl.enforce(\n        data=pd.read_csv(\"val_data.csv\"),\n        policy=\"model_policy.yaml\",\n        target=\"prediction\"\n    )\n\n# 3. Registrar Artefactos de Cumplimiento\nartifact = wandb.Artifact('compliance-bundle', type='evidence')\nartifact.add_file(\".venturalitica/results.json\")\nartifact.add_file(\".venturalitica/trace_wandb_sync.json\")\nwandb.log_artifact(artifact)\n\npassed = all(r.passed for r in audit)\nwandb.log({\"accuracy\": 0.89, \"compliance\": 1.0 if passed else 0.0})\n\nif not passed:\n    raise ValueError(\"Modelo rechazado por pol\u00edtica de GovOps.\")\n</code></pre>"},{"location":"es/academy/level2_integrator/#b-la-verificacion-dashboard","title":"B. La Verificaci\u00f3n (Dashboard)","text":"<p>Ahora que el c\u00f3digo ha corrido, verifiquemos lo que enviamos.</p> <ol> <li>Ejecuta la UI:     <pre><code>uv run venturalitica ui\n</code></pre></li> <li>Chequeo de Logs: Verifica que <code>.venturalitica/results.json</code> existe.</li> <li>Navega a \"Estado de Pol\u00edtica\": Confirma que tu \"Tratamiento de Riesgo\" (el umbral ajustado) est\u00e1 registrado.</li> </ol> <p>Insight Clave: \"El reporte se ve profesional, y no escrib\u00ed una sola palabra de \u00e9l.\"</p> <p></p>"},{"location":"es/academy/level2_integrator/#3-profundizacion-el-handshake-de-dos-politicas-art-10-vs-15","title":"3. Profundizaci\u00f3n: El Handshake de Dos Pol\u00edticas (Art 10 vs 15)","text":"<p>El GovOps profesional requiere separaci\u00f3n de preocupaciones. Ahora gestionas dos capas de gobernanza distintas:</p> <ol> <li>Nivel 1 (Art\u00edculo 10): Verific\u00f3 los Datos Crudos contra <code>data_policy.yaml</code>. El objetivo era probar que el dataset era justo antes de desperdiciar energ\u00eda en entrenamiento.</li> <li>Nivel 2 (Art\u00edculo 15): Verifica el Comportamiento del Modelo contra <code>model_policy.yaml</code>. El objetivo es probar que la IA toma decisiones justas en una ejecuci\u00f3n de \"Caja de Cristal\".</li> </ol> Etapa Mapeo de Variables Archivo de Pol\u00edtica Requisito Mandatorio Auditor\u00eda de Datos <code>target=\"class\"</code> <code>data_policy.yaml</code> Art\u00edculo 10 (Gobernanza de Datos) Auditor\u00eda de Modelo <code>target=\"prediction\"</code> <code>model_policy.yaml</code> Art\u00edculo 15 (Supervisi\u00f3n Humana) <p>Este desacople es el n\u00facleo del Handshake. Incluso si la Ley (<code>&gt; 0.5</code>) permanece igual, el sujeto de la ley cambia de Datos a Matem\u00e1ticas.</p>"},{"location":"es/academy/level2_integrator/#4-la-puerta-cicd","title":"4. La Puerta (CI/CD)","text":"<p>Si <code>compliance_score == 0</code>, la build falla. GitLab CI / GitHub Actions ahora pueden bloquear un despliegue basado en \u00e9tica, igual que bloquean por errores de sintaxis.</p>"},{"location":"es/academy/level2_integrator/#5-mensajes-para-llevar-a-casa","title":"5. Mensajes para Llevar a Casa \ud83c\udfe0","text":"<ol> <li>GovOps es Nativo: La gobernanza no es un paso extra; es un context manager (<code>vl.monitor</code>) alrededor de tu entrenamiento.</li> <li>Telemetr\u00eda es Evidencia: RAM, CO2 y Traza no son solo m\u00e9tricas\u2014cumplen con la supervisi\u00f3n del Art\u00edculo 15.</li> <li>Traza Unificada: <code>vl.monitor()</code> captura todo, desde uso de hardware hasta an\u00e1lisis de c\u00f3digo AST, en un solo archivo <code>.json</code>.</li> <li>Fricci\u00f3n Cero: El Data Scientist sigue usando MLflow/WandB, mientras el SDK cosecha la evidencia.</li> </ol> <p>\ud83d\udc49 Siguiente: Nivel 3 (El Auditor)</p>"},{"location":"es/academy/level3_auditor/","title":"Nivel 3: El Auditor (Traza de Caja de Cristal) \ud83d\udfe0","text":"<p>Objetivo: Verificar tu pol\u00edtica visual y criptogr\u00e1ficamente usando el m\u00e9todo de Caja de Cristal.</p> <p>Prerrequisito: Nivel 2 (El Integrador)</p>"},{"location":"es/academy/level3_auditor/#1-el-problema-paso-pero-podemos-confiar-en-el-proceso","title":"1. El Problema: \"Pas\u00f3, pero \u00bfpodemos confiar en el proceso?\"","text":"<p>En el Nivel 2, registraste el puntaje de cumplimiento. Pero para la IA de Alto Riesgo (como el Scoring de Cr\u00e9dito), las m\u00e9tricas no son suficientes. Un Auditor pregunta: \"\u00bfProbaste en el dataset real, o filtraste los pr\u00e9stamos rechazados?\" y \"\u00bfPuedes probar que este c\u00f3digo fue realmente ejecutado?\"</p>"},{"location":"es/academy/level3_auditor/#2-la-solucion-la-traza-de-caja-de-cristal","title":"2. La Soluci\u00f3n: La Traza de \"Caja de Cristal\"","text":"<p>Seg\u00fan nuestros Documentos de Auditor\u00eda Estrat\u00e9gica, la auditor\u00eda profesional requiere m\u00e1s que resultados\u2014requiere Proveniencia.</p> <p>Ventural\u00edtica usa un contexto <code>monitor()</code> para registrar todo: -   El C\u00f3digo: An\u00e1lisis AST de tu script. -   Los Datos: Conteo de filas y esquema de columnas. -   El Hardware: Memoria, CPU y stats de Carbono (Art\u00edculo 15). -   El Sello: Un hash criptogr\u00e1fico SHA-256 de toda la sesi\u00f3n.</p>"},{"location":"es/academy/level3_auditor/#el-upgrade","title":"El Upgrade","text":"<p>Continuamos trabajando en el mismo proyecto. No se requiere configuraci\u00f3n nueva.</p>"},{"location":"es/academy/level3_auditor/#ejecutar-con-el-monitor-nativo","title":"Ejecutar con el Monitor Nativo","text":"<p>Envuelve tu ejecuci\u00f3n en <code>vl.monitor()</code>. Este context manager captura el \"Handshake\" entre tu c\u00f3digo y la pol\u00edtica cosechando metadatos f\u00edsicos y l\u00f3gicos.</p>"},{"location":"es/academy/level3_auditor/#profundizacion-caja-de-cristal-vs-caja-negra","title":"\ud83d\udd0d Profundizaci\u00f3n: Caja de Cristal vs Caja Negra","text":"Caracter\u00edstica \u2b1b Caja Negra (Est\u00e1ndar) \ud83e\ude9f Caja de Cristal (Ventural\u00edtica) L\u00f3gica \"Conf\u00eda en m\u00ed, ejecut\u00e9 el c\u00f3digo.\" An\u00e1lisis AST: Registramos qu\u00e9 funci\u00f3n mape\u00f3 c\u00f3digo a pol\u00edtica. Datos \"Aqu\u00ed est\u00e1 el CSV.\" Huella Digital: Registramos el SHA-256 del dataset en tiempo de ejecuci\u00f3n. Alcance C\u00f3digo C\u00f3digo + Entorno + Estad\u00edsticas de Hardware <pre><code>import venturalitica as vl\nfrom ucimlrepo import fetch_ucirepo\n\n# 1. Cargar Datos (Lo Real)\ndataset = fetch_ucirepo(id=144)\ndf = dataset.data.features\ndf['class'] = dataset.data.targets\n\n# 2. Iniciar el Monitor Multimodal (La Caja de Cristal)\nwith vl.monitor(\"loan_audit_v1\"):\n    # Este bloque ahora est\u00e1 siendo vigilado por el Auditor\n    results = vl.enforce(\n        data=df,\n        target=\"class\",       # Verificando Verdad Terrestre (Ground Truth)\n        age=\"Attribute13\",    # Mapeando Edad\n        policy=\"data_governance.yaml\"\n    )\n    # El archivo de traza de sesi\u00f3n (.venturalitica/trace_loan_audit_v1.json) \n    # probar\u00e1 NO solo el resultado, sino C\u00d3MO fue computado.\n</code></pre>"},{"location":"es/academy/level3_auditor/#3-la-verificacion-del-sello-digital","title":"3. La Verificaci\u00f3n del \"Sello Digital\"","text":"<p>Despu\u00e9s de ejecutar la auditor\u00eda, lanza la UI:</p> <pre><code>uv run venturalitica ui\n</code></pre> <p>Navega a \"Art\u00edculo 13: Transparencia\".</p>"},{"location":"es/academy/level3_auditor/#encontrando-el-hash-de-evidencia","title":"Encontrando el Hash de Evidencia","text":"<p>Busca el Evidence Hash en el dashboard. <code>Evidence Hash: 89fbf...</code></p> <p>Este hash es tu \"Sello Digital\". Si cambias un p\u00edxel en el dataset o una l\u00ednea en la pol\u00edtica, este hash cambia. Ahora puedes probar a un regulador exactamente qu\u00e9 pas\u00f3 durante la auditor\u00eda.</p>"},{"location":"es/academy/level3_auditor/#4-el-mapa-de-cumplimiento","title":"4. El Mapa de Cumplimiento","text":"<p>El Dashboard traduce la evidencia JSON al lenguaje de la EU AI Act.</p> Ley Pesta\u00f1a del Dashboard Qu\u00e9 Responder Art 9 Gesti\u00f3n de Riesgos \"\u00bfVerificamos sesgo &lt; 0.1?\" (Tu Pol\u00edtica) Art 10 Gobernanza de Datos \"\u00bfSon los datos de entrenamiento representativos?\" Art 13 Transparencia \"\u00bfQu\u00e9 librer\u00edas (BOM) estamos usando?\""},{"location":"es/academy/level3_auditor/#5-mensajes-para-llevar-a-casa","title":"5. Mensajes para Llevar a Casa \ud83c\udfe0","text":"<ol> <li>No Conf\u00edes, Verifica: El Archivo de Traza (capturado autom\u00e1ticamente v\u00eda <code>monitor()</code>) es la fuente de verdad para todo el contexto de ejecuci\u00f3n.</li> <li>Auditor\u00eda de Caja de Cristal: El cumplimiento no es un booleano \"pasa/falla\"; es una historia verificable de ejecuci\u00f3n.</li> <li>Prueba Inmutable: El Hash de Evidencia te permite probar la integridad del proceso de auditor\u00eda.</li> </ol> <p>Siguiente Paso: Tienes el C\u00f3digo (Nivel 1), las Operaciones (Nivel 2), y la Prueba (Nivel 3). Ahora genera los Documentos Legales. \ud83d\udc49 Ir al Nivel 4: El Arquitecto</p>"},{"location":"es/academy/level4_annex_iv/","title":"Nivel 4: El Arquitecto (Generaci\u00f3n Anexo IV) \ud83d\udd34","text":"<p>Objetivo: Automatizar la creaci\u00f3n de documentos regulatorios de 50+ p\u00e1ginas.</p> <p>Prerrequisito: Nivel 3 (El Auditor)</p>"},{"location":"es/academy/level4_annex_iv/#1-el-cuello-de-botella-documentacion-tecnica","title":"1. El Cuello de Botella: \"Documentaci\u00f3n T\u00e9cnica\"","text":"<p>De acuerdo con el Art\u00edculo 11 y Anexo IV de la EU AI Act, los sistemas de Alto Riesgo (como Scoring de Cr\u00e9dito) requieren Documentaci\u00f3n T\u00e9cnica exhaustiva. Escribir esto manualmente toma semanas.</p>"},{"location":"es/academy/level4_annex_iv/#2-la-solucion-cumplimiento-generativo","title":"2. La Soluci\u00f3n: Cumplimiento Generativo","text":"<p>Usamos tus Pol\u00edticas (Nivel 1 &amp; 2) y Evidencia (Nivel 2/3) para invocar a un LLM que redacte el documento por ti.</p> <p>Ventural\u00edtica soporta: - Nube: Mistral (v\u00eda API). - Local: Ollama (Prop\u00f3sito general). - Soberana (NUEVO): ALIA (Nativo Espa\u00f1ol GGUF v\u00eda Llama.cpp) - Experimental.</p>"},{"location":"es/academy/level4_annex_iv/#el-upgrade","title":"El Upgrade","text":"<p>Continuamos trabajando en el proyecto de \"Scoring de Cr\u00e9dito\".</p>"},{"location":"es/academy/level4_annex_iv/#ejecutar-la-auditoria-de-alto-riesgo","title":"Ejecutar la Auditor\u00eda de Alto Riesgo","text":"<p>Aseg\u00farate de haber corrido los pasos de recolecci\u00f3n:</p> <pre><code># Ejecutar la Auditor\u00eda de Gobernanza de Art\u00edculo 10 (Datos) y Art\u00edculo 15 (Modelo)\nwith vl.monitor(\"loan_annex_audit\"):\n    # 1. Verificar Datos de Entrenamiento (Art 10)\n    vl.enforce(data=train_df, policy=\"data_governance.yaml\", target=\"class\")\n\n    # 2. Verificar Rendimiento del Modelo (Art 15)\n    vl.enforce(\n        data=val_df.assign(prediction=model.predict(val_df)), \n        policy=\"model_policy.yaml\", \n        target=\"prediction\"\n    )\n</code></pre>"},{"location":"es/academy/level4_annex_iv/#3-generar-el-documento","title":"3. Generar el Documento","text":"<ol> <li>Abre el Dashboard: <code>uv run venturalitica ui</code>.</li> <li>Ve a la pesta\u00f1a \"Generador Anexo IV\".</li> <li>Selecciona Proveedor: Nube (Mistral), Local (Ollama), o Soberana (ALIA - Experimental).</li> <li> <p>Click en \"Generar Anexo IV\".</p> <p></p> </li> </ol>"},{"location":"es/academy/level4_annex_iv/#el-proceso-de-generacion","title":"El Proceso de Generaci\u00f3n","text":"<p>Observa los logs. El Sistema act\u00faa como un Equipo de Agentes:</p> <ol> <li>Scanner: Lee tu <code>trace.json</code> (La Evidencia).</li> <li>Planner: Decide qu\u00e9 secciones del Anexo IV aplican a tu tipo de modelo espec\u00edfico.</li> <li>Writer: Redacta \"Secci\u00f3n 2.c: Arquitectura\" usando el <code>summary()</code> de tu c\u00f3digo Python real.</li> <li>Critic: Revisa el borrador contra el est\u00e1ndar ISO 42001.</li> </ol> <p>Resultado: Un archivo markdown (<code>Annex_IV.md</code>) que cita tus puntajes de precisi\u00f3n espec\u00edficos (ej. <code>Paridad Demogr\u00e1fica: 0.92</code>) como prueba de seguridad.</p>"},{"location":"es/academy/level4_annex_iv/#4-seleccionando-tu-llm","title":"4. Seleccionando tu LLM","text":"Caracter\u00edstica Nube (Mistral API) Local (Ollama) Soberana (ALIA - Experimental) Privacidad \u2601\ufe0f Transporte Encriptado \ud83d\udd12 100% Offline \ud83d\udee1\ufe0f Bloqueado por Hardware Soberan\u00eda \ud83c\uddeb\ud83c\uddf7 Alojado en UE \u2705 Gen\u00e9rico \ud83c\uddea\ud83c\uddf8 Nativo Espa\u00f1ol Velocidad \u26a1 R\u00e1pido (Modelo Grande) \ud83d\udc22 M\u00e1s lento \ud83d\udc22 Lento (Experimental) Caso de Uso Pulido Final de Alta Calidad Testing Iterativo Solo Investigaci\u00f3n <p>Actualmente ofrecemos ALIA como una feature experimental para organizaciones pilotando IA soberana nativa en espa\u00f1ol.</p> <p>Feature Experimental y Requisitos de Hardware</p> <p>ALIA es un modelo de 40B par\u00e1metros. Est\u00e1 marcado como EXPERIMENTAL y requiere recursos de hardware significativos:</p> <ul> <li>RAM/VRAM: ~41GB requeridos (cuantizaci\u00f3n Q8).</li> <li>GPU: Se recomienda una GPU de gama alta (ej. RTX 3090/4090 con 24GB+) para velocidades usables.</li> <li>Rendimiento: En hardware de consumo o GPUs m\u00e1s peque\u00f1as (como RTX 2000), la inferencia correr\u00e1 efectivamente en CPU y ser\u00e1 muy lenta.</li> </ul>"},{"location":"es/academy/level4_annex_iv/#5-exportar-a-pdf","title":"5. Exportar a PDF","text":"<p>Por defecto, generamos <code>Annex_IV.md</code> (Markdown) para control de versiones. Para convertir esto a un PDF de grado regulatorio:</p> Python (mdpdf)Pandoc (Avanzado) <pre><code>uv pip install mdpdf\nuv run mdpdf Annex_IV.md\n</code></pre> <pre><code>pandoc Annex_IV.md -o Annex_IV.pdf --toc --pdf-engine=xelatex\n</code></pre>"},{"location":"es/academy/level4_annex_iv/#6-mensajes-para-llevar-a-casa","title":"6. Mensajes para Llevar a Casa \ud83c\udfe0","text":"<ol> <li>La Documentaci\u00f3n es una Funci\u00f3n: <code>f(Evidencia) -&gt; Documento</code>. Nunca escribas lo que puedes generar.</li> <li>LiveTrace: Si tu precisi\u00f3n cae ma\u00f1ana, regenera el documento. Reflejar\u00e1 el estado actual, previniendo la \"Deriva de Documentaci\u00f3n\".</li> <li>El Bucle Completo: Has ido de C\u00f3digo -&gt; Pol\u00edtica (N1) -&gt; Ops (N2) -&gt; Evidencia (N3) -&gt; Documento Legal (N4).</li> </ol>"},{"location":"es/academy/level4_annex_iv/#felicidades","title":"\ud83c\udf89 \u00a1Felicidades!","text":"<p>Has completado la Academia Ventural\u00edtica. Ahora est\u00e1s listo para integrar esto en tu propio pipeline CI/CD.</p> <p>\ud83d\udc49 Profundizaci\u00f3n: Integraci\u00f3n MLOps \ud83d\udc49 Profundizaci\u00f3n: Bucle de Entrenamiento</p>"},{"location":"es/tutorials/01_writing_policy/","title":"\ud83d\udee0\ufe0f Escribiendo Pol\u00edtica Primero en C\u00f3digo (El Ingeniero)","text":"<p>Esta gu\u00eda se centra en la Persona del Ingeniero: quien traduce los requisitos legales en reglas t\u00e9cnicas (OSCAL). En el Nivel 1, aprendiste a \"Bloquear\" despliegues incorrectos. Ahora escribiremos el archivo de pol\u00edtica real que gobierna el proyecto.</p>"},{"location":"es/tutorials/01_writing_policy/#parte-1-la-politica-de-datos-data_policyyaml","title":"Parte 1: La Pol\u00edtica de Datos (<code>data_policy.yaml</code>)","text":"<p>Para la Fase 1 (Auditor\u00eda de Datos), solo nos importa el Art\u00edculo 10 (Gobernanza de Datos). Tu Cient\u00edfico de Datos (El Constructor) no puede comenzar el entrenamiento hasta que este archivo est\u00e9 listo.</p>"},{"location":"es/tutorials/01_writing_policy/#1-la-estructura","title":"1. La Estructura","text":"<p>Crea un archivo llamado <code>data_policy.yaml</code> en la ra\u00edz de tu proyecto.</p> <pre><code>assessment-plan:\n  uuid: credit-scoring-v1\n  metadata:\n    title: \"Art\u00edculo 10: Directiva de Cr\u00e9dito al Consumo (CCD)\"\n    description: \"Criterios de aceptaci\u00f3n para la calidad y sesgo de los datos de entrenamiento.\"\n  reviewed-controls:\n    control-selections:\n      - include-controls:\n        # LAS REGLAS VAN AQU\u00cd\n</code></pre>"},{"location":"es/tutorials/01_writing_policy/#2-definiendo-las-reglas-controles","title":"2. Definiendo las Reglas (Controles)","text":"<p>Un \"Control\" es una unidad de l\u00f3gica. En la Ley de IA de la UE, debes probar que verificaste riesgos espec\u00edficos.</p>"},{"location":"es/tutorials/01_writing_policy/#regla-a-representacion-soporte-estadistico","title":"Regla A: Representaci\u00f3n (Soporte Estad\u00edstico)","text":"<ul> <li>Requisito Legal: \"Los conjuntos de datos de entrenamiento, validaci\u00f3n y prueba deber\u00e1n ser pertinentes, representativos, libres de errores y completos.\" (Art 10.3)</li> <li>Traducci\u00f3n: Asegurar que ning\u00fan grupo demogr\u00e1fico sea borrado (M\u00ednimo 20% de representaci\u00f3n).</li> </ul> <pre><code>        - control-id: check-imbalance\n          description: \"Asegurar que los grupos minoritarios sean estad\u00edsticamente significativos.\"\n          props:\n            - name: metric_key\n              value: min_class_ratio\n            - name: threshold\n              value: \"0.20\"  # Fallar si la clase minoritaria &lt; 20%\n            - name: operator\n              value: \"&gt;\"\n</code></pre>"},{"location":"es/tutorials/01_writing_policy/#regla-b-sesgo-impacto-dispar","title":"Regla B: Sesgo (Impacto Dispar)","text":"<ul> <li>Requisito Legal: \"Examen de posibles sesgos.\" (Art 10.2.f)</li> <li>Traducci\u00f3n: Las tasas de aceptaci\u00f3n no deben desviarse m\u00e1s del 20% entre grupos (Regla de los Cuatro Quintos).</li> </ul> <pre><code>        - control-id: check-gender-bias\n          description: \"El Ratio de Impacto Dispar debe estar entre 0.8 - 1.25\"\n          props:\n            - name: metric_key\n              value: disparate_impact_ratio\n            - name: threshold\n              value: \"0.80\"\n            - name: operator\n              value: \"&gt;\"\n</code></pre>"},{"location":"es/tutorials/01_writing_policy/#3-verificar-la-politica","title":"3. Verificar la Pol\u00edtica","text":"<p>Antes de entregarla al Cient\u00edfico de Datos, verifica que funcione.</p> <pre><code>import venturalitica as vl\nfrom venturalitica.quickstart import load_sample\n\n# 1. Cargar el Conjunto de Datos 'Aprobado' (Simulado)\ndata = load_sample('loan')\n\n# 2. Prueba Seca de la Pol\u00edtica\ntry:\n    vl.enforce(\n        data=data,\n        target=\"class\",\n        gender=\"Attribute9\",  # \"Estado personal y sexo\" en Datos de Cr\u00e9dito Alem\u00e1n\n        policy=\"data_policy.yaml\"\n    )\n    print(\"\u2705 La pol\u00edtica tiene sintaxis v\u00e1lida y pasa los datos base.\")\nexcept Exception as e:\n    print(f\"\u274c Error de Pol\u00edtica: {e}\")\n</code></pre>"},{"location":"es/tutorials/01_writing_policy/#parte-2-la-politica-del-modelo-model_policyyaml","title":"Parte 2: La Pol\u00edtica del Modelo (<code>model_policy.yaml</code>)","text":"<p>Una vez aprobados los datos, necesitas definir las reglas para el producto final (el modelo entrenado). Esto corresponde al Art\u00edculo 15 (Precisi\u00f3n, Robustez y Ciberseguridad).</p> <p>Crea un segundo archivo: <code>model_policy.yaml</code>.</p>"},{"location":"es/tutorials/01_writing_policy/#regla-c-rendimiento-precision","title":"Regla C: Rendimiento (Precisi\u00f3n)","text":"<ul> <li>Requisito Legal: \"Los sistemas de IA de alto riesgo se dise\u00f1ar\u00e1n... para lograr un nivel adecuado de precisi\u00f3n.\" (Art 15.1)</li> <li>Traducci\u00f3n: El modelo debe ser mejor que adivinar al azar (ej. &gt; 70% de precisi\u00f3n).</li> </ul> <pre><code>        - control-id: accuracy-check\n          description: \"El modelo debe lograr al menos 70% de precisi\u00f3n.\"\n          props:\n            - name: metric_key\n              value: accuracy_score\n            - name: threshold\n              value: \"0.70\"\n            - name: operator\n              value: \"&gt;\"\n</code></pre>"},{"location":"es/tutorials/01_writing_policy/#regla-d-equidad-post-entrenamiento-resultado","title":"Regla D: Equidad Post-Entrenamiento (Resultado)","text":"<ul> <li>Requisito Legal: \"Los resultados no deber\u00e1n estar sesgados...\"</li> <li>Traducci\u00f3n: Incluso si los datos estaban equilibrados, el modelo podr\u00eda aprender a discriminar. Verifica las predicciones nuevamente.</li> </ul> <pre><code>        - control-id: gender-fairness-model\n          description: \"Asegurar que las predicciones del modelo no impacten disparmente a las mujeres.\"\n          props:\n            - name: metric_key\n              value: disparate_impact_ratio\n            - name: \"input:dimension\"\n              value: \"gender\"         # Enlazar expl\u00edcitamente a la columna de g\u00e9nero\n            - name: threshold\n              value: \"0.80\"\n            - name: operator\n              value: \"&gt;\"\n</code></pre>"},{"location":"es/tutorials/01_writing_policy/#que-sigue","title":"\u00bfQu\u00e9 Sigue?","text":"<p>Ahora has creado la especificaci\u00f3n. \ud83d\udc49 Entrega estos archivos (<code>data_policy.yaml</code> y <code>model_policy.yaml</code>) a tu Cient\u00edfico de Datos. Ellos los usar\u00e1n en el Nivel 2 para auditar su flujo de entrenamiento.</p>"}]}