{"config":{"lang":["en","es"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Ventural\u00edtica","text":"<p>The Glass Box for High-Risk AI.</p> <p>Ventural\u00edtica transforms your Python code into Legal Evidence. It automatically maps your technical metrics, data audits, and execution logs to the EU AI Act (Articles 9-15) without leaving your local environment.</p>"},{"location":"#quickstart-in-60-seconds","title":"\u26a1\ufe0f Quickstart in 60 Seconds","text":"<p>Detect bias in your datasets or models with one line of code.</p> <pre><code>import venturalitica as vl\n\n# 1. Run Audit (Auto-Records Evidence)\nresults = vl.quickstart('loan')\n</code></pre> <p>Then, verify the results in the Glass Box Dashboard:</p> <pre><code>venturalitica ui\n</code></pre>"},{"location":"#key-features","title":"\ud83d\udee1 Key Features","text":"Feature Description TraceCollector Unified evidence gathering for BOM, metrics, and logs. Glass Box Sequential regulatory mapping (Art 9-15) for total transparency. Local Sovereignty Zero-cloud dependency. All enforcement runs locally. Bias Detection Quantitative fairness audits (Disparate Impact, Class Balance). Policy as Code Define governance rules in standard OSCAL/YAML formats. Annex IV Auto-draft technical documentation from local traces."},{"location":"#explore-tutorials","title":"\ud83d\udcda Explore Tutorials","text":"<p>Start with our interactive Jupyter notebooks:</p> <ul> <li>\u26a1\ufe0f Zero-Setup Audit - Run a full compliance scan on any project folder in 2 minutes.</li> <li>\ud83d\udee0\ufe0f Training Workflow - Learn how to audit data before training and verify models post-training.</li> <li>\ud83d\udcca Regulatory Mapping - Deep dive into how Ventural\u00edtica maps technical evidence to the EU AI Act.</li> </ul>"},{"location":"#installation","title":"\u2699\ufe0f Installation","text":"<pre><code>pip install git+https://github.com/Venturalitica/venturalitica-sdk.git\n</code></pre> <p>Quickstart Guide | Regulatory Map | API Reference</p>"},{"location":"#join-the-governance-revolution","title":"\ud83e\udd1d Join the Governance Revolution","text":"<p>Ventural\u00edtica is an open-source movement to bring transparency to AI.</p> <ul> <li>Have a specific compliance need? Check our Compliance Gap Roadmap.</li> <li>Found a bug or want to propose a feature? Open a GitHub Issue.</li> </ul> <p>\u00a9 2026 Ventural\u00edtica | Built for Responsible AI</p>"},{"location":"annex-iv/","title":"Generating Technical Documentation (Annex IV)","text":"<p>One of the most tedious parts of the EU AI Act is Annex IV: the requirement to maintain up-to-date technical documentation.</p> <p>Ventural\u00edtica automates this by treating your code execution traces as the source of truth.</p>"},{"location":"annex-iv/#the-annex-iv-generator","title":"The Annex IV Generator","text":"<p>You can generate a compliant draft of your Technical Documentation directly from the Ventural\u00edtica Dashboard.</p>"},{"location":"annex-iv/#step-1-launch-the-dashboard","title":"Step 1: Launch the Dashboard","text":"<p>Run the UI from your terminal in the root of your project:</p> <pre><code>venturalitica ui\n</code></pre>"},{"location":"annex-iv/#step-2-navigate-to-annex-iv-generator","title":"Step 2: Navigate to \"Annex IV Generator\"","text":"<p>In the left sidebar, look for the GENERATE REPORTS section.</p> <ol> <li>Click on \ud83d\udcc4 technical_doc.md.</li> <li>The system will analyze your local <code>.venturalitica/</code> folder.</li> <li>It will pull:<ul> <li>System Architecture (from <code>bom.json</code>)</li> <li>Risk Management Status (from Article 9 Audit Results)</li> <li>Data Governance (from Article 10 Audit Results)</li> <li>Cybersecurity (from CVE scans)</li> </ul> </li> </ol>"},{"location":"annex-iv/#step-3-download-the-draft","title":"Step 3: Download the Draft","text":"<p>You will see a live preview of the generated markdown file.</p> <ul> <li>Click Download Draft to save it as <code>Annex_IV_Draft.md</code>.</li> <li>You can then convert this Markdown file to PDF using your preferred tool (e.g., Pandoc or VS Code).</li> </ul> <p>Dynamic Updates</p> <p>Each time you run <code>vl.enforce()</code>, the underlying evidence updates. Generating a new report will always reflect the latest state of your system.</p>"},{"location":"annex-iv/#via-cli-alternative","title":"Via CLI (Alternative)","text":"<p>For CI/CD pipelines, you can also generate this documentation without opening the UI:</p> <pre><code>venturalitica doc --output docs/technical_file.md\n</code></pre> <p>This command performs the same logic but saves the file directly to your specified path.</p>"},{"location":"api/","title":"API Reference","text":"<p>Ventural\u00edtica provides a simple, unified interface for AI governance.</p>"},{"location":"api/#core-functions","title":"\ud83d\ude80 Core Functions","text":""},{"location":"api/#quickstartscenario-verbosetrue","title":"<code>quickstart(scenario, verbose=True)</code>","text":"<p>Run a pre-configured bias audit demo on a standard dataset.</p> Parameter Type Description <code>scenario</code> <code>str</code> Predefined scenario: <code>'loan'</code>, <code>'hiring'</code>, <code>'health'</code>. <code>verbose</code> <code>bool</code> Whether to print the structured table report to the console. <p>Returns: <code>List[ComplianceResult]</code></p>"},{"location":"api/#enforcedata-target-predictionnone-policynone-attributes","title":"<code>enforce(data, target, prediction=None, policy=None, **attributes)</code>","text":"<p>The main entry point for auditing datasets and models.</p> Parameter Type Description <code>data</code> <code>DataFrame</code> Pandas DataFrame containing features, targets, and optionally predictions. <code>target</code> <code>str</code> Name of the column with ground truth labels. <code>prediction</code> <code>str\\|array</code> (Optional) Column name or array of model predictions. <code>policy</code> <code>str</code> Path to the OSCAL/YAML policy file. <code>**attributes</code> <code>str</code> Mappings for protected variables (e.g., <code>gender=\"attr9\"</code>, <code>age=\"age_col\"</code>). <p>Returns: <code>List[ComplianceResult]</code></p> <p>Note</p> <p>If <code>prediction</code> is omitted, fairness metrics automatically fall back to using <code>target</code> to audit data bias.</p>"},{"location":"api/#wrapmodel-policy-experimental","title":"<code>wrap(model, policy)</code> (Experimental)","text":"<p>PREVIEW</p> <p>This function is experimental and its API might change.</p> <p>Transparently audit your model during Scikit-Learn standard workflows.</p> Parameter Type Description <code>model</code> <code>object</code> Any Scikit-learn compatible classifier or regressor. <code>policy</code> <code>str</code> Path to the policy for evaluation. <p>Returns: <code>GovernanceWrapper</code> (Preserves original API like <code>.fit()</code> and <code>.predict()</code>).</p>"},{"location":"api/#monitorname","title":"<code>monitor(name)</code>","text":"<p>A context manager to track training metrics, hardware health, and environmental impact.</p> <pre><code>with vl.monitor(name=\"CreditModel-v1\"):\n    model.fit(X, y)\n</code></pre> <p>Collected Telemetry:</p> <ul> <li>\u23f1 Duration: Execution time of the block.</li> <li>\ud83c\udf31 Emissions: Carbon footprint (requires <code>codecarbon</code>).</li> <li>\ud83d\udee1 Stability: Model fingerprinting and integrity verification.</li> </ul>"},{"location":"api/#utility-functions","title":"\ud83d\udee0 Utility Functions","text":""},{"location":"api/#list_scenarios","title":"<code>list_scenarios()</code>","text":"<p>Returns a dictionary of available scenarios and their descriptions.</p>"},{"location":"api/#load_samplescenario","title":"<code>load_sample(scenario)</code>","text":"<p>Loads the corresponding UCI dataset for a scenario as a Pandas DataFrame.</p>"},{"location":"compliance-dashboard/","title":"The Compliance Dashboard: A Glass Box for AI","text":"<p>The Ventural\u00edtica Compliance Dashboard is your local control center for AI Governance. Unlike \"Black Box\" compliance tools that operate behind closed doors, Ventural\u00edtica provides is a Glass Box experience: it exposes the exact technical evidence your system is producing and maps it directly to regulatory obligations.</p> <p>The dashboard makes the abstract concrete. It takes the invisible artifacts of your ML pipeline\u2014metrics, logs, dependencies\u2014and renders them into a Regulatory Traceability Matrix.</p>"},{"location":"compliance-dashboard/#the-sequential-regulatory-map-articles-9-15","title":"The Sequential Regulatory Map (Articles 9-15)","text":"<p>The core feature of the dashboard is the strict sequential mapping of the EU AI Act requirements for High-Risk AI Systems (Chapter III, Section 2). This \"Compliance Walk\" guides you through the lifecycle of a compliant system.</p>"},{"location":"compliance-dashboard/#the-traceability-flow","title":"The Traceability Flow","text":""},{"location":"compliance-dashboard/#1-article-9-risk-management-system","title":"1. Article 9: Risk Management System","text":"<ul> <li>The Law: You must identify and mitigate risks to health, safety, and fundamental rights.</li> <li>The Code: Ventural\u00edtica maps your Fairness Audits here. If you run a bias check (e.g., <code>gender-bias</code>), the result is the technical evidence that you are monitoring Fundamental Rights risks.</li> <li>Status:<ul> <li><code>Mitigation Verified</code>: Your fairness tests passed.</li> <li><code>Risk Materialized</code>: A test failed (e.g., Disparate Impact detected).</li> </ul> </li> </ul>"},{"location":"compliance-dashboard/#2-article-10-data-governance","title":"2. Article 10: Data Governance","text":"<ul> <li>The Law: Training, validation, and testing data must be relevant, representative, and error-free.</li> <li>The Code: Maps to your Data Quality Checks (e.g., class imbalance, missing values) and usage of data libraries (<code>pandas</code>, <code>numpy</code>).</li> <li>Status: Flags if data validation was skipped or failed.</li> </ul>"},{"location":"compliance-dashboard/#3-article-11-technical-documentation","title":"3. Article 11: Technical Documentation","text":"<ul> <li>The Law: You must maintain up-to-date technical documentation demonstrating conformity.</li> <li>The Code: Checks for the presence of your Software Bill of Materials (SBOM) (generated by <code>venturalitica scan</code>) and the Technical File Draft (generated by <code>venturalitica doc</code>).</li> <li>Status: Green if artifacts exist; Yellow/Red if documentation is missing.</li> </ul>"},{"location":"compliance-dashboard/#4-article-12-record-keeping","title":"4. Article 12: Record-Keeping","text":"<ul> <li>The Law: Automatic logging of events over the system's lifetime to ensure traceability.</li> <li>The Code: Verifies two critical components:<ul> <li>Cryptographic Anchoring: Displays the SHA-256 hash of your evidence, proving data integrity.</li> <li>Execution Traces: Confirms that runtime metadata (<code>runtime_meta</code>) was captured during training/inference.</li> </ul> </li> </ul>"},{"location":"compliance-dashboard/#5-article-13-transparency-information","title":"5. Article 13: Transparency &amp; Information","text":"<ul> <li>The Law: The system must be sufficiently transparent to allow users to interpret outputs.</li> <li>The Code: Checks for Code Opacity. Is the source code accessible for audit? Are instructions provided?</li> </ul>"},{"location":"compliance-dashboard/#6-article-14-human-oversight","title":"6. Article 14: Human Oversight","text":"<ul> <li>The Law: The system must be designed to be overseen by natural persons (human-in-the-loop).</li> <li>The Code: Scans for \"Stop Button\" logic or interactive interfaces (e.g., Streamlit apps, Jupyter notebooks) that imply human control capability.</li> </ul>"},{"location":"compliance-dashboard/#7-article-15-accuracy-robustness-cybersecurity","title":"7. Article 15: Accuracy, Robustness &amp; Cybersecurity","text":"<ul> <li>The Law: The system must be resilient to errors and attacks.</li> <li>The Code:<ul> <li>Accuracy: Maps to your Performance Metrics (Accuracy, F1, Recall).</li> <li>Cybersecurity: Checks for Supply Chain Vulnerabilities (CVEs) in your dependencies via the SBOM scan.</li> </ul> </li> </ul>"},{"location":"compliance-dashboard/#why-this-matters","title":"Why This Matters","text":"<p>This sequential layout transforms compliance from a chaotic checklist into a logical engineering workflow:</p> <ol> <li>Assess Risk (Art 9)</li> <li>Clean Data (Art 10)</li> <li>Document It (Art 11)</li> <li>Log It (Art 12)</li> <li>Explain It (Art 13)</li> <li>control It (Art 14)</li> <li>Secure It (Art 15)</li> </ol> <p>By following this flow, you are structurally aligning your AI system with the law, line by line.</p>"},{"location":"compliance-gap/","title":"The Compliance Gap (Roadmap)","text":"<p>Ventural\u00edtica v0.3 provides the foundation for Glass Box AI, but high-risk systems (EU AI Act) require continuous improvement. This document identifies the current technical gaps and the features required to turn \"Technical Evidence\" into \"Legal Certainty.\"</p>"},{"location":"compliance-gap/#missing-features-open-gaps","title":"\ud83d\udee0 Missing Features &amp; Open Gaps","text":""},{"location":"compliance-gap/#1-evidence-hardening-article-12","title":"1. Evidence Hardening (Article 12)","text":"<ul> <li>Current State: SHA-256 hashing of evidence files.</li> <li>The Gap: No native Digital Signing.</li> <li>Requirement: Implementation of GPG/X.509 signing for <code>trace.json</code> files to ensure non-repudiation in legal audits.</li> </ul>"},{"location":"compliance-gap/#2-deep-data-governance-article-10","title":"2. Deep Data Governance (Article 10)","text":"<ul> <li>Current State: Basic class balance and missing value checks.</li> <li>The Gap: Lack of Data Lineage and Annotation Provenance.</li> <li>Requirement: Tools to log the source of labels, inter-annotator agreement metrics, and \"poisoning\" detection for training sets.</li> </ul>"},{"location":"compliance-gap/#3-human-oversight-interactive-checks-article-14","title":"3. Human Oversight Interactive Checks (Article 14)","text":"<ul> <li>Current State: Static check for interactive elements (AST analysis).</li> <li>The Gap: No runtime verification of \"Human-in-the-loop\" (HITL) actions.</li> <li>Requirement: A <code>vl.oversight()</code> wrapper to record when a human actually approves/rejects a high-risk prediction.</li> </ul>"},{"location":"compliance-gap/#4-adversarial-robustness-article-15","title":"4. Adversarial Robustness (Article 15)","text":"<ul> <li>Current State: Performance metrics (Accuracy/F1).</li> <li>The Gap: No native Attack Scanners.</li> <li>Requirement: Integration with robustness libraries (e.g., ART, CleverHans) to automate adversarial testing as part of the <code>enforce()</code> pipeline.</li> </ul>"},{"location":"compliance-gap/#5-automated-bias-mitigation","title":"5. Automated Bias Mitigation","text":"<ul> <li>Current State: Detection only.</li> <li>The Gap: Friction in fixing detected bias.</li> <li>Requirement: Integration with Fairlearn/AIF360 for \"suggested mitigations\" directly in the Dashboard.</li> </ul>"},{"location":"compliance-gap/#propose-a-feature","title":"\ud83d\ude80 Propose a Feature","text":"<p>We are building the future of Responsible AI. If you have a specific requirement to fulfill a compliance mandate, we want to hear from you.</p> <ol> <li>Open a GitHub Issue.</li> <li>Tag it as <code>feature-request</code> + <code>compliance-gap</code>.</li> <li>Describe the Legal Article (e.g., Art 13) or Technical Pain you are addressing.</li> </ol> <p>View Roadmap Discussions</p>"},{"location":"evidence-collection/","title":"Evidence Collection: The Black Box Recorder","text":"<p>While Policies (the Enforcer) stop bad models from reaching production, Evidence Collection (the Recorder) ensures you can prove exactly what happened during training. This is your \"Black Box\" flight recorder for AI.</p> <p>In Ventural\u00edtica, evidence collection is distinct from policy enforcement. You can record evidence without blocking a deployment, or enforce strictly without saving traces. However, for full EU AI Act compliance (Article 12: Record-Keeping), you need both.</p>"},{"location":"evidence-collection/#two-ways-to-record","title":"Two Ways to Record","text":""},{"location":"evidence-collection/#1-the-automatic-wrapper-vlwrap","title":"1. The Automatic Wrapper (<code>vl.wrap</code>)","text":"<p>The easiest way to collect evidence is to wrap your estimator. This automatically hooks into <code>.fit()</code> and <code>.predict()</code> to capture inputs, outputs, and metadata.</p> <pre><code>import venturalitica as vl\nfrom sklearn.ensemble import RandomForestClassifier\n\n# 1. Wrap the model\nmodel = vl.wrap(RandomForestClassifier(), policy=\"my_policy.yaml\")\n\n# 2. Train as usual (Evidence is auto-collected)\nmodel.fit(X_train, y_train, audit_data=train_df, gender=\"sex\")\n</code></pre> <p>What is recorded? *   Timestamp: Precise start/end times. *   Model Config: Hyperparameters (<code>n_estimators</code>, <code>max_depth</code>, etc.). *   Data Shape: Number of rows/columns used. *   Code Context: The filename and AST analysis of the script that called <code>fit</code>.</p>"},{"location":"evidence-collection/#2-the-trace-collector-vltracecollector","title":"2. The Trace Collector (<code>vl.tracecollector</code>)","text":"<p>For custom training loops (e.g., PyTorch, TensorFlow) or complex pipelines where <code>fit()</code> isn't enough, use the context manager.</p> <pre><code>import venturalitica as vl\n\n# Start the recording session\nwith vl.tracecollector(\"custom_training_run\"):\n    # Your custom logic here\n    model = train_custom_model(data)\n    evaluate_model(model)\n\n# Evidence is saved to .venturalitica/trace_custom_training_run.json\n</code></pre>"},{"location":"evidence-collection/#where-does-the-evidence-go","title":"Where does the evidence go?","text":"<p>All evidence is secured locally in the <code>.venturalitica/</code> directory:</p> <ul> <li><code>results.json</code>: The outcome of your policy audits (Pass/Fail).</li> <li><code>trace_{name}.json</code>: The execution metadata (timestamps, code analysis).</li> <li><code>bom.json</code>: The software supply chain inventory (dependencies).</li> </ul>"},{"location":"evidence-collection/#compliance-impact","title":"Compliance Impact","text":"<p>For Article 12 (EU AI Act), this evidence is mandatory. The Ventural\u00edtica Dashboard reads these files to prove: 1.  Traceability: \"We know exactly which code and data produced Model v1.0.\" 2.  Integrity: \"The evidence has not been tampered with\" (via SHA-256 anchoring).</p> <p>View Your Traces</p> <p>After running your training script, launch the dashboard (<code>venturalitica ui</code>) to visualize these traces in the Article 12 section.</p>"},{"location":"integrations/","title":"Deep Integrations (Glass Box v2.0)","text":"<p>Ventural\u00edtica v0.4.0 introduces Deep Integrations, designed to make AI Governance a seamless part of your existing MLOps workflow. We call this \"Glass Box 2.0\": complete visibility into both the code and the regulatory artifacts that governed it.</p>"},{"location":"integrations/#features","title":"Features","text":""},{"location":"integrations/#1-regulatory-versioning","title":"1. Regulatory Versioning","text":"<p>Every time you train a model using <code>vl.wrap()</code>, Ventural\u00edtica automatically snapshots your governance policy (<code>oscal.yaml</code>) and uploads it to your active tracking server.</p> <ul> <li>Why? Ensures that your audit trail is strictly reproducible. You can prove exactly which rules were active during training.</li> <li>Where? Look for <code>policy_snapshot</code> in your MLflow artifacts or WandB files.</li> </ul>"},{"location":"integrations/#2-integrations-status-tab","title":"2. Integrations Status Tab","text":"<p>The new Integrations tab in <code>venturalitica ui</code> provides a real-time health check of your governance ecosystem.</p> <ul> <li>Traffic Light System: Instantly see if your local MLflow or Cloud WandB are connected.</li> <li>Deep Links: One-click navigation to the exact run in your MLOps tool that produced the evidence.</li> </ul>"},{"location":"integrations/#setup","title":"Setup","text":""},{"location":"integrations/#weights-biases-cloud","title":"Weights &amp; Biases (Cloud)","text":"<p>Ventural\u00edtica automatically detects <code>wandb</code> runs.</p> <ol> <li>Configure: Set <code>WANDB_API_KEY</code> in your <code>.env</code>.</li> <li>Run: Just use <code>vl.wrap(model)</code> inside your script.</li> <li>Verify: Open <code>venturalitica ui</code> -&gt; Integrations.</li> </ol>"},{"location":"integrations/#mlflow-localremote","title":"MLflow (Local/Remote)","text":"<p>Compatible with both local <code>mlruns</code> and remote Tracking Servers.</p> <ol> <li>Configure: Set <code>MLFLOW_TRACKING_URI</code> (optional, defaults to <code>./mlruns</code>).</li> <li>Run: Ensure <code>mlflow.start_run()</code> is active when you call <code>fit()</code>.</li> <li>Verify: The UI will generate deep links to your specific Experiment and Run ID.</li> </ol>"},{"location":"integrations/#example","title":"Example","text":"<pre><code>import venturalitica as vl\nimport mlflow\n\n# 1. Define Policy\npolicy = \"risks.oscal.yaml\"\n\n# 2. Start MLOps Run\nwith mlflow.start_run():\n    # 3. Transparent Wrapping\n    model = vl.wrap(RandomForestClassifier(), policy=policy)\n\n    # 4. Train (Artifacts auto-uploaded)\n    model.fit(X_train, y_train) \n</code></pre>"},{"location":"quickstart/","title":"60-Second Quickstart","text":"<p>Goal: Your first bias audit in under 60 seconds.</p>"},{"location":"quickstart/#the-fundamentals-from-risk-to-code","title":"The Fundamentals: From Risk to Code","text":"<p>Building High-Risk AI requires a fundamental shift in how we approach testing. It is no longer enough to check for technical accuracy (e.g., F1 Score); we must now mathematically prove that the system respects fundamental rights, such as non-discrimination or data quality, as mandated by the EU AI Act.</p> <p>Ventural\u00edtica automates this by treating \"Governance\" as a dependency. Instead of vague legal requirements, you define strict policies (OSCAL) that your model must pass before it can be deployed. This turns compliance into a deterministic engineering problem.</p> <p>Is my System High-Risk?</p> <p>According to Article 6 of EU AI Act, a system is High-Risk if it is covered by Annex I (Safety Components like machinery/medical devices) or listed in Annex III (Biometrics, Critical Infrastructure, Education, Employment, Essential Services, Law Enforcement, Migration, Justice/Democracy).</p> <p>The Translation Layer:</p> <ol> <li> <p>Fundamental Risk: \"The model must not discriminate against protected groups\" (Art 9).</p> </li> <li> <p>Policy Control: \"Disparate Impact Ratio must be &gt; 0.8\".</p> </li> <li> <p>Code Assertion: <code>assert calculated_metric &gt; 0.8</code>.</p> </li> </ol> <p>When you run <code>quickstart()</code>, you are technically running a Unit Test for Ethics.</p>"},{"location":"quickstart/#step-1-install","title":"Step 1: Install","text":"<pre><code>pip install git+https://github.com/Venturalitica/venturalitica-sdk.git\n</code></pre>"},{"location":"quickstart/#step-2-run-your-first-audit","title":"Step 2: Run Your First Audit","text":"<pre><code>import venturalitica as vl\n\nvl.quickstart('loan')\n</code></pre> <p>Output:</p> <pre><code>[Ventural\u00edtica v0.3.0] \ud83c\udf93 Scenario: Credit Scoring Fairness\n[Ventural\u00edtica v0.3.0] \ud83d\udcca Loaded: UCI Dataset #144 (1000 samples)\n\n  CONTROL                DESCRIPTION                            ACTUAL     LIMIT      RESULT\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  credit-data-imbalance  Data Quality                           0.431      &gt; 0.2      \u2705 PASS\n  credit-data-bias       Disparate impact                       0.836      &gt; 0.8      \u2705 PASS\n  credit-age-disparate   Age disparity                          0.361      &gt; 0.5      \u274c FAIL\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  Audit Summary: \u274c VIOLATION | 2/3 controls passed\n</code></pre> <p>Info</p> <p>The audit detected age-based bias in the UCI German Credit dataset.</p>"},{"location":"quickstart/#step-3-whats-happening-under-the-hood","title":"Step 3: What's Happening Under the Hood","text":"<p>The <code>quickstart()</code> function is a wrapper that performs the full compliance lifecycle in one go:</p> <ol> <li>Downloads Data: Fetches the UCI German Credit dataset.  </li> <li>Loads Policy: Reads <code>risks.oscal.yaml</code> which defines the fairness rules.</li> <li>Enforces: Runs the audit (<code>vl.enforce</code>).</li> <li>Records: Captures the evidence (<code>trace.json</code>) for the dashboard.</li> </ol> <p>Here's the equivalent \"manual\" code:</p> <pre><code>from ucimlrepo import fetch_ucirepo\nimport venturalitica as vl\n\n# 1. Load Data (The \"Risk Source\")\ndataset = fetch_ucirepo(id=144)\ndf = dataset.data.features\ndf['class'] = dataset.data.targets\n\n# 2. Define the Policy (The \"Law\")\n# We load a pre-defined policies/risks.oscal.yaml\n\n# 3. Run the Audit (The \"Test\")\n# This automatically generates the Evidence Bill of Materials (BOM)\nwith vl.tracecollector(\"manual_audit\"):\n    vl.enforce(\n        data=df,\n        target=\"class\",          # The outcome (True/False)\n        gender=\"Attribute9\",     # Protected Group A\n        age=\"Attribute13\",       # Protected Group B\n        policy=\"risks.oscal.yaml\"\n    )\n</code></pre>"},{"location":"quickstart/#the-policy-logic","title":"The Policy Logic","text":"<p>The policy (<code>risks.oscal.yaml</code>) is the bridge. It tells the SDK what to check so you don't have to hardcode it.</p> <pre><code># ... inside the OSCAL YAML ...\n- control-id: credit-data-bias\n  description: \"Disparate impact ratio must be &gt; 0.8 (80% rule)\"\n  props:\n    - name: metric_key\n      value: disparate_impact   # &lt;--- The Python Function to call\n    - name: threshold\n      value: \"0.8\"              # &lt;--- The Limit to enforce\n    - name: operator\n      value: \"&gt;\"                # &lt;--- The Logic (&gt; 0.8)\n    - name: \"input:dimension\"\n      value: gender             # &lt;--- Maps to \"Attribute9\"\n</code></pre> <p>This design decouples Governance (the policy file) from Engineering (the python code).</p>"},{"location":"quickstart/#why-this-matters","title":"Why This Matters","text":"<p>Without this mechanism, your AI model is a legal \"Black Box\":</p> <ul> <li>Liability: You cannot prove you checked for bias before deployment (Art 9).</li> <li>Fragility: Compliance is a manual checklist, easily forgotten or skipped.</li> <li>Opacity: Auditors cannot see the link between your code and the law.</li> </ul> <p>By running <code>quickstart()</code>, you have just generated an immutable Compliance Artifact. Even if the laws change, your evidence remains.</p>"},{"location":"quickstart/#step-4-the-glass-box-dashboard","title":"Step 4: The \"Glass Box\" Dashboard \ud83d\udcca","text":"<p>Now that we have the evidence (the \"Black Box\" recording), let's inspect it in the Regulatory Map.</p> <pre><code>venturalitica ui\n</code></pre> <p>Navigate through the Compliance Map tabs:</p> <ul> <li>Article 9 (Risk): See the failed <code>credit-age-disparate</code> control. This is your technical evidence of \"Risk Monitoring\".</li> <li>Article 10 (Data): See the data distribution and quality checks.</li> <li>Article 13 (Transparency): Review the \"Transparency Feed\" to see your Python dependencies (BOM).</li> </ul>"},{"location":"quickstart/#step-5-generate-documentation-annex-iv","title":"Step 5: Generate Documentation (Annex IV) \ud83d\udcdd","text":"<p>The final step is to turn this evidence into a legal document.</p> <ol> <li>In the Dashboard, go to the \"Generation\" tab.</li> <li>Select \"English\" (or Spanish/Catalan/Euskera).</li> <li>Click \"Generate Annex IV\".</li> </ol> <p>Ventural\u00edtica will draft a technical document that references your specific run:</p> <p>\"As evidenced in <code>trace_quickstart_loan.json</code>, the system was audited against [OSCAL Policy: Credit Scoring Fairness]. A deviation was detected in Age Disparity (0.36), identifying a potential risk of bias...\"</p>"},{"location":"quickstart/#references","title":"References","text":"<ul> <li>Policy Used: <code>loan/risks.oscal.yaml</code></li> <li>Legal Basis:<ul> <li>EU AI Act Article 9 (Risk Management)</li> <li>EU AI Act Article 11 (Technical Documentation)</li> </ul> </li> </ul>"},{"location":"quickstart/#whats-next","title":"What's Next?","text":"<ul> <li>API Reference - Full documentation</li> <li>Create your own policy - Copy the YAML above and modify thresholds</li> </ul>"},{"location":"training/","title":"\ud83d\udee0\ufe0f Model Training Integration (Ventural\u00edtica)","text":"<p>Integrate fairness and performance checks into your ML workflow with Ventural\u00edtica.</p>"},{"location":"training/#overview","title":"Overview","text":"<p>Interactive Version</p> <p>You can run this tutorial in a Jupyter Notebook: 01-training-tutorial.ipynb</p> Phase Check Function Pre-training Data bias <code>enforce(data=train_df)</code> Post-training Model fairness + Performance <code>enforce(data=test_df, prediction=pred)</code>"},{"location":"training/#step-1-load-and-prepare-data","title":"Step 1: Load and Prepare Data","text":"<p>Since the German Credit dataset contains categorical strings, we must encode them before training.</p> <pre><code>from ucimlrepo import fetch_ucirepo\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\n\n# Fetch UCI German Credit\ndataset = fetch_ucirepo(id=144)\ndf = dataset.data.features.copy()\ndf['class'] = dataset.data.targets\n\n# Split raw data for the audit\ntrain_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n\n# Encode data for Scikit-Learn training\ndf_encoded = pd.get_dummies(df.drop(columns=['class']))\nX_train, X_test, y_train, y_test = train_test_split(\n    df_encoded, \n    df['class'].values.ravel(), \n    test_size=0.2, \n    random_state=42\n)\n</code></pre>"},{"location":"training/#step-2-pre-training-audit-data-bias","title":"Step 2: Pre-Training Audit (Data Bias)","text":"<p>Check your training data for bias before starting the compute-heavy training phase.</p> <p>Why do we need <code>tracecollector</code>?</p> <p>Compliance requires proof. Use <code>vl.tracecollector</code> to record the \"Code Story\" (BOM, Headers) along with the audit results. This is required for Annex IV generation.</p> <pre><code>import venturalitica as vl\n\n# Start the 'evidence recorder'\nwith vl.tracecollector(\"training_audit\"):\n\n    # Run the Data Audit\n    vl.enforce(\n        data=train_df,\n        target=\"class\",\n        gender=\"Attribute9\",  # Gender/Status column\n        age=\"Attribute13\",    # Age column\n        policy=\"loan-policy.yaml\"\n    )\n</code></pre> <p>Real Output: <pre><code>[Ventural\u00edtica v0.3.0] \ud83d\ude80 TraceCollector [training_audit] starting...\n[Ventural\u00edtica v0.3.0] \ud83d\udee1  Enforcing policy: loan-policy.yaml\n\n  CONTROL                DESCRIPTION                            ACTUAL     LIMIT      RESULT\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  imbalance              Minority ratio                         0.431      &gt; 0.2      \u2705 PASS\n  gender-bias            Disparate impact                       0.836      &gt; 0.8      \u2705 PASS\n  age-bias               Age disparity                          0.361      &gt; 0.5      \u274c FAIL\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  Audit Summary: \u274c VIOLATION | 2/3 controls passed\n\n  \u2705 TraceCollector [training_audit] evidence saved to .venturalitica/trace_training_audit.json\n</code></pre></p>"},{"location":"training/#step-3-train-and-evaluate","title":"Step 3: Train and Evaluate","text":"<pre><code>from sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\nmodel.fit(X_train, y_train)\n\n# Get predictions on test set\npredictions = model.predict(X_test)\n</code></pre>"},{"location":"training/#step-4-post-training-audit-fairness-performance","title":"Step 4: Post-Training Audit (Fairness + Performance)","text":"<p>Audit the model's behavior on unseen data. We reuse the same trace collector (or start a new one) to capture this phase.</p> <pre><code># Create audit dataframe (raw features + predictions)\ntest_audit_df = df.iloc[test_df.index].copy()\ntest_audit_df['prediction'] = predictions\n\nwith vl.tracecollector(\"model_eval\"):\n    vl.enforce(\n        data=test_audit_df,\n        target=\"class\",\n        prediction=\"prediction\",\n        gender=\"Attribute9\",\n        age=\"Attribute13\",\n        policy=\"loan-policy.yaml\"\n    )\n</code></pre> <p>Real Output: <pre><code>[Ventural\u00edtica v0.3.0] \ud83d\udee1  Enforcing policy: loan-policy.yaml\n\n  CONTROL                DESCRIPTION                            ACTUAL     LIMIT      RESULT\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  imbalance              Minority ratio                         0.418      &gt; 0.2      \u2705 PASS\n  gender-bias            Disparate impact                       0.905      &gt; 0.8      \u2705 PASS\n  age-bias               Age disparity                          0.600      &gt; 0.5      \u2705 PASS\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  Audit Summary: \u2705 POLICY MET | 3/3 controls passed\n</code></pre></p> <p>Warning</p> <p>While the training data failed the Age check (0.361), the model's predictions on the test set (0.600) managed to pass the policy limit (&gt;0.5). However, this improvement should be closely monitored to ensure it generalizes beyond this specific test slice.</p> <p>Why 0.361 vs 1.000?</p> <p>If you see a perfect <code>1.000</code> but expect bias, check your column binding. If a column is missing or mismatched, Ventural\u00edtica may default to 1.0. Always verify your column names (like <code>Attribute9</code> vs <code>gender</code>) in the <code>enforce()</code> call. v0.3.0 also includes a minimum support filter (N&gt;=5) to ensure statistical significance, which contributes to the precise 0.361 reading.</p>"},{"location":"training/#step-5-including-performance-metrics","title":"Step 5: Including Performance Metrics","text":"<p>It makes perfect sense to audit performance alongside fairness. If you \"fix\" bias but destroy the model's utility (e.g., 20% accuracy), the system is still failing.</p> <p>You can define performance thresholds in the same policy:</p> <pre><code>- control-id: accuracy-threshold\n  description: \"Model must achieve at least 75% accuracy\"\n  props:\n    - name: metric_key\n      value: accuracy\n    - name: threshold\n      value: \"0.75\"\n    - name: operator\n      value: gt\n</code></pre> <p>Ventural\u00edtica supports: <code>accuracy</code>, <code>precision</code>, <code>recall</code>, and <code>f1</code>.</p> <p>Example Output with Performance: <pre><code>[Ventural\u00edtica v0.3.0] \ud83d\udee1  Enforcing policy: tutorial_policy.yaml\n\n  CONTROL                DESCRIPTION                            ACTUAL     LIMIT      RESULT\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  gender-disparate       Gender fairness (DI &gt; 0.8)             0.905      &gt; 0.8      \u2705 PASS\n  age-disparate          Age fairness (DI &gt; 0.5)                0.600      &gt; 0.5      \u2705 PASS\n  accuracy-check         Accuracy &gt; 70%                         0.795      &gt; 0.7      \u2705 PASS\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  Audit Summary: \u2705 POLICY MET | 3/3 controls passed\n</code></pre></p>"},{"location":"training/#step-6-automatic-governance-with-vlwrap-experimental","title":"Step 6: Automatic Governance with <code>vl.wrap</code> (Experimental)","text":"<p>Experimental Feature</p> <p><code>vl.wrap</code> is currently in preview. Its API and behavior may change in future versions. Use with caution.</p> <p>If you are using Scikit-Learn, you can automate the entire audit process by wrapping your model. This ensures that every <code>.fit()</code> and <code>.predict()</code> call is audited against your policy.</p> <pre><code># Wrap your model\nbase_model = RandomForestClassifier(n_estimators=100, random_state=42)\ngoverned_model = vl.wrap(base_model, policy=\"loan-policy.yaml\") # Ventural\u00edtica Governance\n\n# Audits are automated! \n# Just provide the raw data for attribution mapping (e.g., gender, age)\ngoverned_model.fit(\n    X_train, y_train, \n    audit_data=train_df, \n    gender=\"Attribute9\", \n    age=\"Attribute13\"\n)\n\n# Predict also triggers the fairness + performance audit\npredictions = governed_model.predict(\n    X_test, \n    audit_data=test_df, \n    gender=\"Attribute9\", \n    age=\"Attribute13\"\n)\n</code></pre> <p>This pattern reduces boilerplate and guarantees that no model goes to production without a verified audit trail.</p>"},{"location":"training/#step-7-view-evidence-in-dashboard","title":"Step 7: View Evidence in Dashboard","text":"<p>Now that you have run the training and evaluation with <code>tracecollector</code>, you have generated the artifacts required for the EU AI Act.</p> <p>Inspect them in the Glass Box Dashboard:</p> <pre><code>venturalitica ui\n</code></pre> <p>This will launch the local server where you can see:</p> <ul> <li>Article 9: Your Fairness &amp; Performance Audit results.</li> <li>Article 13: The BOM of your training environment.</li> <li>Generation: The draft of your technical documentation.</li> </ul>"},{"location":"tutorials/01_writing_policy/","title":"Tutorial: Writing Your First Policy (OSCAL)","text":"<p>Ventural\u00edtica uses OSCAL (Open Security Controls Assessment Language) to define governance rules. This \"Policy-as-Code\" approach allows you to version control your compliance requirements alongside your software.</p>"},{"location":"tutorials/01_writing_policy/#1-the-structure-of-a-policy","title":"1. The Structure of a Policy","text":"<p>A policy file (<code>.yaml</code>) tells the SDK what to measure (metrics) and why (control descriptions).</p> <pre><code>assessment-plan:\n  uuid: policy-v1\n  metadata:\n    title: \"EU AI Act - High Risk Audit\"\n  reviewed-controls:\n    control-selections:\n      - include-controls:\n        # CONTROL BLOCK 1\n        - control-id: gender-fairness\n          description: \"Article 10: Data Governance. Examination of possible biases.\"\n          props:\n            - name: metric_key\n              value: demographic_parity_diff\n            - name: threshold\n              value: \"0.10\"\n            - name: operator\n              value: \"&lt;\"\n</code></pre>"},{"location":"tutorials/01_writing_policy/#2-defining-controls","title":"2. Defining Controls","text":"<p>Each <code>control-id</code> represents a specific check.</p>"},{"location":"tutorials/01_writing_policy/#a-bias-check-fairness","title":"A. Bias Check (Fairness)","text":"<p>Ensure your model treats groups equally.</p> <pre><code>- control-id: check-gender-bias\n  props:\n    - name: metric_key\n      value: demographic_parity_diff\n    - name: threshold\n      value: \"0.10\"  # Fail if difference &gt; 10%\n    - name: operator\n      value: \"&lt;\"\n</code></pre>"},{"location":"tutorials/01_writing_policy/#b-data-quality","title":"B. Data Quality","text":"<p>Check for class imbalance or missing values.</p> <pre><code>- control-id: check-imbalance\n  props:\n    - name: metric_key\n      value: min_class_ratio\n    - name: threshold\n      value: \"0.20\"  # Fail if minority class &lt; 20%\n    - name: operator\n      value: \"&gt;\"\n</code></pre>"},{"location":"tutorials/01_writing_policy/#3-supported-metrics","title":"3. Supported Metrics","text":"<p>All metrics from <code>venturalitica.metrics</code> are supported. Common keys:</p> Key Description <code>demographic_parity_diff</code> Difference in acceptance rates (Fairness). <code>disparate_impact_ratio</code> Ratio of acceptance rates (Fairness). <code>accuracy_score</code> Overall model accuracy (Performance). <code>f1_score</code> Harmonic mean of precision/recall (Performance). <code>missing_values_ratio</code> Percentage of empty cells (Quality)."},{"location":"tutorials/01_writing_policy/#4-how-to-run-it","title":"4. How to Run It","text":"<p>Once you have your <code>policy.yaml</code>, apply it to your dataframe:</p> <pre><code>import venturalitica as vl\nimport pandas as pd\n\ndf = pd.read_csv(\"data/loan_applications.csv\")\n\nvl.enforce(\n    data=df,\n    target=\"approved\",       # The column to predict\n    gender=\"applicant_sex\",  # The protected attribute\n    policy=\"policy.yaml\"     # Your OSCAL file\n)\n</code></pre> <p>The SDK will evaluate every control in the YAML against your data. If any control fails (and <code>blocking: true</code>), it raises an <code>AuditFailure</code> exception, stopping the pipeline.</p>"},{"location":"es/","title":"Ventural\u00edtica SDK","text":"<p>Gobernanza \"Sin Fricci\u00f3n\" para Sistemas de IA.</p> <p>Ventural\u00edtica SDK integra la gobernanza de IA directamente en tu c\u00f3digo Python. Convierte pol\u00edticas legales abstractas (como la norma EU AI Act) en Tests Unitarios Ejecutables.</p>"},{"location":"es/#por-que-venturalitica","title":"\u26a1 \u00bfPor qu\u00e9 Ventural\u00edtica?","text":""},{"location":"es/#cumplimiento-como-codigo","title":"\ud83d\udee1\ufe0f Cumplimiento como C\u00f3digo","text":"<p>Deja de luchar con PDFs legales. Define tus pol\u00edticas en OSCAL (el est\u00e1ndar de NIST) y ejec\u00fatalas autom\u00e1ticamente en tu pipeline de MLOps.</p>"},{"location":"es/#caja-de-cristal-glass-box-transparency","title":"\ud83d\udd0d Caja de Cristal (Glass Box Transparency)","text":"<p>Genera autom\u00e1ticamente la documentaci\u00f3n t\u00e9cnica requerida por el Anexo IV de la EU AI Act y normas ISO 42001.</p>"},{"location":"es/#soberania-local-privacy-first","title":"\ud83c\uddea\ud83c\uddfa Soberan\u00eda Local (Privacy-First)","text":"<p>Tu c\u00f3digo, tus datos, tu infraestructura. El SDK se ejecuta 100% en local. Ni un solo byte de tus datos de entrenamiento sale de tu servidor.</p>"},{"location":"es/#inicio-rapido","title":"\ud83d\ude80 Inicio R\u00e1pido","text":"<p>Instala la librer\u00eda:</p> <pre><code>pip install venturalitica\n</code></pre> <p>Ejecuta tu primera auditor\u00eda de sesgo (Bias Audit):</p> <pre><code>import venturalitica as vl\n\n# Carga un dataset de ejemplo y aud\u00edtalo contra la EU AI Act\nresultados = vl.quickstart('loan')\n</code></pre> <p>Resultado en consola: <pre><code>[Ventural\u00edtica] \ud83c\udf93 Escenario: Credit Scoring Fairness\n[Ventural\u00edtica] \ud83d\udee1\ufe0f  Pol\u00edtica: EU AI Act - Pr\u00e9stamos Justos\n\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Resultados de Auditor\u00eda \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Control  \u2502 M\u00e9trica              \u2502 Valor \u2502 Estado \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 fair-gen \u2502 demographic_parity   \u2502 0.08  \u2502 \u2713 PASS \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\n\ud83c\udf89 \u00a1Todas las m\u00e9tricas de equidad aprobadas!\n</code></pre></p>"},{"location":"es/#documentacion","title":"\ud83d\udcda Documentaci\u00f3n","text":"<ul> <li>Tutorial: Primera Auditor\u00eda</li> <li>Integraci\u00f3n con Entrenamiento (MLOps)</li> <li>El Mapa Regulatorio (Art 9-15)</li> <li>Referencia de API</li> </ul>"},{"location":"es/#arquitectura","title":"\ud83c\udfd7\ufe0f Arquitectura","text":"<p>El SDK act\u00faa como un puente entre tus datos y la regulaci\u00f3n:</p> <pre><code>graph LR\n    A[Datos / Modelo] --&gt; B(SDK Ventural\u00edtica);\n    C[Pol\u00edtica OSCAL] --&gt; B;\n    B --&gt; D{Validador};\n    D --&gt;|Cumple| E[Log MLflow / WandB];\n    D --&gt;|Falla| F[Alerta Bloqueante];\n</code></pre>      Hecho con \u2764\ufe0f en Europa para una IA confiable."},{"location":"es/annex-iv/","title":"Generando Documentaci\u00f3n T\u00e9cnica (Anexo IV)","text":"<p>Una de las partes m\u00e1s tediosas de la Ley de IA de la UE es el Anexo IV: el requisito de mantener documentaci\u00f3n t\u00e9cnica actualizada.</p> <p>Ventural\u00edtica automatiza esto tratando tus trazas de ejecuci\u00f3n de c\u00f3digo como la fuente de verdad.</p>"},{"location":"es/annex-iv/#el-generador-del-anexo-iv","title":"El Generador del Anexo IV","text":"<p>Puedes generar un borrador conforme de tu Documentaci\u00f3n T\u00e9cnica directamente desde el Panel de Ventural\u00edtica.</p>"},{"location":"es/annex-iv/#paso-1-lanzar-el-panel","title":"Paso 1: Lanzar el Panel","text":"<p>Ejecuta la UI desde tu terminal en la ra\u00edz de tu proyecto:</p> <pre><code>venturalitica ui\n</code></pre>"},{"location":"es/annex-iv/#paso-2-navegar-al-generador-de-anexo-iv","title":"Paso 2: Navegar al \"Generador de Anexo IV\"","text":"<p>En la barra lateral izquierda, busca la secci\u00f3n GENERAR REPORTES.</p> <ol> <li>Haz clic en \ud83d\udcc4 technical_doc.md.</li> <li>El sistema analizar\u00e1 tu carpeta local <code>.venturalitica/</code>.</li> <li>Extraer\u00e1:<ul> <li>Arquitectura del Sistema (de <code>bom.json</code>)</li> <li>Estado de Gesti\u00f3n de Riesgos (de los Resultados de Auditor\u00eda del Art\u00edculo 9)</li> <li>Gobernanza de Datos (de los Resultados de Auditor\u00eda del Art\u00edculo 10)</li> <li>Ciberseguridad (de los escaneos CVE)</li> </ul> </li> </ol>"},{"location":"es/annex-iv/#paso-3-descargar-el-borrador","title":"Paso 3: Descargar el Borrador","text":"<p>Ver\u00e1s una vista previa en vivo del archivo markdown generado.</p> <ul> <li>Haz clic en Descargar Borrador para guardarlo como <code>Anexo_IV_Borrador.md</code>.</li> <li>Luego puedes convertir este archivo Markdown a PDF usando tu herramienta preferida (ej., Pandoc o VS Code).</li> </ul> <p>Actualizaciones Din\u00e1micas</p> <p>Cada vez que ejecutas <code>vl.enforce()</code>, la evidencia subyacente se actualiza. Generar un nuevo reporte siempre reflejar\u00e1 el \u00faltimo estado de tu sistema.</p>"},{"location":"es/annex-iv/#via-cli-alternativa","title":"V\u00eda CLI (Alternativa)","text":"<p>Para canalizaciones de CI/CD, tambi\u00e9n puedes generar esta documentaci\u00f3n sin abrir la UI:</p> <pre><code>venturalitica doc --output docs/technical_file.md\n</code></pre> <p>Este comando realiza la misma l\u00f3gica pero guarda el archivo directamente en tu ruta especificada.</p>"},{"location":"es/api/","title":"Referencia de API","text":"<p>Ventural\u00edtica proporciona una interfaz simple y unificada para la gobernanza de IA.</p>"},{"location":"es/api/#funciones-principales","title":"\ud83d\ude80 Funciones Principales","text":""},{"location":"es/api/#quickstartscenario-verbosetrue","title":"<code>quickstart(scenario, verbose=True)</code>","text":"<p>Ejecuta una demostraci\u00f3n de auditor\u00eda de sesgo preconfigurada en un conjunto de datos est\u00e1ndar.</p> Par\u00e1metro Tipo Descripci\u00f3n <code>scenario</code> <code>str</code> Escenario predefinido: <code>'loan'</code>, <code>'hiring'</code>, <code>'health'</code>. <code>verbose</code> <code>bool</code> Si imprimir el reporte de tabla estructurado en la consola. <p>Retorna: <code>List[ComplianceResult]</code></p>"},{"location":"es/api/#enforcedata-target-predictionnone-policynone-attributes","title":"<code>enforce(data, target, prediction=None, policy=None, **attributes)</code>","text":"<p>El punto de entrada principal para auditar conjuntos de datos y modelos.</p> Par\u00e1metro Tipo Descripci\u00f3n <code>data</code> <code>DataFrame</code> DataFrame de Pandas conteniendo caracter\u00edsticas, objetivos, y opcionalmente predicciones. <code>target</code> <code>str</code> Nombre de la columna con etiquetas de verdad fundamental. <code>prediction</code> <code>str\\|array</code> (Opcional) Nombre de columna o array de predicciones del modelo. <code>policy</code> <code>str</code> Ruta al archivo de pol\u00edtica OSCAL/YAML. <code>**attributes</code> <code>str</code> Mapeos para variables protegidas (ej., <code>gender=\"attr9\"</code>, <code>age=\"age_col\"</code>). <p>Retorna: <code>List[ComplianceResult]</code></p> <p>Note</p> <p>Si se omite <code>prediction</code>, las m\u00e9tricas de equidad recurren autom\u00e1ticamente a usar <code>target</code> para auditar el sesgo de datos.</p>"},{"location":"es/api/#wrapmodel-policy-experimental","title":"<code>wrap(model, policy)</code> (Experimental)","text":"<p>VISTA PREVIA</p> <p>Esta funci\u00f3n es experimental y su API podr\u00eda cambiar.</p> <p>Audita transparentemente tu modelo durante flujos de trabajo est\u00e1ndar de Scikit-Learn.</p> Par\u00e1metro Tipo Descripci\u00f3n <code>model</code> <code>object</code> Cualquier clasificador o regresor compatible con Scikit-learn. <code>policy</code> <code>str</code> Ruta a la pol\u00edtica para evaluaci\u00f3n. <p>Retorna: <code>GovernanceWrapper</code> (Preserva la API original como <code>.fit()</code> y <code>.predict()</code>).</p>"},{"location":"es/api/#monitorname","title":"<code>monitor(name)</code>","text":"<p>Un gestor de contexto para rastrear m\u00e9tricas de entrenamiento, salud del hardware e impacto ambiental.</p> <pre><code>with vl.monitor(name=\"CreditModel-v1\"):\n    model.fit(X, y)\n</code></pre> <p>Telemetr\u00eda Recolectada:</p> <ul> <li>\u23f1 Duraci\u00f3n: Tiempo de ejecuci\u00f3n del bloque.</li> <li>\ud83c\udf31 Emisiones: Huella de carbono (requiere <code>codecarbon</code>).</li> <li>\ud83d\udee1 Estabilidad: Huella digital del modelo y verificaci\u00f3n de integridad.</li> </ul>"},{"location":"es/api/#funciones-de-utilidad","title":"\ud83d\udee0 Funciones de Utilidad","text":""},{"location":"es/api/#list_scenarios","title":"<code>list_scenarios()</code>","text":"<p>Retorna un diccionario de escenarios disponibles y sus descripciones.</p>"},{"location":"es/api/#load_samplescenario","title":"<code>load_sample(scenario)</code>","text":"<p>Carga el conjunto de datos UCI correspondiente para un escenario como un DataFrame de Pandas.</p>"},{"location":"es/compliance-dashboard/","title":"El Panel de Cumplimiento: Una Caja de Cristal para la IA","text":"<p>El Panel de Cumplimiento de Ventural\u00edtica es tu centro de control local para la Gobernanza de IA. A diferencia de las herramientas de cumplimiento de \"Caja Negra\" que operan a puerta cerrada, Ventural\u00edtica proporciona una experiencia de Caja de Cristal: expone la evidencia t\u00e9cnica exacta que tu sistema est\u00e1 produciendo y la mapea directamente a las obligaciones regulatorias.</p> <p>El panel hace concreto lo abstracto. Toma los artefactos invisibles de tu canalizaci\u00f3n de ML\u2014m\u00e9tricas, registros, dependencias\u2014y los convierte en una Matriz de Trazabilidad Regulatoria.</p>"},{"location":"es/compliance-dashboard/#el-mapa-regulatorio-secuencial-articulos-9-15","title":"El Mapa Regulatorio Secuencial (Art\u00edculos 9-15)","text":"<p>La caracter\u00edstica central del panel es el estricto mapeo secuencial de los requisitos de la Ley de IA de la UE para Sistemas de IA de Alto Riesgo (Cap\u00edtulo III, Secci\u00f3n 2). Esta \"Caminata de Cumplimiento\" te gu\u00eda a trav\u00e9s del ciclo de vida de un sistema conforme.</p>"},{"location":"es/compliance-dashboard/#el-flujo-de-trazabilidad","title":"El Flujo de Trazabilidad","text":"<p> # Note: adjusted path</p>"},{"location":"es/compliance-dashboard/#1-articulo-9-sistema-de-gestion-de-riesgos","title":"1. Art\u00edculo 9: Sistema de Gesti\u00f3n de Riesgos","text":"<ul> <li>La Ley: Debes identificar y mitigar riesgos para la salud, seguridad y derechos fundamentales.</li> <li>El C\u00f3digo: Ventural\u00edtica mapea tus Auditor\u00edas de Equidad aqu\u00ed. Si ejecutas una verificaci\u00f3n de sesgo (ej. <code>gender-bias</code>), el resultado es la evidencia t\u00e9cnica de que est\u00e1s monitoreando riesgos de Derechos Fundamentales.</li> <li>Estado:<ul> <li><code>Mitigaci\u00f3n Verificada</code>: Tus pruebas de equidad pasaron.</li> <li><code>Riesgo Materializado</code>: Una prueba fall\u00f3 (ej. Impacto Dispar detectado).</li> </ul> </li> </ul>"},{"location":"es/compliance-dashboard/#2-articulo-10-gobernanza-de-datos","title":"2. Art\u00edculo 10: Gobernanza de Datos","text":"<ul> <li>La Ley: Los datos de entrenamiento, validaci\u00f3n y prueba deben ser relevantes, representativos y libres de errores.</li> <li>El C\u00f3digo: Mapea a tus Verificaciones de Calidad de Datos (ej. desequilibrio de clases, valores faltantes) y uso de bibliotecas de datos (<code>pandas</code>, <code>numpy</code>).</li> <li>Estado: Marca si la validaci\u00f3n de datos fue omitida o fall\u00f3.</li> </ul>"},{"location":"es/compliance-dashboard/#3-articulo-11-documentacion-tecnica","title":"3. Art\u00edculo 11: Documentaci\u00f3n T\u00e9cnica","text":"<ul> <li>La Ley: Debes mantener documentaci\u00f3n t\u00e9cnica actualizada demostrando conformidad.</li> <li>El C\u00f3digo: Verifica la presencia de tu Lista de Materiales de Software (SBOM) (generada por <code>venturalitica scan</code>) y el Borrador de Archivo T\u00e9cnico (generado por <code>venturalitica doc</code>).</li> <li>Estado: Verde si existen artefactos; Amarillo/Rojo si falta documentaci\u00f3n.</li> </ul> <p> # Note: adjusted path</p>"},{"location":"es/compliance-dashboard/#4-articulo-12-mantenimiento-de-registros","title":"4. Art\u00edculo 12: Mantenimiento de Registros","text":"<ul> <li>La Ley: Registro autom\u00e1tico de eventos durante la vida del sistema para asegurar trazabilidad.</li> <li>El C\u00f3digo: Verifica dos componentes cr\u00edticos:<ul> <li>Anclaje Criptogr\u00e1fico: Muestra el hash SHA-256 de tu evidencia, probando la integridad de los datos.</li> <li>Trazas de Ejecuci\u00f3n: Confirma que los metadatos de tiempo de ejecuci\u00f3n (<code>runtime_meta</code>) fueron capturados durante el entrenamiento/inferencia.</li> </ul> </li> </ul>"},{"location":"es/compliance-dashboard/#5-articulo-13-transparencia-e-informacion","title":"5. Art\u00edculo 13: Transparencia e Informaci\u00f3n","text":"<ul> <li>La Ley: El sistema debe ser suficientemente transparente para permitir a los usuarios interpretar los resultados.</li> <li>El C\u00f3digo: Verifica la Opacidad del C\u00f3digo. \u00bfEs accesible el c\u00f3digo fuente para auditor\u00eda? \u00bfSe proporcionan instrucciones?</li> </ul>"},{"location":"es/compliance-dashboard/#6-articulo-14-supervision-humana","title":"6. Art\u00edculo 14: Supervisi\u00f3n Humana","text":"<ul> <li>La Ley: El sistema debe estar dise\u00f1ado para ser supervisado por personas naturales (humano en el bucle).</li> <li>El C\u00f3digo: Escanea en busca de l\u00f3gica de \"Bot\u00f3n de Parada\" o interfaces interactivas (ej. aplicaciones Streamlit, notebooks Jupyter) que impliquen capacidad de control humano.</li> </ul>"},{"location":"es/compliance-dashboard/#7-articulo-15-precision-robustez-y-ciberseguridad","title":"7. Art\u00edculo 15: Precisi\u00f3n, Robustez y Ciberseguridad","text":"<ul> <li>La Ley: El sistema debe ser resistente a errores y ataques.</li> <li>El C\u00f3digo:<ul> <li>Precisi\u00f3n: Mapea a tus M\u00e9tricas de Rendimiento (Accuracy, F1, Recall).</li> <li>Ciberseguridad: Verifica Vulnerabilidades de Cadena de Suministro (CVEs) en tus dependencias a trav\u00e9s del escaneo SBOM.</li> </ul> </li> </ul>"},{"location":"es/compliance-dashboard/#por-que-importa-esto","title":"Por Qu\u00e9 Importa Esto","text":"<p>Este dise\u00f1o secuencial transforma el cumplimiento de una lista de verificaci\u00f3n ca\u00f3tica en un flujo de trabajo de ingenier\u00eda l\u00f3gico:</p> <ol> <li>Evaluar Riesgo (Art 9)</li> <li>Limpiar Datos (Art 10)</li> <li>Documentarlo (Art 11)</li> <li>Registrarlo (Art 12)</li> <li>Explicarlo (Art 13)</li> <li>Controlarlo (Art 14)</li> <li>Asegurarlo (Art 15)</li> </ol> <p>Al seguir este flujo, est\u00e1s alineando estructuralmente tu sistema de IA con la ley, l\u00ednea por l\u00ednea.</p>"},{"location":"es/compliance-gap/","title":"La Brecha de Cumplimiento (Hoja de Ruta)","text":"<p>Ventural\u00edtica v0.3 proporciona la base para una IA de Caja de Cristal, pero los sistemas de alto riesgo (Ley de IA de la UE) requieren una mejora continua. Este documento identifica las brechas t\u00e9cnicas actuales y las caracter\u00edsticas requeridas para convertir la \"Evidencia T\u00e9cnica\" en \"Certeza Legal\".</p>"},{"location":"es/compliance-gap/#caracteristicas-faltantes-y-brechas-abiertas","title":"\ud83d\udee0 Caracter\u00edsticas Faltantes y Brechas Abiertas","text":""},{"location":"es/compliance-gap/#1-endurecimiento-de-evidencia-articulo-12","title":"1. Endurecimiento de Evidencia (Art\u00edculo 12)","text":"<ul> <li>Estado Actual: Hashing SHA-256 de archivos de evidencia.</li> <li>La Brecha: Sin Firma Digital nativa.</li> <li>Requisito: Implementaci\u00f3n de firma GPG/X.509 para archivos <code>trace.json</code> para asegurar el no repudio en auditor\u00edas legales.</li> </ul>"},{"location":"es/compliance-gap/#2-gobernanza-de-datos-profunda-articulo-10","title":"2. Gobernanza de Datos Profunda (Art\u00edculo 10)","text":"<ul> <li>Estado Actual: Equilibrio de clases b\u00e1sico y verificaciones de valores faltantes.</li> <li>La Brecha: Falta de Linaje de Datos y Procedencia de Anotaciones.</li> <li>Requisito: Herramientas para registrar la fuente de las etiquetas, m\u00e9tricas de acuerdo entre anotadores y detecci\u00f3n de \"envenenamiento\" para conjuntos de entrenamiento.</li> </ul>"},{"location":"es/compliance-gap/#3-verificaciones-interactivas-de-supervision-humana-articulo-14","title":"3. Verificaciones Interactivas de Supervisi\u00f3n Humana (Art\u00edculo 14)","text":"<ul> <li>Estado Actual: Verificaci\u00f3n est\u00e1tica de elementos interactivos (an\u00e1lisis AST).</li> <li>La Brecha: Sin verificaci\u00f3n en tiempo de ejecuci\u00f3n de acciones \"Humano-en-el-bucle\" (HITL).</li> <li>Requisito: Un envoltorio <code>vl.oversight()</code> para registrar cuando un humano realmente aprueba/rechaza una predicci\u00f3n de alto riesgo.</li> </ul>"},{"location":"es/compliance-gap/#4-robustez-adversarial-articulo-15","title":"4. Robustez Adversarial (Art\u00edculo 15)","text":"<ul> <li>Estado Actual: M\u00e9tricas de rendimiento (Precisi\u00f3n/F1).</li> <li>La Brecha: Sin Esc\u00e1neres de Ataques nativos.</li> <li>Requisito: Integraci\u00f3n con bibliotecas de robustez (ej., ART, CleverHans) para automatizar pruebas adversariales como parte de la canalizaci\u00f3n <code>enforce()</code>.</li> </ul>"},{"location":"es/compliance-gap/#5-mitigacion-automatizada-de-sesgos","title":"5. Mitigaci\u00f3n Automatizada de Sesgos","text":"<ul> <li>Estado Actual: Solo detecci\u00f3n.</li> <li>La Brecha: Fricci\u00f3n en la correcci\u00f3n del sesgo detectado.</li> <li>Requisito: Integraci\u00f3n con Fairlearn/AIF360 para \"mitigaciones sugeridas\" directamente en el Panel.</li> </ul>"},{"location":"es/compliance-gap/#proponer-una-caracteristica","title":"\ud83d\ude80 Proponer una Caracter\u00edstica","text":"<p>Estamos construyendo el futuro de la IA Responsable. Si tienes un requisito espec\u00edfico para cumplir un mandato de cumplimiento, queremos escucharte.</p> <ol> <li>Abre un Issue en GitHub.</li> <li>Etiqu\u00e9talo como <code>feature-request</code> + <code>compliance-gap</code>.</li> <li>Describe el Art\u00edculo Legal (ej., Art 13) o Dolor T\u00e9cnico que est\u00e1s abordando.</li> </ol> <p>Ver Discusiones de la Hoja de Ruta</p>"},{"location":"es/evidence-collection/","title":"Colecci\u00f3n de Evidencia: La Grabadora de Caja Negra","text":"<p>Mientras que las Pol\u00edticas (el Ejecutor) evitan que los modelos malos lleguen a producci\u00f3n, la Colecci\u00f3n de Evidencia (la Grabadora) asegura que puedas probar exactamente qu\u00e9 sucedi\u00f3 durante el entrenamiento. Esta es tu grabadora de vuelo de \"Caja Negra\" para la IA.</p> <p>En Ventural\u00edtica, la colecci\u00f3n de evidencia es distinta de la aplicaci\u00f3n de pol\u00edticas. Puedes registrar evidencia sin bloquear un despliegue, o aplicar estrictamente sin guardar trazas. Sin embargo, para el pleno cumplimiento de la Ley de IA de la UE (Art\u00edculo 12: Mantenimiento de Registros), necesitas ambos.</p>"},{"location":"es/evidence-collection/#dos-formas-de-registrar","title":"Dos Formas de Registrar","text":""},{"location":"es/evidence-collection/#1-el-envoltorio-automatico-vlwrap","title":"1. El Envoltorio Autom\u00e1tico (<code>vl.wrap</code>)","text":"<p>La forma m\u00e1s f\u00e1cil de recolectar evidencia es envolver tu estimador. Esto se conecta autom\u00e1ticamente a <code>.fit()</code> y <code>.predict()</code> para capturar entradas, salidas y metadatos.</p> <pre><code>import venturalitica as vl\nfrom sklearn.ensemble import RandomForestClassifier\n\n# 1. Envolver el modelo\nmodel = vl.wrap(RandomForestClassifier(), policy=\"my_policy.yaml\")\n\n# 2. Entrenar como de costumbre (La evidencia se auto-recolecta)\nmodel.fit(X_train, y_train, audit_data=train_df, gender=\"sex\")\n</code></pre> <p>\u00bfQu\u00e9 se registra? *   Marca de tiempo: Horas precisas de inicio/fin. *   Configuraci\u00f3n del Modelo: Hiperpar\u00e1metros (<code>n_estimators</code>, <code>max_depth</code>, etc.). *   Forma de Datos: N\u00famero de filas/columnas utilizadas. *   Contexto del C\u00f3digo: El nombre del archivo y el an\u00e1lisis AST del script que llam\u00f3 a <code>fit</code>.</p>"},{"location":"es/evidence-collection/#2-el-recolector-de-trazas-vltracecollector","title":"2. El Recolector de Trazas (<code>vl.tracecollector</code>)","text":"<p>Para bucles de entrenamiento personalizados (ej., PyTorch, TensorFlow) o canalizaciones complejas donde <code>fit()</code> no es suficiente, usa el gestor de contexto.</p> <pre><code>import venturalitica as vl\n\n# Iniciar la sesi\u00f3n de grabaci\u00f3n\nwith vl.tracecollector(\"custom_training_run\"):\n    # Tu l\u00f3gica personalizada aqu\u00ed\n    model = train_custom_model(data)\n    evaluate_model(model)\n\n# La evidencia se guarda en .venturalitica/trace_custom_training_run.json\n</code></pre>"},{"location":"es/evidence-collection/#a-donde-va-la-evidencia","title":"\u00bfA d\u00f3nde va la evidencia?","text":"<p>Toda la evidencia se asegura localmente en el directorio <code>.venturalitica/</code>:</p> <ul> <li><code>results.json</code>: El resultado de tus auditor\u00edas de pol\u00edtica (Pasa/Falla).</li> <li><code>trace_{name}.json</code>: Los metadatos de ejecuci\u00f3n (marcas de tiempo, an\u00e1lisis de c\u00f3digo).</li> <li><code>bom.json</code>: El inventario de la cadena de suministro de software (dependencias).</li> </ul>"},{"location":"es/evidence-collection/#impacto-en-el-cumplimiento","title":"Impacto en el Cumplimiento","text":"<p>Para el Art\u00edculo 12 (Ley de IA de la UE), esta evidencia es obligatoria. El Panel de Ventural\u00edtica lee estos archivos para probar:</p> <ol> <li>Trazabilidad: \"Sabemos exactamente qu\u00e9 c\u00f3digo y datos produjeron el Modelo v1.0.\"</li> <li>Integridad: \"La evidencia no ha sido manipulada\" (v\u00eda anclaje SHA-256).</li> </ol> <p>Ver Tus Trazas</p> <p>Despu\u00e9s de ejecutar tu script de entrenamiento, lanza el panel (<code>venturalitica ui</code>) para visualizar estas trazas en la secci\u00f3n Art\u00edculo 12.</p>"},{"location":"es/integrations/","title":"Integraciones Profundas (Caja de Cristal v2.0)","text":"<p>Ventural\u00edtica v0.4.0 introduce Integraciones Profundas, dise\u00f1adas para hacer que la Gobernanza de IA sea una parte perfecta de tu flujo de trabajo MLOps existente. Llamamos a esto \"Caja de Cristal 2.0\": visibilidad completa tanto en el c\u00f3digo como en los artefactos regulatorios que lo gobernaron.</p>"},{"location":"es/integrations/#caracteristicas","title":"Caracter\u00edsticas","text":""},{"location":"es/integrations/#1-versionado-regulatorio","title":"1. Versionado Regulatorio","text":"<p>Cada vez que entrenas un modelo usando <code>vl.wrap()</code>, Ventural\u00edtica autom\u00e1ticamente toma una instant\u00e1nea de tu pol\u00edtica de gobernanza (<code>oscal.yaml</code>) y la sube a tu servidor de seguimiento activo.</p> <ul> <li>\u00bfPor qu\u00e9? Asegura que tu rastro de auditor\u00eda sea estrictamente reproducible. Puedes probar exactamente qu\u00e9 reglas estaban activas durante el entrenamiento.</li> <li>\u00bfD\u00f3nde? Busca <code>policy_snapshot</code> en tus artefactos de MLflow o archivos de WandB.</li> </ul>"},{"location":"es/integrations/#2-pestana-de-estado-de-integraciones","title":"2. Pesta\u00f1a de Estado de Integraciones","text":"<p>La nueva pesta\u00f1a Integraciones en <code>venturalitica ui</code> proporciona una verificaci\u00f3n de salud en tiempo real de tu ecosistema de gobernanza.</p> <ul> <li>Sistema de Sem\u00e1foro: Ve instant\u00e1neamente si tu MLflow local o WandB en la Nube est\u00e1n conectados.</li> <li>Enlaces Profundos: Navegaci\u00f3n de un clic a la ejecuci\u00f3n exacta en tu herramienta MLOps que produjo la evidencia.</li> </ul>"},{"location":"es/integrations/#configuracion","title":"Configuraci\u00f3n","text":""},{"location":"es/integrations/#weights-biases-nube","title":"Weights &amp; Biases (Nube)","text":"<p>Ventural\u00edtica detecta autom\u00e1ticamente ejecuciones de <code>wandb</code>.</p> <ol> <li>Configurar: Establece <code>WANDB_API_KEY</code> en tu <code>.env</code>.</li> <li>Ejecutar: Solo usa <code>vl.wrap(model)</code> dentro de tu script.</li> <li>Verificar: Abre <code>venturalitica ui</code> -&gt; Integraciones.</li> </ol>"},{"location":"es/integrations/#mlflow-localremoto","title":"MLflow (Local/Remoto)","text":"<p>Compatible tanto con <code>mlruns</code> locales como con Servidores de Seguimiento remotos.</p> <ol> <li>Configurar: Establece <code>MLFLOW_TRACKING_URI</code> (opcional, predeterminado a <code>./mlruns</code>).</li> <li>Ejecutar: Aseg\u00farate de que <code>mlflow.start_run()</code> est\u00e9 activo cuando llames a <code>fit()</code>.</li> <li>Verificar: La UI generar\u00e1 enlaces profundos a tu Experimento y ID de Ejecuci\u00f3n espec\u00edficos.</li> </ol>"},{"location":"es/integrations/#ejemplo","title":"Ejemplo","text":"<pre><code>import venturalitica as vl\nimport mlflow\n\n# 1. Definir Pol\u00edtica\npolicy = \"risks.oscal.yaml\"\n\n# 2. Iniciar Ejecuci\u00f3n MLOps\nwith mlflow.start_run():\n    # 3. Envoltura Transparente\n    model = vl.wrap(RandomForestClassifier(), policy=policy)\n\n    # 4. Entrenar (Artefactos auto-subidos)\n    model.fit(X_train, y_train) \n</code></pre>"},{"location":"es/quickstart/","title":"Inicio R\u00e1pido en 60 Segundos","text":"<p>Objetivo: Tu primera auditor\u00eda de sesgo en menos de 60 segundos.</p>"},{"location":"es/quickstart/#los-fundamentos-del-riesgo-al-codigo","title":"Los fundamentos: Del Riesgo al C\u00f3digo","text":"<p>Construir una IA de Alto Riesgo requiere un cambio fundamental en c\u00f3mo abordamos las pruebas. Ya no es suficiente verificar la precisi\u00f3n t\u00e9cnica (por ejemplo, F1 Score); ahora debemos probar matem\u00e1ticamente que el sistema respeta los derechos fundamentales, como la no discriminaci\u00f3n o la calidad de los datos, tal como lo exige la Ley de IA de la UE.</p> <p>Ventural\u00edtica automatiza esto tratando la \"Gobernanza\" como una dependencia. En lugar de vagos requisitos legales, defines pol\u00edticas estrictas (OSCAL) que tu modelo debe aprobar antes de ser desplegado. Esto convierte el cumplimiento en un problema de ingenier\u00eda determinista.</p> <p>\u00bfEs mi Sistema de Alto Riesgo?</p> <p>Seg\u00fan el Art\u00edculo 6 de la Ley de IA de la UE, un sistema es de Alto Riesgo si est\u00e1 cubierto por el Anexo I (Componentes de Seguridad como maquinaria/dispositivos m\u00e9dicos) o listado en el Anexo III (Biometr\u00eda, Infraestructura Cr\u00edtica, Educaci\u00f3n, Empleo, Servicios Esenciales, Cumplimiento de la Ley, Migraci\u00f3n, Justicia/Democracia).</p> <p>La Capa de Traducci\u00f3n:</p> <ol> <li> <p>Riesgo Fundamental: \"El modelo no debe discriminar a grupos protegidos\" (Art 9).</p> </li> <li> <p>Control de Pol\u00edtica: \"La Tasa de Impacto Dispar debe ser &gt; 0.8\".</p> </li> <li> <p>Aserci\u00f3n de C\u00f3digo: <code>assert calculated_metric &gt; 0.8</code>.</p> </li> </ol> <p>Cuando ejecutas <code>quickstart()</code>, t\u00e9cnicamente est\u00e1s ejecutando una Prueba Unitaria de \u00c9tica.</p>"},{"location":"es/quickstart/#paso-1-instalacion","title":"Paso 1: Instalaci\u00f3n","text":"<pre><code>pip install git+https://github.com/Venturalitica/venturalitica-sdk.git\n</code></pre>"},{"location":"es/quickstart/#paso-2-ejecuta-tu-primera-auditoria","title":"Paso 2: Ejecuta Tu Primera Auditor\u00eda","text":"<pre><code>import venturalitica as vl\n\nvl.quickstart('loan')\n</code></pre> <p>Salida:</p> <pre><code>[Ventural\u00edtica v0.3.0] \ud83c\udf93 Escenario: Equidad en Calificaci\u00f3n Crediticia\n[Ventural\u00edtica v0.3.0] \ud83d\udcca Cargado: UCI Dataset #144 (1000 muestras)\n\n  CONTROL                DESCRIPCION                            ACTUAL     LIMITE     RESULTADO\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  credit-data-imbalance  Calidad de Datos                       0.431      &gt; 0.2      \u2705 PASS\n  credit-data-bias       Impacto Dispar                         0.836      &gt; 0.8      \u2705 PASS\n  credit-age-disparate   Disparidad por Edad                    0.361      &gt; 0.5      \u274c FAIL\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  Resumen de Auditor\u00eda: \u274c VIOLACI\u00d3N | 2/3 controles pasados\n</code></pre> <p>Info</p> <p>La auditor\u00eda detect\u00f3 un sesgo basado en la edad en el conjunto de datos de Cr\u00e9dito Alem\u00e1n UCI.</p>"},{"location":"es/quickstart/#paso-3-que-sucede-bajo-el-capo","title":"Paso 3: Qu\u00e9 Sucede Bajo el Cap\u00f3","text":"<p>La funci\u00f3n <code>quickstart()</code> es un envoltorio que realiza el ciclo de vida completo de cumplimiento de una sola vez:</p> <ol> <li>Descarga Datos: Obtiene el conjunto de datos de Cr\u00e9dito Alem\u00e1n UCI.</li> <li>Carga Pol\u00edtica: Lee <code>risks.oscal.yaml</code> que define las reglas de equidad.</li> <li>Ejecuta: Corre la auditor\u00eda (<code>vl.enforce</code>).</li> <li>Registra: Captura la evidencia (<code>trace.json</code>) para el panel de control.</li> </ol> <p>Aqu\u00ed est\u00e1 el c\u00f3digo \"manual\" equivalente:</p> <pre><code>from ucimlrepo import fetch_ucirepo\nimport venturalitica as vl\n\n# 1. Cargar Datos (La \"Fuente de Riesgo\")\ndataset = fetch_ucirepo(id=144)\ndf = dataset.data.features\ndf['class'] = dataset.data.targets\n\n# 2. Definir la Pol\u00edtica (La \"Ley\")\n# Cargamos una pre-definida policies/risks.oscal.yaml\n\n# 3. Ejecutar la Auditor\u00eda (La \"Prueba\")\n# Esto genera autom\u00e1ticamente la Lista de Materiales de Evidencia (BOM)\nwith vl.tracecollector(\"manual_audit\"):\n    vl.enforce(\n        data=df,\n        target=\"class\",          # El resultado (True/False)\n        gender=\"Attribute9\",     # Grupo Protegido A\n        age=\"Attribute13\",       # Grupo Protegido B\n        policy=\"risks.oscal.yaml\"\n    )\n</code></pre>"},{"location":"es/quickstart/#la-logica-de-la-politica","title":"La L\u00f3gica de la Pol\u00edtica","text":"<p>La pol\u00edtica (<code>risks.oscal.yaml</code>) es el puente. Le dice al SDK qu\u00e9 verificar para que no tengas que codificarlo.</p> <pre><code># ... dentro del YAML OSCAL ...\n- control-id: credit-data-bias\n  description: \"La tasa de impacto dispar debe ser &gt; 0.8 (regla del 80%)\"\n  props:\n    - name: metric_key\n      value: disparate_impact   # &lt;--- La Funci\u00f3n Python a llamar\n    - name: threshold\n      value: \"0.8\"              # &lt;--- El L\u00edmite a aplicar\n    - name: operator\n      value: \"&gt;\"                # &lt;--- La L\u00f3gica (&gt; 0.8)\n    - name: \"input:dimension\"\n      value: gender             # &lt;--- Mapea a \"Attribute9\"\n</code></pre> <p>Este dise\u00f1o desacopla la Gobernanza (el archivo de pol\u00edtica) de la Ingenier\u00eda (el c\u00f3digo python).</p>"},{"location":"es/quickstart/#por-que-importa-esto","title":"Por Qu\u00e9 Importa Esto","text":"<p>Sin este mecanismo, tu modelo de IA es una \"Caja Negra\" legal:</p> <ul> <li>Responsabilidad Civil: No puedes probar que verificaste el sesgo antes del despliegue (Art 9).</li> <li>Fragilidad: El cumplimiento es una lista de verificaci\u00f3n manual, f\u00e1cil de olvidar u omitir.</li> <li>Opacidad: Los auditores no pueden ver el v\u00ednculo entre tu c\u00f3digo y la ley.</li> </ul> <p>Al ejecutar <code>quickstart()</code>, acabas de generar un Artefacto de Cumplimiento inmutable. Incluso si las leyes cambian, tu evidencia permanece.</p>"},{"location":"es/quickstart/#paso-4-el-panel-de-control-caja-de-cristal","title":"Paso 4: El Panel de Control \"Caja de Cristal\" \ud83d\udcca","text":"<p>Ahora que tenemos la evidencia (la grabaci\u00f3n de la \"Caja Negra\"), inspeccion\u00e9mosla en el Mapa Regulatorio.</p> <pre><code>venturalitica ui\n</code></pre> <p>Navega a trav\u00e9s de las pesta\u00f1as del Mapa de Cumplimiento:</p> <ul> <li>Art\u00edculo 9 (Riesgo): Ve el control fallido <code>credit-age-disparate</code>. Esta es tu evidencia t\u00e9cnica de \"Monitoreo de Riesgos\".</li> <li>Art\u00edculo 10 (Datos): Ve la distribuci\u00f3n de datos y verificaciones de calidad.</li> <li>Art\u00edculo 13 (Transparencia): Revisa el \"Feed de Transparencia\" para ver tus dependencias de Python (BOM).</li> </ul>"},{"location":"es/quickstart/#paso-5-generar-documentacion-anexo-iv","title":"Paso 5: Generar Documentaci\u00f3n (Anexo IV) \ud83d\udcdd","text":"<p>El paso final es convertir esta evidencia en un documento legal.</p> <ol> <li>En el Panel, ve a la pesta\u00f1a \"Generaci\u00f3n\".</li> <li>Selecciona \"Espa\u00f1ol\".</li> <li>Haz clic en \"Generar Anexo IV\".</li> </ol> <p>Ventural\u00edtica redactar\u00e1 un documento t\u00e9cnico que hace referencia a tu ejecuci\u00f3n espec\u00edfica:</p> <p>\"Como se evidencia en <code>trace_quickstart_loan.json</code>, el sistema fue auditado contra [Pol\u00edtica OSCAL: Equidad en Calificaci\u00f3n Crediticia]. Se detect\u00f3 una desviaci\u00f3n en la Disparidad de Edad (0.36), identificando un riesgo potencial de sesgo...\"</p>"},{"location":"es/quickstart/#referencias","title":"Referencias","text":"<ul> <li>Pol\u00edtica Usada: <code>loan/risks.oscal.yaml</code></li> <li>Base Legal:<ul> <li>Ley de IA de la UE Art\u00edculo 9 (Gesti\u00f3n de Riesgos)</li> <li>Ley de IA de la UE Art\u00edculo 11 (Documentaci\u00f3n T\u00e9cnica)</li> </ul> </li> </ul>"},{"location":"es/quickstart/#que-sigue","title":"\u00bfQu\u00e9 sigue?","text":"<ul> <li>Referencia de API - Documentaci\u00f3n completa</li> <li>Crea tu propia pol\u00edtica - Copia el YAML anterior y modifica los umbrales</li> </ul>"},{"location":"es/training/","title":"\ud83d\udee0\ufe0f Integraci\u00f3n de Entrenamiento de Modelos (Ventural\u00edtica)","text":"<p>Integra verificaciones de equidad y rendimiento en tu flujo de trabajo de ML con Ventural\u00edtica.</p>"},{"location":"es/training/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>Versi\u00f3n Interactiva</p> <p>Puedes ejecutar este tutorial en un Jupyter Notebook: 01-training-tutorial.ipynb</p> Fase Verificaci\u00f3n Funci\u00f3n Pre-entrenamiento Sesgo de datos <code>enforce(data=train_df)</code> Post-entrenamiento Equidad del modelo + Rendimiento <code>enforce(data=test_df, prediction=pred)</code>"},{"location":"es/training/#paso-1-cargar-y-preparar-datos","title":"Paso 1: Cargar y Preparar Datos","text":"<p>Dado que el conjunto de datos de Cr\u00e9dito Alem\u00e1n contiene cadenas categ\u00f3ricas, debemos codificarlas antes del entrenamiento.</p> <pre><code>from ucimlrepo import fetch_ucirepo\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\n\n# Obtener Cr\u00e9dito Alem\u00e1n UCI\ndataset = fetch_ucirepo(id=144)\ndf = dataset.data.features.copy()\ndf['class'] = dataset.data.targets\n\n# Dividir datos sin procesar para la auditor\u00eda\ntrain_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n\n# Codificar datos para entrenamiento con Scikit-Learn\ndf_encoded = pd.get_dummies(df.drop(columns=['class']))\nX_train, X_test, y_train, y_test = train_test_split(\n    df_encoded, \n    df['class'].values.ravel(), \n    test_size=0.2, \n    random_state=42\n)\n</code></pre>"},{"location":"es/training/#paso-2-auditoria-pre-entrenamiento-sesgo-de-datos","title":"Paso 2: Auditor\u00eda Pre-Entrenamiento (Sesgo de Datos)","text":"<p>Verifica tus datos de entrenamiento en busca de sesgos antes de comenzar la fase de entrenamiento intensiva en c\u00f3mputo.</p> <p>\u00bfPor qu\u00e9 necesitamos <code>tracecollector</code>?</p> <p>El cumplimiento requiere pruebas. Usa <code>vl.tracecollector</code> para registrar la \"Historia del C\u00f3digo\" (BOM, Encabezados) junto con los resultados de la auditor\u00eda. Esto es requerido para la generaci\u00f3n del Anexo IV.</p> <pre><code>import venturalitica as vl\n\n# Iniciar el 'registrador de evidencia'\nwith vl.tracecollector(\"training_audit\"):\n\n    # Ejecutar la Auditor\u00eda de Datos\n    vl.enforce(\n        data=train_df,\n        target=\"class\",\n        gender=\"Attribute9\",  # Columna de G\u00e9nero/Estado\n        age=\"Attribute13\",    # Columna de Edad\n        policy=\"loan-policy.yaml\"\n    )\n</code></pre> <p>Salida Real: <pre><code>[Ventural\u00edtica v0.3.0] \ud83d\ude80 TraceCollector [training_audit] comenzando...\n[Ventural\u00edtica v0.3.0] \ud83d\udee1  Aplicando pol\u00edtica: loan-policy.yaml\n\n  CONTROL                DESCRIPCION                            ACTUAL     LIMITE     RESULTADO\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  imbalance              Proporci\u00f3n minoritaria                 0.431      &gt; 0.2      \u2705 PASS\n  gender-bias            Impacto dispar                         0.836      &gt; 0.8      \u2705 PASS\n  age-bias               Disparidad por edad                    0.361      &gt; 0.5      \u274c FAIL\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  Resumen de Auditor\u00eda: \u274c VIOLACI\u00d3N | 2/3 controles pasados\n\n  \u2705 TraceCollector [training_audit] evidencia guardada en .venturalitica/trace_training_audit.json\n</code></pre></p>"},{"location":"es/training/#paso-3-entrenar-y-evaluar","title":"Paso 3: Entrenar y Evaluar","text":"<pre><code>from sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\nmodel.fit(X_train, y_train)\n\n# Obtener predicciones en el conjunto de prueba\npredictions = model.predict(X_test)\n</code></pre>"},{"location":"es/training/#paso-4-auditoria-post-entrenamiento-equidad-rendimiento","title":"Paso 4: Auditor\u00eda Post-Entrenamiento (Equidad + Rendimiento)","text":"<p>Audita el comportamiento del modelo en datos no vistos. Reutilizamos el mismo recolector de trazas (o iniciamos uno nuevo) para capturar esta fase.</p> <pre><code># Crear dataframe de auditor\u00eda (caracter\u00edsticas sin procesar + predicciones)\ntest_audit_df = df.iloc[test_df.index].copy()\ntest_audit_df['prediction'] = predictions\n\nwith vl.tracecollector(\"model_eval\"):\n    vl.enforce(\n        data=test_audit_df,\n        target=\"class\",\n        prediction=\"prediction\",\n        gender=\"Attribute9\",\n        age=\"Attribute13\",\n        policy=\"loan-policy.yaml\"\n    )\n</code></pre> <p>Salida Real: <pre><code>[Ventural\u00edtica v0.3.0] \ud83d\udee1  Aplicando pol\u00edtica: loan-policy.yaml\n\n  CONTROL                DESCRIPCION                            ACTUAL     LIMITE     RESULTADO\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  imbalance              Proporci\u00f3n minoritaria                 0.418      &gt; 0.2      \u2705 PASS\n  gender-bias            Impacto dispar                         0.905      &gt; 0.8      \u2705 PASS\n  age-bias               Disparidad por edad                    0.600      &gt; 0.5      \u2705 PASS\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  Resumen de Auditor\u00eda: \u2705 POL\u00cdTICA CUMPLIDA | 3/3 controles pasados\n</code></pre></p> <p>Warning</p> <p>Aunque los datos de entrenamiento fallaron la verificaci\u00f3n de Edad (0.361), las predicciones del modelo en el conjunto de prueba (0.600) lograron pasar el l\u00edmite de la pol\u00edtica (&gt;0.5). Sin embargo, esta mejora debe ser monitoreada de cerca para asegurar que se generalice m\u00e1s all\u00e1 de este segmento de prueba espec\u00edfico.</p> <p>\u00bfPor qu\u00e9 0.361 vs 1.000?</p> <p>Si ves un <code>1.000</code> perfecto pero esperas sesgo, verifica tu vinculaci\u00f3n de columnas. Si falta una columna o no coincide, Ventural\u00edtica puede predeterminar a 1.0. Siempre verifica los nombres de tus columnas (como <code>Attribute9</code> vs <code>gender</code>) en la llamada <code>enforce()</code>. v0.3.0 tambi\u00e9n incluye un filtro de soporte m\u00ednimo (N&gt;=5) para asegurar significancia estad\u00edstica, lo que contribuye a la lectura precisa de 0.361.</p>"},{"location":"es/training/#paso-5-incluyendo-metricas-de-rendimiento","title":"Paso 5: Incluyendo M\u00e9tricas de Rendimiento","text":"<p>Tiene perfecto sentido auditar el rendimiento junto con la equidad. Si \"arreglas\" el sesgo pero destruyes la utilidad del modelo (por ejemplo, 20% de precisi\u00f3n), el sistema sigue fallando.</p> <p>Puedes definir umbrales de rendimiento en la misma pol\u00edtica:</p> <pre><code>- control-id: accuracy-threshold\n  description: \"El modelo debe lograr al menos 75% de precisi\u00f3n\"\n  props:\n    - name: metric_key\n      value: accuracy\n    - name: threshold\n      value: \"0.75\"\n    - name: operator\n      value: gt\n</code></pre> <p>Ventural\u00edtica soporta: <code>accuracy</code>, <code>precision</code>, <code>recall</code>, y <code>f1</code>.</p> <p>Ejemplo de Salida con Rendimiento: <pre><code>[Ventural\u00edtica v0.3.0] \ud83d\udee1  Aplicando pol\u00edtica: tutorial_policy.yaml\n\n  CONTROL                DESCRIPCION                            ACTUAL     LIMITE     RESULTADO\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  gender-disparate       Equidad de g\u00e9nero (DI &gt; 0.8)           0.905      &gt; 0.8      \u2705 PASS\n  age-disparate          Equidad de edad (DI &gt; 0.5)             0.600      &gt; 0.5      \u2705 PASS\n  accuracy-check         Precisi\u00f3n &gt; 70%                        0.795      &gt; 0.7      \u2705 PASS\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  Resumen de Auditor\u00eda: \u2705 POL\u00cdTICA CUMPLIDA | 3/3 controles pasados\n</code></pre></p>"},{"location":"es/training/#paso-6-gobernanza-automatica-con-vlwrap-experimental","title":"Paso 6: Gobernanza Autom\u00e1tica con <code>vl.wrap</code> (Experimental)","text":"<p>Caracter\u00edstica Experimental</p> <p><code>vl.wrap</code> est\u00e1 actualmente en vista previa. Su API y comportamiento pueden cambiar en versiones futuras. \u00dasalo con precauci\u00f3n.</p> <p>Si est\u00e1s usando Scikit-Learn, puedes automatizar todo el proceso de auditor\u00eda envolviendo tu modelo. Esto asegura que cada llamada <code>.fit()</code> y <code>.predict()</code> sea auditada contra tu pol\u00edtica.</p> <pre><code># Envolver tu modelo\nbase_model = RandomForestClassifier(n_estimators=100, random_state=42)\ngoverned_model = vl.wrap(base_model, policy=\"loan-policy.yaml\") # Gobernanza Ventural\u00edtica\n\n# \u00a1Las auditor\u00edas son automatizadas! \n# Solo proporciona los datos sin procesar para el mapeo de atribuci\u00f3n (ej. g\u00e9nero, edad)\ngoverned_model.fit(\n    X_train, y_train, \n    audit_data=train_df, \n    gender=\"Attribute9\", \n    age=\"Attribute13\"\n)\n\n# Predecir tambi\u00e9n activa la auditor\u00eda de equidad + rendimiento\npredictions = governed_model.predict(\n    X_test, \n    audit_data=test_df, \n    gender=\"Attribute9\", \n    age=\"Attribute13\"\n)\n</code></pre> <p>Este patr\u00f3n reduce el c\u00f3digo repetitivo y garantiza que ning\u00fan modelo vaya a producci\u00f3n sin un rastro de auditor\u00eda verificado.</p>"},{"location":"es/training/#paso-7-ver-evidencia-en-el-panel-de-control","title":"Paso 7: Ver Evidencia en el Panel de Control","text":"<p>Ahora que has ejecutado el entrenamiento y evaluaci\u00f3n con <code>tracecollector</code>, has generado los artefactos requeridos para la Ley de IA de la UE.</p> <p>Inspecci\u00f3nalos en el Panel de Caja de Cristal:</p> <pre><code>venturalitica ui\n</code></pre> <p>Esto lanzar\u00e1 el servidor local donde puedes ver:</p> <ul> <li>Art\u00edculo 9: Tus resultados de Auditor\u00eda de Equidad y Rendimiento.</li> <li>Art\u00edculo 13: La BOM de tu entorno de entrenamiento.</li> <li>Generaci\u00f3n: El borrador de tu documentaci\u00f3n t\u00e9cnica.</li> </ul>"},{"location":"es/tutorials/01_writing_policy/","title":"Tutorial: Escribiendo Tu Primera Pol\u00edtica (OSCAL)","text":"<p>Ventural\u00edtica utiliza OSCAL (Open Security Controls Assessment Language) para definir reglas de gobernanza. Este enfoque de \"Pol\u00edtica-como-C\u00f3digo\" te permite controlar las versiones de tus requisitos de cumplimiento junto con tu software.</p>"},{"location":"es/tutorials/01_writing_policy/#1-la-estructura-de-una-politica","title":"1. La Estructura de una Pol\u00edtica","text":"<p>Un archivo de pol\u00edtica (<code>.yaml</code>) le dice al SDK qu\u00e9 medir (m\u00e9tricas) y por qu\u00e9 (descripciones de control).</p> <pre><code>assessment-plan:\n  uuid: policy-v1\n  metadata:\n    title: \"Ley de IA de la UE - Auditor\u00eda de Alto Riesgo\"\n  reviewed-controls:\n    control-selections:\n      - include-controls:\n        # BLOQUE DE CONTROL 1\n        - control-id: gender-fairness\n          description: \"Art\u00edculo 10: Gobernanza de Datos. Examen de posibles sesgos.\"\n          props:\n            - name: metric_key\n              value: demographic_parity_diff\n            - name: threshold\n              value: \"0.10\"\n            - name: operator\n              value: \"&lt;\"\n</code></pre>"},{"location":"es/tutorials/01_writing_policy/#2-definiendo-controles","title":"2. Definiendo Controles","text":"<p>Cada <code>control-id</code> representa una verificaci\u00f3n espec\u00edfica.</p>"},{"location":"es/tutorials/01_writing_policy/#a-verificacion-de-sesgo-equidad","title":"A. Verificaci\u00f3n de Sesgo (Equidad)","text":"<p>Asegura que tu modelo trate a los grupos por igual.</p> <pre><code>- control-id: check-gender-bias\n  props:\n    - name: metric_key\n      value: demographic_parity_diff\n    - name: threshold\n      value: \"0.10\"  # Fallar si la diferencia &gt; 10%\n    - name: operator\n      value: \"&lt;\"\n</code></pre>"},{"location":"es/tutorials/01_writing_policy/#b-calidad-de-datos","title":"B. Calidad de Datos","text":"<p>Verifica el desequilibrio de clases o valores faltantes.</p> <pre><code>- control-id: check-imbalance\n  props:\n    - name: metric_key\n      value: min_class_ratio\n    - name: threshold\n      value: \"0.20\"  # Fallar si la clase minoritaria &lt; 20%\n    - name: operator\n      value: \"&gt;\"\n</code></pre>"},{"location":"es/tutorials/01_writing_policy/#3-metricas-soportadas","title":"3. M\u00e9tricas Soportadas","text":"<p>Todas las m\u00e9tricas de <code>venturalitica.metrics</code> son soportadas. Claves comunes:</p> Clave Descripci\u00f3n <code>demographic_parity_diff</code> Diferencia en tasas de aceptaci\u00f3n (Equidad). <code>disparate_impact_ratio</code> Proporci\u00f3n de tasas de aceptaci\u00f3n (Equidad). <code>accuracy_score</code> Precisi\u00f3n general del modelo (Rendimiento). <code>f1_score</code> Media arm\u00f3nica de precisi\u00f3n/recuerdo (Rendimiento). <code>missing_values_ratio</code> Porcentaje de celdas vac\u00edas (Calidad)."},{"location":"es/tutorials/01_writing_policy/#4-como-ejecutarlo","title":"4. C\u00f3mo Ejecutarlo","text":"<p>Una vez que tengas tu <code>policy.yaml</code>, apl\u00edcalo a tu dataframe:</p> <pre><code>import venturalitica as vl\nimport pandas as pd\n\ndf = pd.read_csv(\"data/loan_applications.csv\")\n\nvl.enforce(\n    data=df,\n    target=\"approved\",       # La columna a predecir\n    gender=\"applicant_sex\",  # El atributo protegido\n    policy=\"policy.yaml\"     # Tu archivo OSCAL\n)\n</code></pre> <p>El SDK evaluar\u00e1 cada control en el YAML contra tus datos. Si alg\u00fan control falla (y <code>blocking: true</code>), genera una excepci\u00f3n <code>AuditFailure</code>, deteniendo la canalizaci\u00f3n.</p>"}]}